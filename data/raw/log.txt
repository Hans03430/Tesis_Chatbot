
Reading dataset 'csv'...

Final shared vocab size: 91354

Splitting 194225 samples into training & validation sets (20.0% used for validation)...
Training set: 155380 samples. Validation set: 38845 samples.
Sorting training & validation sets to increase training efficiency...
Initializing model...


Creating checkpoint batch files...
Initializing training...
Epochs: 100
Batch Size: 128
Optimizer: adam
Epoch:   1/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 11737.474, Training Time: 52 seconds), Stats for epoch: (Training Loss: 11737.474, Training Time: 52 seconds)
Epoch:   1/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 16922.049, Training Time: 51 seconds), Stats for epoch: (Training Loss: 14329.762, Training Time: 103 seconds)
Epoch:   1/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 19980.360, Training Time: 52 seconds), Stats for epoch: (Training Loss: 16213.294, Training Time: 155 seconds)
Epoch:   1/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 21523.128, Training Time: 53 seconds), Stats for epoch: (Training Loss: 17540.753, Training Time: 208 seconds)
Epoch:   1/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 22276.578, Training Time: 54 seconds), Stats for epoch: (Training Loss: 18487.918, Training Time: 263 seconds)
Epoch:   1/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 21561.374, Training Time: 55 seconds), Stats for epoch: (Training Loss: 19000.161, Training Time: 319 seconds)
Epoch:   1/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 20510.618, Training Time: 57 seconds), Stats for epoch: (Training Loss: 19215.940, Training Time: 376 seconds)
Epoch:   1/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 18356.060, Training Time: 58 seconds), Stats for epoch: (Training Loss: 19108.455, Training Time: 435 seconds)
Epoch:   1/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 17699.541, Training Time: 60 seconds), Stats for epoch: (Training Loss: 18951.909, Training Time: 496 seconds)
Epoch:   1/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 16332.775, Training Time: 63 seconds), Stats for epoch: (Training Loss: 18689.996, Training Time: 559 seconds)
Epoch:   1/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 16635.430, Training Time: 65 seconds), Stats for epoch: (Training Loss: 18503.217, Training Time: 625 seconds)
Epoch:   1/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 13464.440, Training Time: 65 seconds), Stats for epoch: (Training Loss: 18083.319, Training Time: 690 seconds)
Epoch:   1/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 14045.269, Training Time: 9 seconds), Stats for epoch: (Training Loss: 18036.752, Training Time: 699 seconds)
Epoch:   1/100, Validation loss: 16791.032, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  2.000 to  1.995
Training loss improved!
Validation loss improved!
Epoch:   2/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 20079.885, Training Time: 49 seconds), Stats for epoch: (Training Loss: 20079.885, Training Time: 49 seconds)
Epoch:   2/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 16238.133, Training Time: 51 seconds), Stats for epoch: (Training Loss: 18159.009, Training Time: 100 seconds)
Epoch:   2/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 13460.487, Training Time: 52 seconds), Stats for epoch: (Training Loss: 16592.835, Training Time: 152 seconds)
Epoch:   2/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 11225.808, Training Time: 53 seconds), Stats for epoch: (Training Loss: 15251.078, Training Time: 206 seconds)
Epoch:   2/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 9791.197, Training Time: 54 seconds), Stats for epoch: (Training Loss: 14159.102, Training Time: 261 seconds)
Epoch:   2/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 9740.167, Training Time: 55 seconds), Stats for epoch: (Training Loss: 13422.613, Training Time: 316 seconds)
Epoch:   2/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 10166.682, Training Time: 57 seconds), Stats for epoch: (Training Loss: 12957.480, Training Time: 374 seconds)
Epoch:   2/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 11525.268, Training Time: 58 seconds), Stats for epoch: (Training Loss: 12778.453, Training Time: 432 seconds)
Epoch:   2/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 12389.338, Training Time: 60 seconds), Stats for epoch: (Training Loss: 12735.218, Training Time: 493 seconds)
Epoch:   2/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 13359.976, Training Time: 63 seconds), Stats for epoch: (Training Loss: 12797.694, Training Time: 557 seconds)
Epoch:   2/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 17766.540, Training Time: 65 seconds), Stats for epoch: (Training Loss: 13249.407, Training Time: 622 seconds)
Epoch:   2/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 19115.469, Training Time: 65 seconds), Stats for epoch: (Training Loss: 13738.246, Training Time: 688 seconds)
Epoch:   2/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 21145.589, Training Time: 9 seconds), Stats for epoch: (Training Loss: 13823.668, Training Time: 697 seconds)
Epoch:   2/100, Validation loss: 20952.670, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.995 to  1.990
Training loss improved!
Epoch:   3/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 19537.427, Training Time: 49 seconds), Stats for epoch: (Training Loss: 19537.427, Training Time: 49 seconds)
Epoch:   3/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 18020.453, Training Time: 51 seconds), Stats for epoch: (Training Loss: 18778.940, Training Time: 100 seconds)
Epoch:   3/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 16798.149, Training Time: 52 seconds), Stats for epoch: (Training Loss: 18118.676, Training Time: 152 seconds)
Epoch:   3/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 15617.722, Training Time: 53 seconds), Stats for epoch: (Training Loss: 17493.438, Training Time: 206 seconds)
Epoch:   3/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 14421.734, Training Time: 54 seconds), Stats for epoch: (Training Loss: 16879.097, Training Time: 260 seconds)
Epoch:   3/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 13063.282, Training Time: 55 seconds), Stats for epoch: (Training Loss: 16243.128, Training Time: 316 seconds)
Epoch:   3/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 11694.431, Training Time: 57 seconds), Stats for epoch: (Training Loss: 15593.314, Training Time: 374 seconds)
Epoch:   3/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 10289.718, Training Time: 58 seconds), Stats for epoch: (Training Loss: 14930.364, Training Time: 432 seconds)
Epoch:   3/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 9307.604, Training Time: 60 seconds), Stats for epoch: (Training Loss: 14305.613, Training Time: 493 seconds)
Epoch:   3/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 8953.812, Training Time: 63 seconds), Stats for epoch: (Training Loss: 13770.433, Training Time: 557 seconds)
Epoch:   3/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 12401.319, Training Time: 65 seconds), Stats for epoch: (Training Loss: 13645.968, Training Time: 622 seconds)
Epoch:   3/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 13206.224, Training Time: 65 seconds), Stats for epoch: (Training Loss: 13609.323, Training Time: 688 seconds)
Epoch:   3/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 12830.266, Training Time: 9 seconds), Stats for epoch: (Training Loss: 13600.339, Training Time: 697 seconds)
Epoch:   3/100, Validation loss: 14344.808, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.990 to  1.985
Training loss improved!
Validation loss improved!
Epoch:   4/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 21142.652, Training Time: 49 seconds), Stats for epoch: (Training Loss: 21142.652, Training Time: 49 seconds)
Epoch:   4/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 18187.808, Training Time: 51 seconds), Stats for epoch: (Training Loss: 19665.230, Training Time: 100 seconds)
Epoch:   4/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 16494.169, Training Time: 52 seconds), Stats for epoch: (Training Loss: 18608.210, Training Time: 152 seconds)
Epoch:   4/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 15093.229, Training Time: 53 seconds), Stats for epoch: (Training Loss: 17729.465, Training Time: 206 seconds)
Epoch:   4/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 13497.020, Training Time: 54 seconds), Stats for epoch: (Training Loss: 16882.976, Training Time: 260 seconds)
Epoch:   4/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 12220.932, Training Time: 55 seconds), Stats for epoch: (Training Loss: 16105.968, Training Time: 316 seconds)
Epoch:   4/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 11033.532, Training Time: 57 seconds), Stats for epoch: (Training Loss: 15381.334, Training Time: 374 seconds)
Epoch:   4/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 10105.405, Training Time: 58 seconds), Stats for epoch: (Training Loss: 14721.843, Training Time: 432 seconds)
Epoch:   4/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 10977.799, Training Time: 60 seconds), Stats for epoch: (Training Loss: 14305.838, Training Time: 493 seconds)
Epoch:   4/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 10092.592, Training Time: 63 seconds), Stats for epoch: (Training Loss: 13884.514, Training Time: 557 seconds)
Epoch:   4/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 14815.496, Training Time: 65 seconds), Stats for epoch: (Training Loss: 13969.148, Training Time: 622 seconds)
Epoch:   4/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 12155.114, Training Time: 65 seconds), Stats for epoch: (Training Loss: 13817.979, Training Time: 688 seconds)
Epoch:   4/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 11630.896, Training Time: 9 seconds), Stats for epoch: (Training Loss: 13792.757, Training Time: 697 seconds)
Epoch:   4/100, Validation loss: 14206.173, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.985 to  1.980
Validation loss improved!
Epoch:   5/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 24389.424, Training Time: 49 seconds), Stats for epoch: (Training Loss: 24389.424, Training Time: 49 seconds)
Epoch:   5/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 21854.347, Training Time: 51 seconds), Stats for epoch: (Training Loss: 23121.886, Training Time: 100 seconds)
Epoch:   5/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 19777.083, Training Time: 52 seconds), Stats for epoch: (Training Loss: 22006.951, Training Time: 152 seconds)
Epoch:   5/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 18027.841, Training Time: 53 seconds), Stats for epoch: (Training Loss: 21012.174, Training Time: 206 seconds)
Epoch:   5/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 16191.769, Training Time: 54 seconds), Stats for epoch: (Training Loss: 20048.093, Training Time: 260 seconds)
Epoch:   5/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 14662.524, Training Time: 55 seconds), Stats for epoch: (Training Loss: 19150.498, Training Time: 316 seconds)
Epoch:   5/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 13434.459, Training Time: 57 seconds), Stats for epoch: (Training Loss: 18333.921, Training Time: 374 seconds)
Epoch:   5/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 12122.056, Training Time: 58 seconds), Stats for epoch: (Training Loss: 17557.438, Training Time: 433 seconds)
Epoch:   5/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 10544.312, Training Time: 60 seconds), Stats for epoch: (Training Loss: 16778.202, Training Time: 493 seconds)
Epoch:   5/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 9107.258, Training Time: 63 seconds), Stats for epoch: (Training Loss: 16011.107, Training Time: 557 seconds)
Epoch:   5/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 13211.373, Training Time: 65 seconds), Stats for epoch: (Training Loss: 15756.586, Training Time: 622 seconds)
Epoch:   5/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 10388.899, Training Time: 65 seconds), Stats for epoch: (Training Loss: 15309.279, Training Time: 688 seconds)
Epoch:   5/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 11764.041, Training Time: 9 seconds), Stats for epoch: (Training Loss: 15268.395, Training Time: 697 seconds)
Epoch:   5/100, Validation loss: 15037.355, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.980 to  1.975
Epoch:   6/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 27962.727, Training Time: 49 seconds), Stats for epoch: (Training Loss: 27962.727, Training Time: 49 seconds)
Epoch:   6/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 26626.455, Training Time: 51 seconds), Stats for epoch: (Training Loss: 27294.591, Training Time: 100 seconds)
Epoch:   6/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 24044.075, Training Time: 52 seconds), Stats for epoch: (Training Loss: 26211.086, Training Time: 152 seconds)
Epoch:   6/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 22099.410, Training Time: 53 seconds), Stats for epoch: (Training Loss: 25183.167, Training Time: 206 seconds)
Epoch:   6/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 20022.887, Training Time: 54 seconds), Stats for epoch: (Training Loss: 24151.111, Training Time: 260 seconds)
Epoch:   6/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 18025.831, Training Time: 55 seconds), Stats for epoch: (Training Loss: 23130.231, Training Time: 316 seconds)
Epoch:   6/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 16033.461, Training Time: 57 seconds), Stats for epoch: (Training Loss: 22116.407, Training Time: 374 seconds)
Epoch:   6/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 17480.847, Training Time: 58 seconds), Stats for epoch: (Training Loss: 21536.962, Training Time: 432 seconds)
Epoch:   6/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 14802.917, Training Time: 60 seconds), Stats for epoch: (Training Loss: 20788.735, Training Time: 493 seconds)
Epoch:   6/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 15451.474, Training Time: 63 seconds), Stats for epoch: (Training Loss: 20255.008, Training Time: 557 seconds)
Epoch:   6/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 18599.431, Training Time: 65 seconds), Stats for epoch: (Training Loss: 20104.501, Training Time: 622 seconds)
Epoch:   6/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 19782.711, Training Time: 65 seconds), Stats for epoch: (Training Loss: 20077.686, Training Time: 688 seconds)
Epoch:   6/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 23446.972, Training Time: 9 seconds), Stats for epoch: (Training Loss: 20116.541, Training Time: 697 seconds)
Epoch:   6/100, Validation loss: 25515.514, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.975 to  1.970
Epoch:   7/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 30862.369, Training Time: 49 seconds), Stats for epoch: (Training Loss: 30862.369, Training Time: 49 seconds)
Epoch:   7/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 28672.688, Training Time: 51 seconds), Stats for epoch: (Training Loss: 29767.529, Training Time: 100 seconds)
Epoch:   7/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 26810.589, Training Time: 52 seconds), Stats for epoch: (Training Loss: 28781.882, Training Time: 152 seconds)
Epoch:   7/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 25413.161, Training Time: 53 seconds), Stats for epoch: (Training Loss: 27939.702, Training Time: 206 seconds)
Epoch:   7/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 23681.474, Training Time: 54 seconds), Stats for epoch: (Training Loss: 27088.056, Training Time: 260 seconds)
Epoch:   7/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 21503.358, Training Time: 55 seconds), Stats for epoch: (Training Loss: 26157.273, Training Time: 316 seconds)
Epoch:   7/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 19106.320, Training Time: 57 seconds), Stats for epoch: (Training Loss: 25149.994, Training Time: 374 seconds)
Epoch:   7/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 17433.311, Training Time: 58 seconds), Stats for epoch: (Training Loss: 24185.409, Training Time: 432 seconds)
Epoch:   7/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 15387.438, Training Time: 60 seconds), Stats for epoch: (Training Loss: 23207.857, Training Time: 493 seconds)
Epoch:   7/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 19560.481, Training Time: 63 seconds), Stats for epoch: (Training Loss: 22843.119, Training Time: 557 seconds)
Epoch:   7/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 21014.028, Training Time: 65 seconds), Stats for epoch: (Training Loss: 22676.838, Training Time: 622 seconds)
Epoch:   7/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 22262.621, Training Time: 65 seconds), Stats for epoch: (Training Loss: 22642.320, Training Time: 688 seconds)
Epoch:   7/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 21303.978, Training Time: 9 seconds), Stats for epoch: (Training Loss: 22626.886, Training Time: 697 seconds)
Epoch:   7/100, Validation loss: 24856.096, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.970 to  1.965
Epoch:   8/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 33098.646, Training Time: 49 seconds), Stats for epoch: (Training Loss: 33098.646, Training Time: 49 seconds)
Epoch:   8/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 31371.659, Training Time: 51 seconds), Stats for epoch: (Training Loss: 32235.152, Training Time: 100 seconds)
Epoch:   8/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 29639.144, Training Time: 52 seconds), Stats for epoch: (Training Loss: 31369.816, Training Time: 153 seconds)
Epoch:   8/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 28363.358, Training Time: 53 seconds), Stats for epoch: (Training Loss: 30618.202, Training Time: 206 seconds)
Epoch:   8/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 26517.567, Training Time: 54 seconds), Stats for epoch: (Training Loss: 29798.075, Training Time: 260 seconds)
Epoch:   8/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 24540.093, Training Time: 55 seconds), Stats for epoch: (Training Loss: 28921.744, Training Time: 316 seconds)
Epoch:   8/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 22522.556, Training Time: 57 seconds), Stats for epoch: (Training Loss: 28007.575, Training Time: 374 seconds)
Epoch:   8/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 20287.282, Training Time: 58 seconds), Stats for epoch: (Training Loss: 27042.538, Training Time: 432 seconds)
Epoch:   8/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 18814.439, Training Time: 60 seconds), Stats for epoch: (Training Loss: 26128.305, Training Time: 493 seconds)
Epoch:   8/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 18725.176, Training Time: 63 seconds), Stats for epoch: (Training Loss: 25387.992, Training Time: 557 seconds)
Epoch:   8/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 19536.907, Training Time: 65 seconds), Stats for epoch: (Training Loss: 24856.075, Training Time: 622 seconds)
Epoch:   8/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 19611.534, Training Time: 65 seconds), Stats for epoch: (Training Loss: 24419.030, Training Time: 688 seconds)
Epoch:   8/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 18676.892, Training Time: 9 seconds), Stats for epoch: (Training Loss: 24352.811, Training Time: 697 seconds)
Epoch:   8/100, Validation loss: 23945.675, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.965 to  1.960
Epoch:   9/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 31470.828, Training Time: 49 seconds), Stats for epoch: (Training Loss: 31470.828, Training Time: 49 seconds)
Epoch:   9/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 31742.875, Training Time: 51 seconds), Stats for epoch: (Training Loss: 31606.852, Training Time: 100 seconds)
Epoch:   9/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 30098.298, Training Time: 52 seconds), Stats for epoch: (Training Loss: 31104.000, Training Time: 153 seconds)
Epoch:   9/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 28582.189, Training Time: 53 seconds), Stats for epoch: (Training Loss: 30473.547, Training Time: 206 seconds)
Epoch:   9/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 26556.197, Training Time: 54 seconds), Stats for epoch: (Training Loss: 29690.077, Training Time: 261 seconds)
Epoch:   9/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 24628.154, Training Time: 55 seconds), Stats for epoch: (Training Loss: 28846.423, Training Time: 316 seconds)
Epoch:   9/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 22373.898, Training Time: 57 seconds), Stats for epoch: (Training Loss: 27921.777, Training Time: 374 seconds)
Epoch:   9/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 20372.438, Training Time: 58 seconds), Stats for epoch: (Training Loss: 26978.110, Training Time: 433 seconds)
Epoch:   9/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 18612.361, Training Time: 60 seconds), Stats for epoch: (Training Loss: 26048.582, Training Time: 493 seconds)
Epoch:   9/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 18240.996, Training Time: 63 seconds), Stats for epoch: (Training Loss: 25267.823, Training Time: 557 seconds)
Epoch:   9/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 23072.063, Training Time: 65 seconds), Stats for epoch: (Training Loss: 25068.209, Training Time: 623 seconds)
Epoch:   9/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 23390.841, Training Time: 65 seconds), Stats for epoch: (Training Loss: 24928.428, Training Time: 688 seconds)
Epoch:   9/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 24669.725, Training Time: 9 seconds), Stats for epoch: (Training Loss: 24925.445, Training Time: 697 seconds)
Epoch:   9/100, Validation loss: 28592.640, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.960 to  1.955
Epoch:  10/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 35903.676, Training Time: 49 seconds), Stats for epoch: (Training Loss: 35903.676, Training Time: 49 seconds)
Epoch:  10/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 36472.885, Training Time: 51 seconds), Stats for epoch: (Training Loss: 36188.281, Training Time: 100 seconds)
Epoch:  10/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 34936.335, Training Time: 52 seconds), Stats for epoch: (Training Loss: 35770.966, Training Time: 153 seconds)
Epoch:  10/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 33518.492, Training Time: 53 seconds), Stats for epoch: (Training Loss: 35207.847, Training Time: 206 seconds)
Epoch:  10/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 30876.882, Training Time: 54 seconds), Stats for epoch: (Training Loss: 34341.654, Training Time: 260 seconds)
Epoch:  10/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 28634.351, Training Time: 55 seconds), Stats for epoch: (Training Loss: 33390.437, Training Time: 316 seconds)
Epoch:  10/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 26429.572, Training Time: 57 seconds), Stats for epoch: (Training Loss: 32396.028, Training Time: 374 seconds)
Epoch:  10/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 23661.392, Training Time: 58 seconds), Stats for epoch: (Training Loss: 31304.198, Training Time: 432 seconds)
Epoch:  10/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 22417.704, Training Time: 60 seconds), Stats for epoch: (Training Loss: 30316.810, Training Time: 493 seconds)
Epoch:  10/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 21528.617, Training Time: 63 seconds), Stats for epoch: (Training Loss: 29437.991, Training Time: 557 seconds)
Epoch:  10/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 23939.957, Training Time: 65 seconds), Stats for epoch: (Training Loss: 28938.169, Training Time: 623 seconds)
Epoch:  10/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 25109.450, Training Time: 65 seconds), Stats for epoch: (Training Loss: 28619.109, Training Time: 688 seconds)
Epoch:  10/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 26723.416, Training Time: 9 seconds), Stats for epoch: (Training Loss: 28597.248, Training Time: 697 seconds)
Epoch:  10/100, Validation loss: 32498.410, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.955 to  1.951
Epoch:  11/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 42783.776, Training Time: 49 seconds), Stats for epoch: (Training Loss: 42783.776, Training Time: 49 seconds)
Epoch:  11/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 45252.413, Training Time: 51 seconds), Stats for epoch: (Training Loss: 44018.095, Training Time: 100 seconds)
Epoch:  11/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 43269.856, Training Time: 52 seconds), Stats for epoch: (Training Loss: 43768.682, Training Time: 152 seconds)
Epoch:  11/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 41145.263, Training Time: 53 seconds), Stats for epoch: (Training Loss: 43112.827, Training Time: 206 seconds)
Epoch:  11/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 38324.179, Training Time: 54 seconds), Stats for epoch: (Training Loss: 42155.097, Training Time: 260 seconds)
Epoch:  11/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 36132.420, Training Time: 55 seconds), Stats for epoch: (Training Loss: 41151.318, Training Time: 316 seconds)
Epoch:  11/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 32963.750, Training Time: 57 seconds), Stats for epoch: (Training Loss: 39981.665, Training Time: 374 seconds)
Epoch:  11/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 29392.809, Training Time: 58 seconds), Stats for epoch: (Training Loss: 38658.058, Training Time: 432 seconds)
Epoch:  11/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 27278.062, Training Time: 60 seconds), Stats for epoch: (Training Loss: 37393.614, Training Time: 493 seconds)
Epoch:  11/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 23358.548, Training Time: 63 seconds), Stats for epoch: (Training Loss: 35990.107, Training Time: 557 seconds)
Epoch:  11/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 26947.881, Training Time: 65 seconds), Stats for epoch: (Training Loss: 35168.087, Training Time: 622 seconds)
Epoch:  11/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 27790.127, Training Time: 65 seconds), Stats for epoch: (Training Loss: 34553.257, Training Time: 688 seconds)
Epoch:  11/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 28048.173, Training Time: 9 seconds), Stats for epoch: (Training Loss: 34478.239, Training Time: 697 seconds)
Epoch:  11/100, Validation loss: 35795.851, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.951 to  1.946
Epoch:  12/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 40370.089, Training Time: 49 seconds), Stats for epoch: (Training Loss: 40370.089, Training Time: 49 seconds)
Epoch:  12/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 43339.526, Training Time: 51 seconds), Stats for epoch: (Training Loss: 41854.808, Training Time: 100 seconds)
Epoch:  12/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 41485.632, Training Time: 52 seconds), Stats for epoch: (Training Loss: 41731.749, Training Time: 152 seconds)
Epoch:  12/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 39422.070, Training Time: 53 seconds), Stats for epoch: (Training Loss: 41154.329, Training Time: 206 seconds)
Epoch:  12/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 36641.567, Training Time: 54 seconds), Stats for epoch: (Training Loss: 40251.777, Training Time: 260 seconds)
Epoch:  12/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 34270.072, Training Time: 55 seconds), Stats for epoch: (Training Loss: 39254.826, Training Time: 316 seconds)
Epoch:  12/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 31388.631, Training Time: 57 seconds), Stats for epoch: (Training Loss: 38131.084, Training Time: 373 seconds)
Epoch:  12/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 28422.623, Training Time: 58 seconds), Stats for epoch: (Training Loss: 36917.526, Training Time: 432 seconds)
Epoch:  12/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 25702.142, Training Time: 60 seconds), Stats for epoch: (Training Loss: 35671.373, Training Time: 493 seconds)
Epoch:  12/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 24340.762, Training Time: 63 seconds), Stats for epoch: (Training Loss: 34538.312, Training Time: 557 seconds)
Epoch:  12/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 29449.769, Training Time: 65 seconds), Stats for epoch: (Training Loss: 34075.717, Training Time: 622 seconds)
Epoch:  12/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 27943.609, Training Time: 65 seconds), Stats for epoch: (Training Loss: 33564.708, Training Time: 688 seconds)
Epoch:  12/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 32715.878, Training Time: 9 seconds), Stats for epoch: (Training Loss: 33554.919, Training Time: 697 seconds)
Epoch:  12/100, Validation loss: 39201.471, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.946 to  1.941
Epoch:  13/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 41452.446, Training Time: 49 seconds), Stats for epoch: (Training Loss: 41452.446, Training Time: 49 seconds)
Epoch:  13/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 46064.690, Training Time: 51 seconds), Stats for epoch: (Training Loss: 43758.568, Training Time: 100 seconds)
Epoch:  13/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 45195.793, Training Time: 52 seconds), Stats for epoch: (Training Loss: 44237.643, Training Time: 152 seconds)
Epoch:  13/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 43962.019, Training Time: 53 seconds), Stats for epoch: (Training Loss: 44168.737, Training Time: 206 seconds)
Epoch:  13/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 41337.976, Training Time: 54 seconds), Stats for epoch: (Training Loss: 43602.585, Training Time: 260 seconds)
Epoch:  13/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 39165.484, Training Time: 55 seconds), Stats for epoch: (Training Loss: 42863.068, Training Time: 316 seconds)
Epoch:  13/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 36103.411, Training Time: 57 seconds), Stats for epoch: (Training Loss: 41897.403, Training Time: 374 seconds)
Epoch:  13/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 32948.914, Training Time: 58 seconds), Stats for epoch: (Training Loss: 40778.842, Training Time: 432 seconds)
Epoch:  13/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 29703.161, Training Time: 61 seconds), Stats for epoch: (Training Loss: 39548.210, Training Time: 493 seconds)
Epoch:  13/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 26139.244, Training Time: 63 seconds), Stats for epoch: (Training Loss: 38207.314, Training Time: 557 seconds)
Epoch:  13/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 23328.559, Training Time: 65 seconds), Stats for epoch: (Training Loss: 36854.700, Training Time: 623 seconds)
Epoch:  13/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 24049.332, Training Time: 65 seconds), Stats for epoch: (Training Loss: 35787.586, Training Time: 688 seconds)
Epoch:  13/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 25722.657, Training Time: 9 seconds), Stats for epoch: (Training Loss: 35671.516, Training Time: 698 seconds)
Epoch:  13/100, Validation loss: 37861.786, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.941 to  1.936
Epoch:  14/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 44684.693, Training Time: 49 seconds), Stats for epoch: (Training Loss: 44684.693, Training Time: 49 seconds)
Epoch:  14/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 51206.927, Training Time: 51 seconds), Stats for epoch: (Training Loss: 47945.810, Training Time: 100 seconds)
Epoch:  14/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 48955.295, Training Time: 52 seconds), Stats for epoch: (Training Loss: 48282.305, Training Time: 152 seconds)
Epoch:  14/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 46744.130, Training Time: 53 seconds), Stats for epoch: (Training Loss: 47897.761, Training Time: 206 seconds)
Epoch:  14/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 43274.022, Training Time: 54 seconds), Stats for epoch: (Training Loss: 46973.013, Training Time: 260 seconds)
Epoch:  14/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 40772.052, Training Time: 55 seconds), Stats for epoch: (Training Loss: 45939.520, Training Time: 316 seconds)
Epoch:  14/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 37554.041, Training Time: 57 seconds), Stats for epoch: (Training Loss: 44741.594, Training Time: 374 seconds)
Epoch:  14/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 33481.273, Training Time: 58 seconds), Stats for epoch: (Training Loss: 43334.054, Training Time: 432 seconds)
Epoch:  14/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 29460.266, Training Time: 60 seconds), Stats for epoch: (Training Loss: 41792.522, Training Time: 493 seconds)
Epoch:  14/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 24725.730, Training Time: 63 seconds), Stats for epoch: (Training Loss: 40085.843, Training Time: 557 seconds)
Epoch:  14/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 24695.817, Training Time: 65 seconds), Stats for epoch: (Training Loss: 38686.750, Training Time: 622 seconds)
Epoch:  14/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 23868.109, Training Time: 65 seconds), Stats for epoch: (Training Loss: 37451.863, Training Time: 688 seconds)
Epoch:  14/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 27892.539, Training Time: 9 seconds), Stats for epoch: (Training Loss: 37341.624, Training Time: 697 seconds)
Epoch:  14/100, Validation loss: 39312.085, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.936 to  1.931
Epoch:  15/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 46206.590, Training Time: 49 seconds), Stats for epoch: (Training Loss: 46206.590, Training Time: 49 seconds)
Epoch:  15/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 52059.594, Training Time: 51 seconds), Stats for epoch: (Training Loss: 49133.092, Training Time: 100 seconds)
Epoch:  15/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 49793.428, Training Time: 52 seconds), Stats for epoch: (Training Loss: 49353.204, Training Time: 152 seconds)
Epoch:  15/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 47609.353, Training Time: 53 seconds), Stats for epoch: (Training Loss: 48917.241, Training Time: 206 seconds)
Epoch:  15/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 43838.743, Training Time: 54 seconds), Stats for epoch: (Training Loss: 47901.541, Training Time: 260 seconds)
Epoch:  15/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 41100.236, Training Time: 56 seconds), Stats for epoch: (Training Loss: 46767.990, Training Time: 316 seconds)
Epoch:  15/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 37568.671, Training Time: 57 seconds), Stats for epoch: (Training Loss: 45453.802, Training Time: 374 seconds)
Epoch:  15/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 33863.477, Training Time: 58 seconds), Stats for epoch: (Training Loss: 44005.011, Training Time: 432 seconds)
Epoch:  15/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 30298.757, Training Time: 60 seconds), Stats for epoch: (Training Loss: 42482.094, Training Time: 493 seconds)
Epoch:  15/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 24962.391, Training Time: 63 seconds), Stats for epoch: (Training Loss: 40730.124, Training Time: 557 seconds)
Epoch:  15/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 24394.930, Training Time: 65 seconds), Stats for epoch: (Training Loss: 39245.106, Training Time: 622 seconds)
Epoch:  15/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 21458.494, Training Time: 65 seconds), Stats for epoch: (Training Loss: 37762.889, Training Time: 688 seconds)
Epoch:  15/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 21567.032, Training Time: 9 seconds), Stats for epoch: (Training Loss: 37576.116, Training Time: 697 seconds)
Epoch:  15/100, Validation loss: 36488.619, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.931 to  1.926
Epoch:  16/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 41607.042, Training Time: 49 seconds), Stats for epoch: (Training Loss: 41607.042, Training Time: 49 seconds)
Epoch:  16/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 46908.916, Training Time: 51 seconds), Stats for epoch: (Training Loss: 44257.979, Training Time: 100 seconds)
Epoch:  16/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 44680.562, Training Time: 52 seconds), Stats for epoch: (Training Loss: 44398.840, Training Time: 153 seconds)
Epoch:  16/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 42686.770, Training Time: 53 seconds), Stats for epoch: (Training Loss: 43970.823, Training Time: 206 seconds)
Epoch:  16/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 39092.852, Training Time: 54 seconds), Stats for epoch: (Training Loss: 42995.229, Training Time: 261 seconds)
Epoch:  16/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 36827.081, Training Time: 55 seconds), Stats for epoch: (Training Loss: 41967.204, Training Time: 316 seconds)
Epoch:  16/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 33921.784, Training Time: 57 seconds), Stats for epoch: (Training Loss: 40817.858, Training Time: 374 seconds)
Epoch:  16/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 30898.022, Training Time: 58 seconds), Stats for epoch: (Training Loss: 39577.879, Training Time: 432 seconds)
Epoch:  16/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 27510.492, Training Time: 59 seconds), Stats for epoch: (Training Loss: 38237.058, Training Time: 492 seconds)
Epoch:  16/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 22763.318, Training Time: 62 seconds), Stats for epoch: (Training Loss: 36689.684, Training Time: 555 seconds)
Epoch:  16/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 20895.832, Training Time: 64 seconds), Stats for epoch: (Training Loss: 35253.879, Training Time: 619 seconds)
Epoch:  16/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 20707.327, Training Time: 64 seconds), Stats for epoch: (Training Loss: 34041.667, Training Time: 684 seconds)
Epoch:  16/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 20472.606, Training Time: 8 seconds), Stats for epoch: (Training Loss: 33885.186, Training Time: 692 seconds)
Epoch:  16/100, Validation loss: 34026.140, Batch Validation Time: 52 seconds
Learning rate decay: adjusting from  1.926 to  1.921
Epoch:  17/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 44430.372, Training Time: 49 seconds), Stats for epoch: (Training Loss: 44430.372, Training Time: 49 seconds)
Epoch:  17/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 51718.028, Training Time: 50 seconds), Stats for epoch: (Training Loss: 48074.200, Training Time: 99 seconds)
Epoch:  17/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 49184.336, Training Time: 51 seconds), Stats for epoch: (Training Loss: 48444.245, Training Time: 151 seconds)
Epoch:  17/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 46733.427, Training Time: 52 seconds), Stats for epoch: (Training Loss: 48016.541, Training Time: 204 seconds)
Epoch:  17/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 42768.028, Training Time: 53 seconds), Stats for epoch: (Training Loss: 46966.838, Training Time: 257 seconds)
Epoch:  17/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 39916.252, Training Time: 54 seconds), Stats for epoch: (Training Loss: 45791.741, Training Time: 312 seconds)
Epoch:  17/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 36564.733, Training Time: 56 seconds), Stats for epoch: (Training Loss: 44473.597, Training Time: 368 seconds)
Epoch:  17/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 32765.448, Training Time: 57 seconds), Stats for epoch: (Training Loss: 43010.078, Training Time: 426 seconds)
Epoch:  17/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 28990.715, Training Time: 59 seconds), Stats for epoch: (Training Loss: 41452.371, Training Time: 486 seconds)
Epoch:  17/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 23755.596, Training Time: 62 seconds), Stats for epoch: (Training Loss: 39682.694, Training Time: 548 seconds)
Epoch:  17/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 23540.374, Training Time: 64 seconds), Stats for epoch: (Training Loss: 38215.210, Training Time: 613 seconds)
Epoch:  17/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 22350.703, Training Time: 64 seconds), Stats for epoch: (Training Loss: 36893.168, Training Time: 677 seconds)
Epoch:  17/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 24531.538, Training Time: 8 seconds), Stats for epoch: (Training Loss: 36750.612, Training Time: 686 seconds)
Epoch:  17/100, Validation loss: 38072.906, Batch Validation Time: 52 seconds
Learning rate decay: adjusting from  1.921 to  1.917
Epoch:  18/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 44222.715, Training Time: 48 seconds), Stats for epoch: (Training Loss: 44222.715, Training Time: 48 seconds)
Epoch:  18/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 52290.960, Training Time: 50 seconds), Stats for epoch: (Training Loss: 48256.837, Training Time: 99 seconds)
Epoch:  18/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 50199.244, Training Time: 51 seconds), Stats for epoch: (Training Loss: 48904.306, Training Time: 151 seconds)
Epoch:  18/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 47570.917, Training Time: 52 seconds), Stats for epoch: (Training Loss: 48570.959, Training Time: 204 seconds)
Epoch:  18/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 43521.579, Training Time: 54 seconds), Stats for epoch: (Training Loss: 47561.083, Training Time: 258 seconds)
Epoch:  18/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 40706.673, Training Time: 54 seconds), Stats for epoch: (Training Loss: 46418.681, Training Time: 313 seconds)
Epoch:  18/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 37212.485, Training Time: 56 seconds), Stats for epoch: (Training Loss: 45103.510, Training Time: 369 seconds)
Epoch:  18/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 33177.175, Training Time: 58 seconds), Stats for epoch: (Training Loss: 43612.719, Training Time: 427 seconds)
Epoch:  18/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 29244.499, Training Time: 59 seconds), Stats for epoch: (Training Loss: 42016.250, Training Time: 487 seconds)
Epoch:  18/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 25678.272, Training Time: 62 seconds), Stats for epoch: (Training Loss: 40382.452, Training Time: 549 seconds)
Epoch:  18/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 27674.729, Training Time: 64 seconds), Stats for epoch: (Training Loss: 39227.204, Training Time: 614 seconds)
Epoch:  18/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 26530.848, Training Time: 65 seconds), Stats for epoch: (Training Loss: 38169.175, Training Time: 680 seconds)
Epoch:  18/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 29322.117, Training Time: 9 seconds), Stats for epoch: (Training Loss: 38067.149, Training Time: 689 seconds)
Epoch:  18/100, Validation loss: 42332.708, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.917 to  1.912
Epoch:  19/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 43857.207, Training Time: 48 seconds), Stats for epoch: (Training Loss: 43857.207, Training Time: 48 seconds)
Epoch:  19/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 52879.400, Training Time: 49 seconds), Stats for epoch: (Training Loss: 48368.304, Training Time: 98 seconds)
Epoch:  19/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 51112.046, Training Time: 50 seconds), Stats for epoch: (Training Loss: 49282.885, Training Time: 149 seconds)
Epoch:  19/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 48692.242, Training Time: 52 seconds), Stats for epoch: (Training Loss: 49135.224, Training Time: 201 seconds)
Epoch:  19/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 44475.973, Training Time: 52 seconds), Stats for epoch: (Training Loss: 48203.374, Training Time: 254 seconds)
Epoch:  19/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 41539.592, Training Time: 54 seconds), Stats for epoch: (Training Loss: 47092.743, Training Time: 308 seconds)
Epoch:  19/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 37956.846, Training Time: 55 seconds), Stats for epoch: (Training Loss: 45787.615, Training Time: 364 seconds)
Epoch:  19/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 33529.954, Training Time: 57 seconds), Stats for epoch: (Training Loss: 44255.408, Training Time: 421 seconds)
Epoch:  19/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 29940.620, Training Time: 59 seconds), Stats for epoch: (Training Loss: 42664.876, Training Time: 480 seconds)
Epoch:  19/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 25598.818, Training Time: 61 seconds), Stats for epoch: (Training Loss: 40958.270, Training Time: 542 seconds)
Epoch:  19/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 21809.282, Training Time: 63 seconds), Stats for epoch: (Training Loss: 39217.453, Training Time: 606 seconds)
Epoch:  19/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 24324.340, Training Time: 63 seconds), Stats for epoch: (Training Loss: 37976.360, Training Time: 669 seconds)
Epoch:  19/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 30116.567, Training Time: 8 seconds), Stats for epoch: (Training Loss: 37885.720, Training Time: 678 seconds)
Epoch:  19/100, Validation loss: 41739.167, Batch Validation Time: 51 seconds
Learning rate decay: adjusting from  1.912 to  1.907
Epoch:  20/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 43540.732, Training Time: 48 seconds), Stats for epoch: (Training Loss: 43540.732, Training Time: 48 seconds)
Epoch:  20/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 54023.055, Training Time: 49 seconds), Stats for epoch: (Training Loss: 48781.893, Training Time: 98 seconds)
Epoch:  20/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 52161.960, Training Time: 50 seconds), Stats for epoch: (Training Loss: 49908.582, Training Time: 149 seconds)
Epoch:  20/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 49602.105, Training Time: 52 seconds), Stats for epoch: (Training Loss: 49831.963, Training Time: 201 seconds)
Epoch:  20/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 45247.143, Training Time: 53 seconds), Stats for epoch: (Training Loss: 48914.999, Training Time: 254 seconds)
Epoch:  20/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 42360.880, Training Time: 54 seconds), Stats for epoch: (Training Loss: 47822.646, Training Time: 309 seconds)
Epoch:  20/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 37986.042, Training Time: 55 seconds), Stats for epoch: (Training Loss: 46417.417, Training Time: 364 seconds)
Epoch:  20/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 33923.092, Training Time: 57 seconds), Stats for epoch: (Training Loss: 44855.626, Training Time: 422 seconds)
Epoch:  20/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 30342.746, Training Time: 58 seconds), Stats for epoch: (Training Loss: 43243.084, Training Time: 481 seconds)
Epoch:  20/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 24953.034, Training Time: 61 seconds), Stats for epoch: (Training Loss: 41414.079, Training Time: 542 seconds)
Epoch:  20/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 22279.675, Training Time: 63 seconds), Stats for epoch: (Training Loss: 39674.587, Training Time: 606 seconds)
Epoch:  20/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 23003.293, Training Time: 63 seconds), Stats for epoch: (Training Loss: 38285.313, Training Time: 670 seconds)
Epoch:  20/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 25399.927, Training Time: 8 seconds), Stats for epoch: (Training Loss: 38136.717, Training Time: 679 seconds)
Epoch:  20/100, Validation loss: 39484.520, Batch Validation Time: 51 seconds
Learning rate decay: adjusting from  1.907 to  1.902
Epoch:  21/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 46677.960, Training Time: 48 seconds), Stats for epoch: (Training Loss: 46677.960, Training Time: 48 seconds)
Epoch:  21/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 57455.170, Training Time: 49 seconds), Stats for epoch: (Training Loss: 52066.565, Training Time: 98 seconds)
Epoch:  21/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 55055.622, Training Time: 50 seconds), Stats for epoch: (Training Loss: 53062.917, Training Time: 148 seconds)
Epoch:  21/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 52024.454, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52803.301, Training Time: 200 seconds)
Epoch:  21/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 47084.076, Training Time: 53 seconds), Stats for epoch: (Training Loss: 51659.456, Training Time: 253 seconds)
Epoch:  21/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 43902.369, Training Time: 54 seconds), Stats for epoch: (Training Loss: 50366.608, Training Time: 308 seconds)
Epoch:  21/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 39676.417, Training Time: 55 seconds), Stats for epoch: (Training Loss: 48839.438, Training Time: 364 seconds)
Epoch:  21/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 35135.524, Training Time: 57 seconds), Stats for epoch: (Training Loss: 47126.449, Training Time: 421 seconds)
Epoch:  21/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 31105.239, Training Time: 58 seconds), Stats for epoch: (Training Loss: 45346.315, Training Time: 480 seconds)
Epoch:  21/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 25346.060, Training Time: 61 seconds), Stats for epoch: (Training Loss: 43346.289, Training Time: 541 seconds)
Epoch:  21/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 22072.221, Training Time: 63 seconds), Stats for epoch: (Training Loss: 41412.283, Training Time: 605 seconds)
Epoch:  21/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 26813.255, Training Time: 63 seconds), Stats for epoch: (Training Loss: 40195.697, Training Time: 669 seconds)
Epoch:  21/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 27937.413, Training Time: 8 seconds), Stats for epoch: (Training Loss: 40054.333, Training Time: 678 seconds)
Epoch:  21/100, Validation loss: 42898.802, Batch Validation Time: 51 seconds
Learning rate decay: adjusting from  1.902 to  1.898
Epoch:  22/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 47249.134, Training Time: 48 seconds), Stats for epoch: (Training Loss: 47249.134, Training Time: 48 seconds)
Epoch:  22/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 57295.756, Training Time: 49 seconds), Stats for epoch: (Training Loss: 52272.445, Training Time: 98 seconds)
Epoch:  22/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 55171.005, Training Time: 51 seconds), Stats for epoch: (Training Loss: 53238.632, Training Time: 149 seconds)
Epoch:  22/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 52469.183, Training Time: 53 seconds), Stats for epoch: (Training Loss: 53046.270, Training Time: 203 seconds)
Epoch:  22/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 47986.612, Training Time: 54 seconds), Stats for epoch: (Training Loss: 52034.338, Training Time: 257 seconds)
Epoch:  22/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 44638.528, Training Time: 55 seconds), Stats for epoch: (Training Loss: 50801.703, Training Time: 313 seconds)
Epoch:  22/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 39639.621, Training Time: 57 seconds), Stats for epoch: (Training Loss: 49207.120, Training Time: 371 seconds)
Epoch:  22/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 34793.757, Training Time: 58 seconds), Stats for epoch: (Training Loss: 47405.449, Training Time: 429 seconds)
Epoch:  22/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 31279.705, Training Time: 60 seconds), Stats for epoch: (Training Loss: 45613.700, Training Time: 490 seconds)
Epoch:  22/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 25999.795, Training Time: 63 seconds), Stats for epoch: (Training Loss: 43652.310, Training Time: 554 seconds)
Epoch:  22/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 24786.823, Training Time: 65 seconds), Stats for epoch: (Training Loss: 41937.265, Training Time: 619 seconds)
Epoch:  22/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 27843.097, Training Time: 65 seconds), Stats for epoch: (Training Loss: 40762.751, Training Time: 685 seconds)
Epoch:  22/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 33660.436, Training Time: 9 seconds), Stats for epoch: (Training Loss: 40680.846, Training Time: 694 seconds)
Epoch:  22/100, Validation loss: 45622.209, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.898 to  1.893
Epoch:  23/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 46240.071, Training Time: 49 seconds), Stats for epoch: (Training Loss: 46240.071, Training Time: 49 seconds)
Epoch:  23/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 57103.572, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51671.821, Training Time: 100 seconds)
Epoch:  23/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 55370.362, Training Time: 52 seconds), Stats for epoch: (Training Loss: 52904.668, Training Time: 152 seconds)
Epoch:  23/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 52471.308, Training Time: 53 seconds), Stats for epoch: (Training Loss: 52796.328, Training Time: 206 seconds)
Epoch:  23/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 47244.855, Training Time: 54 seconds), Stats for epoch: (Training Loss: 51686.034, Training Time: 260 seconds)
Epoch:  23/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 44070.958, Training Time: 55 seconds), Stats for epoch: (Training Loss: 50416.854, Training Time: 316 seconds)
Epoch:  23/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 40016.185, Training Time: 57 seconds), Stats for epoch: (Training Loss: 48931.044, Training Time: 373 seconds)
Epoch:  23/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 35230.956, Training Time: 58 seconds), Stats for epoch: (Training Loss: 47218.533, Training Time: 432 seconds)
Epoch:  23/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 30704.694, Training Time: 60 seconds), Stats for epoch: (Training Loss: 45383.662, Training Time: 493 seconds)
Epoch:  23/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 27348.082, Training Time: 63 seconds), Stats for epoch: (Training Loss: 43580.104, Training Time: 557 seconds)
Epoch:  23/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 27669.280, Training Time: 65 seconds), Stats for epoch: (Training Loss: 42133.666, Training Time: 622 seconds)
Epoch:  23/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 25516.127, Training Time: 65 seconds), Stats for epoch: (Training Loss: 40748.871, Training Time: 688 seconds)
Epoch:  23/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 28071.689, Training Time: 9 seconds), Stats for epoch: (Training Loss: 40602.676, Training Time: 697 seconds)
Epoch:  23/100, Validation loss: 43324.583, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.893 to  1.888
Epoch:  24/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 45595.924, Training Time: 49 seconds), Stats for epoch: (Training Loss: 45595.924, Training Time: 49 seconds)
Epoch:  24/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 58187.632, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51891.778, Training Time: 100 seconds)
Epoch:  24/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 56424.748, Training Time: 52 seconds), Stats for epoch: (Training Loss: 53402.768, Training Time: 152 seconds)
Epoch:  24/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 53567.530, Training Time: 53 seconds), Stats for epoch: (Training Loss: 53443.958, Training Time: 206 seconds)
Epoch:  24/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 48322.686, Training Time: 54 seconds), Stats for epoch: (Training Loss: 52419.704, Training Time: 260 seconds)
Epoch:  24/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 45005.278, Training Time: 55 seconds), Stats for epoch: (Training Loss: 51183.966, Training Time: 316 seconds)
Epoch:  24/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 40556.048, Training Time: 57 seconds), Stats for epoch: (Training Loss: 49665.692, Training Time: 374 seconds)
Epoch:  24/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 36278.927, Training Time: 58 seconds), Stats for epoch: (Training Loss: 47992.347, Training Time: 432 seconds)
Epoch:  24/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 32627.503, Training Time: 60 seconds), Stats for epoch: (Training Loss: 46285.142, Training Time: 493 seconds)
Epoch:  24/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 27728.159, Training Time: 63 seconds), Stats for epoch: (Training Loss: 44429.443, Training Time: 557 seconds)
Epoch:  24/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 22342.343, Training Time: 65 seconds), Stats for epoch: (Training Loss: 42421.525, Training Time: 622 seconds)
Epoch:  24/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 23363.802, Training Time: 65 seconds), Stats for epoch: (Training Loss: 40833.382, Training Time: 688 seconds)
Epoch:  24/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 24377.796, Training Time: 9 seconds), Stats for epoch: (Training Loss: 40643.614, Training Time: 697 seconds)
Epoch:  24/100, Validation loss: 42742.486, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.888 to  1.883
Epoch:  25/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 46626.872, Training Time: 49 seconds), Stats for epoch: (Training Loss: 46626.872, Training Time: 49 seconds)
Epoch:  25/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 59213.974, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52920.423, Training Time: 100 seconds)
Epoch:  25/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 57259.838, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54366.894, Training Time: 152 seconds)
Epoch:  25/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 54237.399, Training Time: 53 seconds), Stats for epoch: (Training Loss: 54334.521, Training Time: 206 seconds)
Epoch:  25/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 48849.601, Training Time: 54 seconds), Stats for epoch: (Training Loss: 53237.537, Training Time: 260 seconds)
Epoch:  25/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 45625.567, Training Time: 55 seconds), Stats for epoch: (Training Loss: 51968.875, Training Time: 316 seconds)
Epoch:  25/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 40750.844, Training Time: 57 seconds), Stats for epoch: (Training Loss: 50366.299, Training Time: 374 seconds)
Epoch:  25/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 36239.323, Training Time: 58 seconds), Stats for epoch: (Training Loss: 48600.427, Training Time: 432 seconds)
Epoch:  25/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 32191.799, Training Time: 60 seconds), Stats for epoch: (Training Loss: 46777.246, Training Time: 493 seconds)
Epoch:  25/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 26574.376, Training Time: 63 seconds), Stats for epoch: (Training Loss: 44756.959, Training Time: 557 seconds)
Epoch:  25/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 24912.689, Training Time: 65 seconds), Stats for epoch: (Training Loss: 42952.935, Training Time: 622 seconds)
Epoch:  25/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 24667.143, Training Time: 65 seconds), Stats for epoch: (Training Loss: 41429.119, Training Time: 688 seconds)
Epoch:  25/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 27609.503, Training Time: 9 seconds), Stats for epoch: (Training Loss: 41269.749, Training Time: 697 seconds)
Epoch:  25/100, Validation loss: 43435.411, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.883 to  1.879
Epoch:  26/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 46011.190, Training Time: 49 seconds), Stats for epoch: (Training Loss: 46011.190, Training Time: 49 seconds)
Epoch:  26/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 59120.399, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52565.794, Training Time: 100 seconds)
Epoch:  26/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 57722.231, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54284.606, Training Time: 152 seconds)
Epoch:  26/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 54661.576, Training Time: 53 seconds), Stats for epoch: (Training Loss: 54378.849, Training Time: 206 seconds)
Epoch:  26/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 48504.447, Training Time: 54 seconds), Stats for epoch: (Training Loss: 53203.968, Training Time: 260 seconds)
Epoch:  26/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 44545.199, Training Time: 55 seconds), Stats for epoch: (Training Loss: 51760.840, Training Time: 316 seconds)
Epoch:  26/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 39994.233, Training Time: 57 seconds), Stats for epoch: (Training Loss: 50079.896, Training Time: 373 seconds)
Epoch:  26/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 35704.878, Training Time: 58 seconds), Stats for epoch: (Training Loss: 48283.019, Training Time: 432 seconds)
Epoch:  26/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 31184.268, Training Time: 60 seconds), Stats for epoch: (Training Loss: 46383.158, Training Time: 493 seconds)
Epoch:  26/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 28148.200, Training Time: 63 seconds), Stats for epoch: (Training Loss: 44559.662, Training Time: 557 seconds)
Epoch:  26/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 25610.565, Training Time: 65 seconds), Stats for epoch: (Training Loss: 42837.017, Training Time: 622 seconds)
Epoch:  26/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 28189.481, Training Time: 65 seconds), Stats for epoch: (Training Loss: 41616.389, Training Time: 688 seconds)
Epoch:  26/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 28198.050, Training Time: 9 seconds), Stats for epoch: (Training Loss: 41461.647, Training Time: 697 seconds)
Epoch:  26/100, Validation loss: 42808.357, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.879 to  1.874
Epoch:  27/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 44632.074, Training Time: 49 seconds), Stats for epoch: (Training Loss: 44632.074, Training Time: 49 seconds)
Epoch:  27/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 59274.479, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51953.277, Training Time: 100 seconds)
Epoch:  27/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 57497.029, Training Time: 52 seconds), Stats for epoch: (Training Loss: 53801.194, Training Time: 152 seconds)
Epoch:  27/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 54220.195, Training Time: 53 seconds), Stats for epoch: (Training Loss: 53905.945, Training Time: 206 seconds)
Epoch:  27/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 49008.377, Training Time: 54 seconds), Stats for epoch: (Training Loss: 52926.431, Training Time: 260 seconds)
Epoch:  27/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 46095.977, Training Time: 55 seconds), Stats for epoch: (Training Loss: 51788.022, Training Time: 316 seconds)
Epoch:  27/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 41565.342, Training Time: 57 seconds), Stats for epoch: (Training Loss: 50327.639, Training Time: 374 seconds)
Epoch:  27/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 36925.537, Training Time: 58 seconds), Stats for epoch: (Training Loss: 48652.376, Training Time: 432 seconds)
Epoch:  27/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 32897.838, Training Time: 60 seconds), Stats for epoch: (Training Loss: 46901.872, Training Time: 493 seconds)
Epoch:  27/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 27044.862, Training Time: 63 seconds), Stats for epoch: (Training Loss: 44916.171, Training Time: 557 seconds)
Epoch:  27/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 24316.466, Training Time: 65 seconds), Stats for epoch: (Training Loss: 43043.471, Training Time: 622 seconds)
Epoch:  27/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 30179.363, Training Time: 65 seconds), Stats for epoch: (Training Loss: 41971.462, Training Time: 688 seconds)
Epoch:  27/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 32870.654, Training Time: 9 seconds), Stats for epoch: (Training Loss: 41866.510, Training Time: 697 seconds)
Epoch:  27/100, Validation loss: 46312.837, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.874 to  1.869
Epoch:  28/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 45483.331, Training Time: 49 seconds), Stats for epoch: (Training Loss: 45483.331, Training Time: 49 seconds)
Epoch:  28/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 60957.458, Training Time: 51 seconds), Stats for epoch: (Training Loss: 53220.395, Training Time: 100 seconds)
Epoch:  28/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 59701.454, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55380.748, Training Time: 153 seconds)
Epoch:  28/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 56384.337, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55631.645, Training Time: 206 seconds)
Epoch:  28/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 50336.555, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54572.627, Training Time: 260 seconds)
Epoch:  28/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 47071.397, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53322.422, Training Time: 316 seconds)
Epoch:  28/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 42696.089, Training Time: 57 seconds), Stats for epoch: (Training Loss: 51804.374, Training Time: 374 seconds)
Epoch:  28/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 37909.028, Training Time: 58 seconds), Stats for epoch: (Training Loss: 50067.456, Training Time: 432 seconds)
Epoch:  28/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 33519.721, Training Time: 60 seconds), Stats for epoch: (Training Loss: 48228.819, Training Time: 493 seconds)
Epoch:  28/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 28722.986, Training Time: 63 seconds), Stats for epoch: (Training Loss: 46278.235, Training Time: 557 seconds)
Epoch:  28/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 27190.414, Training Time: 65 seconds), Stats for epoch: (Training Loss: 44542.979, Training Time: 622 seconds)
Epoch:  28/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 27226.299, Training Time: 65 seconds), Stats for epoch: (Training Loss: 43099.922, Training Time: 688 seconds)
Epoch:  28/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 29520.225, Training Time: 9 seconds), Stats for epoch: (Training Loss: 42943.320, Training Time: 697 seconds)
Epoch:  28/100, Validation loss: 43965.293, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.869 to  1.865
Epoch:  29/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 43278.896, Training Time: 49 seconds), Stats for epoch: (Training Loss: 43278.896, Training Time: 49 seconds)
Epoch:  29/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 58460.229, Training Time: 51 seconds), Stats for epoch: (Training Loss: 50869.563, Training Time: 100 seconds)
Epoch:  29/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 56800.908, Training Time: 52 seconds), Stats for epoch: (Training Loss: 52846.678, Training Time: 152 seconds)
Epoch:  29/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 53349.919, Training Time: 53 seconds), Stats for epoch: (Training Loss: 52972.488, Training Time: 206 seconds)
Epoch:  29/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 47934.239, Training Time: 54 seconds), Stats for epoch: (Training Loss: 51964.838, Training Time: 260 seconds)
Epoch:  29/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 44555.254, Training Time: 55 seconds), Stats for epoch: (Training Loss: 50729.908, Training Time: 316 seconds)
Epoch:  29/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 40032.850, Training Time: 57 seconds), Stats for epoch: (Training Loss: 49201.756, Training Time: 373 seconds)
Epoch:  29/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 35592.566, Training Time: 58 seconds), Stats for epoch: (Training Loss: 47500.608, Training Time: 432 seconds)
Epoch:  29/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 32028.068, Training Time: 60 seconds), Stats for epoch: (Training Loss: 45781.437, Training Time: 493 seconds)
Epoch:  29/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 29134.452, Training Time: 63 seconds), Stats for epoch: (Training Loss: 44116.738, Training Time: 557 seconds)
Epoch:  29/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 28905.902, Training Time: 65 seconds), Stats for epoch: (Training Loss: 42733.935, Training Time: 622 seconds)
Epoch:  29/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 29222.320, Training Time: 65 seconds), Stats for epoch: (Training Loss: 41607.967, Training Time: 688 seconds)
Epoch:  29/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 34624.548, Training Time: 9 seconds), Stats for epoch: (Training Loss: 41527.433, Training Time: 697 seconds)
Epoch:  29/100, Validation loss: 46059.533, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.865 to  1.860
Epoch:  30/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 44265.675, Training Time: 49 seconds), Stats for epoch: (Training Loss: 44265.675, Training Time: 49 seconds)
Epoch:  30/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 61568.877, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52917.276, Training Time: 100 seconds)
Epoch:  30/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 59844.812, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55226.455, Training Time: 153 seconds)
Epoch:  30/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 56118.293, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55449.414, Training Time: 206 seconds)
Epoch:  30/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 50211.305, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54401.792, Training Time: 260 seconds)
Epoch:  30/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 46662.259, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53111.870, Training Time: 316 seconds)
Epoch:  30/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 42126.046, Training Time: 57 seconds), Stats for epoch: (Training Loss: 51542.467, Training Time: 374 seconds)
Epoch:  30/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 37641.894, Training Time: 58 seconds), Stats for epoch: (Training Loss: 49804.895, Training Time: 432 seconds)
Epoch:  30/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 34996.387, Training Time: 60 seconds), Stats for epoch: (Training Loss: 48159.505, Training Time: 493 seconds)
Epoch:  30/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 31297.137, Training Time: 63 seconds), Stats for epoch: (Training Loss: 46473.268, Training Time: 557 seconds)
Epoch:  30/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 30449.999, Training Time: 65 seconds), Stats for epoch: (Training Loss: 45016.608, Training Time: 622 seconds)
Epoch:  30/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 32811.011, Training Time: 65 seconds), Stats for epoch: (Training Loss: 43999.475, Training Time: 688 seconds)
Epoch:  30/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 40506.340, Training Time: 9 seconds), Stats for epoch: (Training Loss: 43959.191, Training Time: 697 seconds)
Epoch:  30/100, Validation loss: 52141.559, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.860 to  1.855
Epoch:  31/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 43177.708, Training Time: 49 seconds), Stats for epoch: (Training Loss: 43177.708, Training Time: 49 seconds)
Epoch:  31/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 60751.631, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51964.669, Training Time: 100 seconds)
Epoch:  31/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 59887.416, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54605.585, Training Time: 153 seconds)
Epoch:  31/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 56364.083, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55045.209, Training Time: 206 seconds)
Epoch:  31/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 51254.734, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54287.114, Training Time: 260 seconds)
Epoch:  31/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 48139.928, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53262.583, Training Time: 316 seconds)
Epoch:  31/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 43962.441, Training Time: 57 seconds), Stats for epoch: (Training Loss: 51933.991, Training Time: 374 seconds)
Epoch:  31/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 39873.961, Training Time: 58 seconds), Stats for epoch: (Training Loss: 50426.488, Training Time: 432 seconds)
Epoch:  31/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 37686.874, Training Time: 60 seconds), Stats for epoch: (Training Loss: 49010.975, Training Time: 493 seconds)
Epoch:  31/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 34852.707, Training Time: 63 seconds), Stats for epoch: (Training Loss: 47595.148, Training Time: 557 seconds)
Epoch:  31/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 35959.942, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46537.402, Training Time: 622 seconds)
Epoch:  31/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 38016.896, Training Time: 65 seconds), Stats for epoch: (Training Loss: 45827.360, Training Time: 688 seconds)
Epoch:  31/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 41445.292, Training Time: 9 seconds), Stats for epoch: (Training Loss: 45776.826, Training Time: 697 seconds)
Epoch:  31/100, Validation loss: 53396.316, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.855 to  1.851
Epoch:  32/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 43884.311, Training Time: 49 seconds), Stats for epoch: (Training Loss: 43884.311, Training Time: 49 seconds)
Epoch:  32/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 62885.050, Training Time: 51 seconds), Stats for epoch: (Training Loss: 53384.681, Training Time: 100 seconds)
Epoch:  32/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62557.628, Training Time: 52 seconds), Stats for epoch: (Training Loss: 56442.330, Training Time: 152 seconds)
Epoch:  32/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 59378.086, Training Time: 53 seconds), Stats for epoch: (Training Loss: 57176.269, Training Time: 206 seconds)
Epoch:  32/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 54319.700, Training Time: 54 seconds), Stats for epoch: (Training Loss: 56604.955, Training Time: 260 seconds)
Epoch:  32/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 50989.023, Training Time: 55 seconds), Stats for epoch: (Training Loss: 55668.966, Training Time: 316 seconds)
Epoch:  32/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 45861.397, Training Time: 57 seconds), Stats for epoch: (Training Loss: 54267.885, Training Time: 373 seconds)
Epoch:  32/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 41207.008, Training Time: 58 seconds), Stats for epoch: (Training Loss: 52635.275, Training Time: 432 seconds)
Epoch:  32/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 37987.048, Training Time: 60 seconds), Stats for epoch: (Training Loss: 51007.695, Training Time: 493 seconds)
Epoch:  32/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 35379.196, Training Time: 63 seconds), Stats for epoch: (Training Loss: 49444.845, Training Time: 556 seconds)
Epoch:  32/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 38034.133, Training Time: 65 seconds), Stats for epoch: (Training Loss: 48407.507, Training Time: 622 seconds)
Epoch:  32/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 38217.807, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47558.366, Training Time: 688 seconds)
Epoch:  32/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 39728.778, Training Time: 9 seconds), Stats for epoch: (Training Loss: 47468.074, Training Time: 697 seconds)
Epoch:  32/100, Validation loss: 50949.191, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.851 to  1.846
Epoch:  33/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 43979.042, Training Time: 49 seconds), Stats for epoch: (Training Loss: 43979.042, Training Time: 49 seconds)
Epoch:  33/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63676.240, Training Time: 51 seconds), Stats for epoch: (Training Loss: 53827.641, Training Time: 100 seconds)
Epoch:  33/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62333.734, Training Time: 52 seconds), Stats for epoch: (Training Loss: 56663.006, Training Time: 152 seconds)
Epoch:  33/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 58617.722, Training Time: 53 seconds), Stats for epoch: (Training Loss: 57151.685, Training Time: 206 seconds)
Epoch:  33/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 53610.228, Training Time: 54 seconds), Stats for epoch: (Training Loss: 56443.393, Training Time: 260 seconds)
Epoch:  33/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 50639.832, Training Time: 55 seconds), Stats for epoch: (Training Loss: 55476.133, Training Time: 316 seconds)
Epoch:  33/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 46198.208, Training Time: 57 seconds), Stats for epoch: (Training Loss: 54150.715, Training Time: 373 seconds)
Epoch:  33/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 42940.235, Training Time: 58 seconds), Stats for epoch: (Training Loss: 52749.405, Training Time: 432 seconds)
Epoch:  33/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 38269.984, Training Time: 60 seconds), Stats for epoch: (Training Loss: 51140.581, Training Time: 493 seconds)
Epoch:  33/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 33556.372, Training Time: 63 seconds), Stats for epoch: (Training Loss: 49382.160, Training Time: 556 seconds)
Epoch:  33/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 31451.446, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47752.095, Training Time: 622 seconds)
Epoch:  33/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 32578.489, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46487.628, Training Time: 687 seconds)
Epoch:  33/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 36558.730, Training Time: 9 seconds), Stats for epoch: (Training Loss: 46373.126, Training Time: 697 seconds)
Epoch:  33/100, Validation loss: 49629.698, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.846 to  1.841
Epoch:  34/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 42044.225, Training Time: 49 seconds), Stats for epoch: (Training Loss: 42044.225, Training Time: 49 seconds)
Epoch:  34/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 60895.421, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51469.823, Training Time: 100 seconds)
Epoch:  34/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 59148.616, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54029.421, Training Time: 153 seconds)
Epoch:  34/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 54959.246, Training Time: 53 seconds), Stats for epoch: (Training Loss: 54261.877, Training Time: 206 seconds)
Epoch:  34/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 49486.312, Training Time: 54 seconds), Stats for epoch: (Training Loss: 53306.764, Training Time: 260 seconds)
Epoch:  34/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 46347.135, Training Time: 55 seconds), Stats for epoch: (Training Loss: 52146.826, Training Time: 316 seconds)
Epoch:  34/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 41938.074, Training Time: 57 seconds), Stats for epoch: (Training Loss: 50688.433, Training Time: 373 seconds)
Epoch:  34/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 39236.190, Training Time: 58 seconds), Stats for epoch: (Training Loss: 49256.902, Training Time: 432 seconds)
Epoch:  34/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 36971.895, Training Time: 60 seconds), Stats for epoch: (Training Loss: 47891.902, Training Time: 493 seconds)
Epoch:  34/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 36077.547, Training Time: 63 seconds), Stats for epoch: (Training Loss: 46710.466, Training Time: 557 seconds)
Epoch:  34/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 37283.610, Training Time: 65 seconds), Stats for epoch: (Training Loss: 45853.479, Training Time: 622 seconds)
Epoch:  34/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 40423.637, Training Time: 65 seconds), Stats for epoch: (Training Loss: 45400.992, Training Time: 688 seconds)
Epoch:  34/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 43473.815, Training Time: 9 seconds), Stats for epoch: (Training Loss: 45378.768, Training Time: 697 seconds)
Epoch:  34/100, Validation loss: 54067.830, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.841 to  1.837
Epoch:  35/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 42510.848, Training Time: 49 seconds), Stats for epoch: (Training Loss: 42510.848, Training Time: 49 seconds)
Epoch:  35/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63043.635, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52777.242, Training Time: 100 seconds)
Epoch:  35/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62050.377, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55868.287, Training Time: 152 seconds)
Epoch:  35/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 58579.212, Training Time: 53 seconds), Stats for epoch: (Training Loss: 56546.018, Training Time: 206 seconds)
Epoch:  35/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 53164.212, Training Time: 54 seconds), Stats for epoch: (Training Loss: 55869.657, Training Time: 260 seconds)
Epoch:  35/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 49882.529, Training Time: 55 seconds), Stats for epoch: (Training Loss: 54871.802, Training Time: 316 seconds)
Epoch:  35/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 46211.174, Training Time: 57 seconds), Stats for epoch: (Training Loss: 53634.569, Training Time: 373 seconds)
Epoch:  35/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 43002.935, Training Time: 58 seconds), Stats for epoch: (Training Loss: 52305.615, Training Time: 432 seconds)
Epoch:  35/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 39131.795, Training Time: 60 seconds), Stats for epoch: (Training Loss: 50841.857, Training Time: 493 seconds)
Epoch:  35/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 33255.141, Training Time: 63 seconds), Stats for epoch: (Training Loss: 49083.186, Training Time: 557 seconds)
Epoch:  35/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 30720.508, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47413.851, Training Time: 622 seconds)
Epoch:  35/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 33257.676, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46234.170, Training Time: 688 seconds)
Epoch:  35/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 36251.340, Training Time: 9 seconds), Stats for epoch: (Training Loss: 46119.047, Training Time: 697 seconds)
Epoch:  35/100, Validation loss: 48675.117, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.837 to  1.832
Epoch:  36/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 41519.813, Training Time: 49 seconds), Stats for epoch: (Training Loss: 41519.813, Training Time: 49 seconds)
Epoch:  36/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 62223.212, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51871.512, Training Time: 100 seconds)
Epoch:  36/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 60582.217, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54775.081, Training Time: 152 seconds)
Epoch:  36/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 56512.974, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55209.554, Training Time: 206 seconds)
Epoch:  36/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 50832.612, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54334.166, Training Time: 260 seconds)
Epoch:  36/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 48124.671, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53299.250, Training Time: 316 seconds)
Epoch:  36/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 44231.972, Training Time: 57 seconds), Stats for epoch: (Training Loss: 52003.925, Training Time: 373 seconds)
Epoch:  36/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 40169.991, Training Time: 58 seconds), Stats for epoch: (Training Loss: 50524.683, Training Time: 432 seconds)
Epoch:  36/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 37209.043, Training Time: 60 seconds), Stats for epoch: (Training Loss: 49045.167, Training Time: 493 seconds)
Epoch:  36/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 32570.329, Training Time: 63 seconds), Stats for epoch: (Training Loss: 47397.684, Training Time: 556 seconds)
Epoch:  36/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 32663.341, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46058.198, Training Time: 622 seconds)
Epoch:  36/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 39005.886, Training Time: 65 seconds), Stats for epoch: (Training Loss: 45470.505, Training Time: 687 seconds)
Epoch:  36/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 42514.096, Training Time: 9 seconds), Stats for epoch: (Training Loss: 45436.412, Training Time: 696 seconds)
Epoch:  36/100, Validation loss: 54036.726, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.832 to  1.828
Epoch:  37/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 41467.786, Training Time: 49 seconds), Stats for epoch: (Training Loss: 41467.786, Training Time: 49 seconds)
Epoch:  37/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 62819.873, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52143.830, Training Time: 100 seconds)
Epoch:  37/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 61958.437, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55415.366, Training Time: 152 seconds)
Epoch:  37/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 57985.477, Training Time: 53 seconds), Stats for epoch: (Training Loss: 56057.893, Training Time: 206 seconds)
Epoch:  37/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 52513.040, Training Time: 54 seconds), Stats for epoch: (Training Loss: 55348.923, Training Time: 260 seconds)
Epoch:  37/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 49017.147, Training Time: 55 seconds), Stats for epoch: (Training Loss: 54293.627, Training Time: 316 seconds)
Epoch:  37/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 44230.209, Training Time: 57 seconds), Stats for epoch: (Training Loss: 52855.996, Training Time: 373 seconds)
Epoch:  37/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 40853.308, Training Time: 58 seconds), Stats for epoch: (Training Loss: 51355.660, Training Time: 432 seconds)
Epoch:  37/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 38096.458, Training Time: 60 seconds), Stats for epoch: (Training Loss: 49882.415, Training Time: 493 seconds)
Epoch:  37/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 36435.348, Training Time: 63 seconds), Stats for epoch: (Training Loss: 48537.708, Training Time: 556 seconds)
Epoch:  37/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 38103.433, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47589.138, Training Time: 622 seconds)
Epoch:  37/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 43442.705, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47243.602, Training Time: 687 seconds)
Epoch:  37/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 47930.332, Training Time: 9 seconds), Stats for epoch: (Training Loss: 47251.521, Training Time: 697 seconds)
Epoch:  37/100, Validation loss: 59362.266, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.828 to  1.823
Epoch:  38/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 42548.129, Training Time: 49 seconds), Stats for epoch: (Training Loss: 42548.129, Training Time: 49 seconds)
Epoch:  38/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64559.391, Training Time: 51 seconds), Stats for epoch: (Training Loss: 53553.760, Training Time: 100 seconds)
Epoch:  38/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 64327.096, Training Time: 52 seconds), Stats for epoch: (Training Loss: 57144.872, Training Time: 152 seconds)
Epoch:  38/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 61183.164, Training Time: 53 seconds), Stats for epoch: (Training Loss: 58154.445, Training Time: 206 seconds)
Epoch:  38/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 56113.883, Training Time: 54 seconds), Stats for epoch: (Training Loss: 57746.333, Training Time: 260 seconds)
Epoch:  38/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 52962.605, Training Time: 55 seconds), Stats for epoch: (Training Loss: 56949.045, Training Time: 316 seconds)
Epoch:  38/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 47566.133, Training Time: 57 seconds), Stats for epoch: (Training Loss: 55608.629, Training Time: 373 seconds)
Epoch:  38/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 44987.366, Training Time: 58 seconds), Stats for epoch: (Training Loss: 54280.971, Training Time: 432 seconds)
Epoch:  38/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 42563.182, Training Time: 60 seconds), Stats for epoch: (Training Loss: 52978.994, Training Time: 493 seconds)
Epoch:  38/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 42557.515, Training Time: 63 seconds), Stats for epoch: (Training Loss: 51936.846, Training Time: 556 seconds)
Epoch:  38/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 43619.135, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51180.691, Training Time: 622 seconds)
Epoch:  38/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 44469.371, Training Time: 65 seconds), Stats for epoch: (Training Loss: 50621.414, Training Time: 687 seconds)
Epoch:  38/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 49136.915, Training Time: 9 seconds), Stats for epoch: (Training Loss: 50604.295, Training Time: 697 seconds)
Epoch:  38/100, Validation loss: 60452.062, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.823 to  1.819
Epoch:  39/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 42085.776, Training Time: 49 seconds), Stats for epoch: (Training Loss: 42085.776, Training Time: 49 seconds)
Epoch:  39/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64702.844, Training Time: 51 seconds), Stats for epoch: (Training Loss: 53394.310, Training Time: 100 seconds)
Epoch:  39/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 65182.307, Training Time: 52 seconds), Stats for epoch: (Training Loss: 57323.642, Training Time: 152 seconds)
Epoch:  39/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 61614.732, Training Time: 53 seconds), Stats for epoch: (Training Loss: 58396.415, Training Time: 206 seconds)
Epoch:  39/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 56564.538, Training Time: 54 seconds), Stats for epoch: (Training Loss: 58030.039, Training Time: 260 seconds)
Epoch:  39/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 53912.874, Training Time: 55 seconds), Stats for epoch: (Training Loss: 57343.845, Training Time: 316 seconds)
Epoch:  39/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 49255.074, Training Time: 57 seconds), Stats for epoch: (Training Loss: 56188.306, Training Time: 374 seconds)
Epoch:  39/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 46066.040, Training Time: 58 seconds), Stats for epoch: (Training Loss: 54923.023, Training Time: 432 seconds)
Epoch:  39/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 43773.416, Training Time: 60 seconds), Stats for epoch: (Training Loss: 53684.178, Training Time: 493 seconds)
Epoch:  39/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 42715.414, Training Time: 63 seconds), Stats for epoch: (Training Loss: 52587.301, Training Time: 557 seconds)
Epoch:  39/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 46279.612, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52013.875, Training Time: 622 seconds)
Epoch:  39/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 48290.499, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51703.594, Training Time: 688 seconds)
Epoch:  39/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 50975.053, Training Time: 9 seconds), Stats for epoch: (Training Loss: 51695.192, Training Time: 697 seconds)
Epoch:  39/100, Validation loss: 61974.337, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.819 to  1.814
Epoch:  40/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 42372.990, Training Time: 49 seconds), Stats for epoch: (Training Loss: 42372.990, Training Time: 49 seconds)
Epoch:  40/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 66016.775, Training Time: 51 seconds), Stats for epoch: (Training Loss: 54194.883, Training Time: 100 seconds)
Epoch:  40/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 66359.913, Training Time: 52 seconds), Stats for epoch: (Training Loss: 58249.893, Training Time: 152 seconds)
Epoch:  40/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 63580.005, Training Time: 53 seconds), Stats for epoch: (Training Loss: 59582.421, Training Time: 206 seconds)
Epoch:  40/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 58895.069, Training Time: 54 seconds), Stats for epoch: (Training Loss: 59444.950, Training Time: 260 seconds)
Epoch:  40/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 56514.659, Training Time: 55 seconds), Stats for epoch: (Training Loss: 58956.569, Training Time: 316 seconds)
Epoch:  40/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 51820.770, Training Time: 57 seconds), Stats for epoch: (Training Loss: 57937.169, Training Time: 373 seconds)
Epoch:  40/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 47510.129, Training Time: 58 seconds), Stats for epoch: (Training Loss: 56633.789, Training Time: 432 seconds)
Epoch:  40/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 45588.914, Training Time: 60 seconds), Stats for epoch: (Training Loss: 55406.581, Training Time: 493 seconds)
Epoch:  40/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 43252.476, Training Time: 63 seconds), Stats for epoch: (Training Loss: 54191.170, Training Time: 557 seconds)
Epoch:  40/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 42798.272, Training Time: 65 seconds), Stats for epoch: (Training Loss: 53155.452, Training Time: 622 seconds)
Epoch:  40/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 44062.214, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52397.682, Training Time: 688 seconds)
Epoch:  40/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 46949.248, Training Time: 9 seconds), Stats for epoch: (Training Loss: 52334.850, Training Time: 697 seconds)
Epoch:  40/100, Validation loss: 58921.211, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.814 to  1.809
Epoch:  41/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 40182.510, Training Time: 49 seconds), Stats for epoch: (Training Loss: 40182.510, Training Time: 49 seconds)
Epoch:  41/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63114.083, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51648.297, Training Time: 100 seconds)
Epoch:  41/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 63559.836, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55618.810, Training Time: 153 seconds)
Epoch:  41/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 60584.306, Training Time: 53 seconds), Stats for epoch: (Training Loss: 56860.184, Training Time: 206 seconds)
Epoch:  41/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 55782.495, Training Time: 54 seconds), Stats for epoch: (Training Loss: 56644.646, Training Time: 261 seconds)
Epoch:  41/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 53518.168, Training Time: 55 seconds), Stats for epoch: (Training Loss: 56123.567, Training Time: 316 seconds)
Epoch:  41/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 49867.855, Training Time: 57 seconds), Stats for epoch: (Training Loss: 55229.894, Training Time: 374 seconds)
Epoch:  41/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 46751.418, Training Time: 58 seconds), Stats for epoch: (Training Loss: 54170.084, Training Time: 432 seconds)
Epoch:  41/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 46139.300, Training Time: 60 seconds), Stats for epoch: (Training Loss: 53277.775, Training Time: 493 seconds)
Epoch:  41/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 44951.375, Training Time: 63 seconds), Stats for epoch: (Training Loss: 52445.135, Training Time: 557 seconds)
Epoch:  41/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 47361.532, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51982.989, Training Time: 622 seconds)
Epoch:  41/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 49293.657, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51758.878, Training Time: 688 seconds)
Epoch:  41/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 51930.676, Training Time: 9 seconds), Stats for epoch: (Training Loss: 51760.859, Training Time: 697 seconds)
Epoch:  41/100, Validation loss: 62525.245, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.809 to  1.805
Epoch:  42/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 41556.723, Training Time: 49 seconds), Stats for epoch: (Training Loss: 41556.723, Training Time: 49 seconds)
Epoch:  42/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64926.441, Training Time: 51 seconds), Stats for epoch: (Training Loss: 53241.582, Training Time: 100 seconds)
Epoch:  42/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 65602.924, Training Time: 52 seconds), Stats for epoch: (Training Loss: 57362.029, Training Time: 152 seconds)
Epoch:  42/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 62826.944, Training Time: 53 seconds), Stats for epoch: (Training Loss: 58728.258, Training Time: 206 seconds)
Epoch:  42/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 58658.372, Training Time: 54 seconds), Stats for epoch: (Training Loss: 58714.281, Training Time: 260 seconds)
Epoch:  42/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 56578.821, Training Time: 55 seconds), Stats for epoch: (Training Loss: 58358.371, Training Time: 316 seconds)
Epoch:  42/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 52112.261, Training Time: 57 seconds), Stats for epoch: (Training Loss: 57466.069, Training Time: 373 seconds)
Epoch:  42/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 48730.027, Training Time: 58 seconds), Stats for epoch: (Training Loss: 56374.064, Training Time: 432 seconds)
Epoch:  42/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 46750.102, Training Time: 60 seconds), Stats for epoch: (Training Loss: 55304.735, Training Time: 493 seconds)
Epoch:  42/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 43074.122, Training Time: 63 seconds), Stats for epoch: (Training Loss: 54081.674, Training Time: 556 seconds)
Epoch:  42/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 45244.648, Training Time: 65 seconds), Stats for epoch: (Training Loss: 53278.308, Training Time: 622 seconds)
Epoch:  42/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 45646.711, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52642.341, Training Time: 687 seconds)
Epoch:  42/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 48192.507, Training Time: 9 seconds), Stats for epoch: (Training Loss: 52591.025, Training Time: 696 seconds)
Epoch:  42/100, Validation loss: 59255.578, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.805 to  1.800
Epoch:  43/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 40146.364, Training Time: 49 seconds), Stats for epoch: (Training Loss: 40146.364, Training Time: 49 seconds)
Epoch:  43/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64537.160, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52341.762, Training Time: 100 seconds)
Epoch:  43/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 64839.903, Training Time: 52 seconds), Stats for epoch: (Training Loss: 56507.809, Training Time: 152 seconds)
Epoch:  43/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 61480.496, Training Time: 53 seconds), Stats for epoch: (Training Loss: 57750.981, Training Time: 206 seconds)
Epoch:  43/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 56794.313, Training Time: 54 seconds), Stats for epoch: (Training Loss: 57559.647, Training Time: 260 seconds)
Epoch:  43/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 54820.859, Training Time: 55 seconds), Stats for epoch: (Training Loss: 57103.182, Training Time: 316 seconds)
Epoch:  43/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 51054.570, Training Time: 57 seconds), Stats for epoch: (Training Loss: 56239.095, Training Time: 374 seconds)
Epoch:  43/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 48090.979, Training Time: 58 seconds), Stats for epoch: (Training Loss: 55220.580, Training Time: 432 seconds)
Epoch:  43/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 46179.003, Training Time: 60 seconds), Stats for epoch: (Training Loss: 54215.961, Training Time: 493 seconds)
Epoch:  43/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 45844.789, Training Time: 63 seconds), Stats for epoch: (Training Loss: 53378.844, Training Time: 557 seconds)
Epoch:  43/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 44581.519, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52579.087, Training Time: 622 seconds)
Epoch:  43/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 45572.559, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51995.210, Training Time: 688 seconds)
Epoch:  43/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 48777.458, Training Time: 9 seconds), Stats for epoch: (Training Loss: 51958.102, Training Time: 697 seconds)
Epoch:  43/100, Validation loss: 60151.834, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.800 to  1.796
Epoch:  44/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 39504.993, Training Time: 49 seconds), Stats for epoch: (Training Loss: 39504.993, Training Time: 49 seconds)
Epoch:  44/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63520.799, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51512.896, Training Time: 100 seconds)
Epoch:  44/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 63820.476, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55615.423, Training Time: 152 seconds)
Epoch:  44/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 60263.374, Training Time: 53 seconds), Stats for epoch: (Training Loss: 56777.411, Training Time: 206 seconds)
Epoch:  44/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 55677.036, Training Time: 54 seconds), Stats for epoch: (Training Loss: 56557.336, Training Time: 260 seconds)
Epoch:  44/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 53533.678, Training Time: 55 seconds), Stats for epoch: (Training Loss: 56053.393, Training Time: 316 seconds)
Epoch:  44/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 49445.388, Training Time: 57 seconds), Stats for epoch: (Training Loss: 55109.392, Training Time: 373 seconds)
Epoch:  44/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 46409.028, Training Time: 58 seconds), Stats for epoch: (Training Loss: 54021.847, Training Time: 432 seconds)
Epoch:  44/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 44528.919, Training Time: 60 seconds), Stats for epoch: (Training Loss: 52967.077, Training Time: 493 seconds)
Epoch:  44/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 43013.243, Training Time: 63 seconds), Stats for epoch: (Training Loss: 51971.693, Training Time: 557 seconds)
Epoch:  44/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 44776.322, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51317.569, Training Time: 622 seconds)
Epoch:  44/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 48054.031, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51045.607, Training Time: 688 seconds)
Epoch:  44/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 52081.797, Training Time: 9 seconds), Stats for epoch: (Training Loss: 51057.557, Training Time: 697 seconds)
Epoch:  44/100, Validation loss: 62031.466, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.796 to  1.791
Epoch:  45/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 40411.175, Training Time: 49 seconds), Stats for epoch: (Training Loss: 40411.175, Training Time: 49 seconds)
Epoch:  45/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 65396.335, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52903.755, Training Time: 100 seconds)
Epoch:  45/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 66153.299, Training Time: 52 seconds), Stats for epoch: (Training Loss: 57320.270, Training Time: 152 seconds)
Epoch:  45/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 63116.292, Training Time: 53 seconds), Stats for epoch: (Training Loss: 58769.275, Training Time: 206 seconds)
Epoch:  45/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 58400.158, Training Time: 54 seconds), Stats for epoch: (Training Loss: 58695.452, Training Time: 260 seconds)
Epoch:  45/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 55891.105, Training Time: 55 seconds), Stats for epoch: (Training Loss: 58228.061, Training Time: 316 seconds)
Epoch:  45/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 51355.273, Training Time: 57 seconds), Stats for epoch: (Training Loss: 57246.234, Training Time: 374 seconds)
Epoch:  45/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 47800.799, Training Time: 58 seconds), Stats for epoch: (Training Loss: 56065.554, Training Time: 432 seconds)
Epoch:  45/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 44724.681, Training Time: 60 seconds), Stats for epoch: (Training Loss: 54805.457, Training Time: 493 seconds)
Epoch:  45/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 44261.307, Training Time: 63 seconds), Stats for epoch: (Training Loss: 53751.042, Training Time: 557 seconds)
Epoch:  45/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 44929.466, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52949.081, Training Time: 622 seconds)
Epoch:  45/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 47978.001, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52534.824, Training Time: 688 seconds)
Epoch:  45/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 51471.598, Training Time: 9 seconds), Stats for epoch: (Training Loss: 52522.563, Training Time: 697 seconds)
Epoch:  45/100, Validation loss: 61057.154, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.791 to  1.787
Epoch:  46/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 40518.926, Training Time: 49 seconds), Stats for epoch: (Training Loss: 40518.926, Training Time: 49 seconds)
Epoch:  46/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 65345.834, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52932.380, Training Time: 100 seconds)
Epoch:  46/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 65824.927, Training Time: 52 seconds), Stats for epoch: (Training Loss: 57229.896, Training Time: 152 seconds)
Epoch:  46/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 62786.625, Training Time: 53 seconds), Stats for epoch: (Training Loss: 58619.078, Training Time: 206 seconds)
Epoch:  46/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 57828.768, Training Time: 54 seconds), Stats for epoch: (Training Loss: 58461.016, Training Time: 260 seconds)
Epoch:  46/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 55377.163, Training Time: 55 seconds), Stats for epoch: (Training Loss: 57947.040, Training Time: 316 seconds)
Epoch:  46/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 50781.681, Training Time: 57 seconds), Stats for epoch: (Training Loss: 56923.418, Training Time: 374 seconds)
Epoch:  46/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 48196.677, Training Time: 58 seconds), Stats for epoch: (Training Loss: 55832.575, Training Time: 432 seconds)
Epoch:  46/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 45004.111, Training Time: 60 seconds), Stats for epoch: (Training Loss: 54629.412, Training Time: 493 seconds)
Epoch:  46/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 43891.781, Training Time: 63 seconds), Stats for epoch: (Training Loss: 53555.649, Training Time: 557 seconds)
Epoch:  46/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 43670.165, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52656.969, Training Time: 622 seconds)
Epoch:  46/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 47006.674, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52186.111, Training Time: 688 seconds)
Epoch:  46/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 50809.741, Training Time: 9 seconds), Stats for epoch: (Training Loss: 52170.239, Training Time: 697 seconds)
Epoch:  46/100, Validation loss: 60911.179, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.787 to  1.782
Epoch:  47/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 39791.020, Training Time: 49 seconds), Stats for epoch: (Training Loss: 39791.020, Training Time: 49 seconds)
Epoch:  47/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64800.585, Training Time: 51 seconds), Stats for epoch: (Training Loss: 52295.802, Training Time: 100 seconds)
Epoch:  47/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 65764.587, Training Time: 52 seconds), Stats for epoch: (Training Loss: 56785.397, Training Time: 152 seconds)
Epoch:  47/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 62284.880, Training Time: 53 seconds), Stats for epoch: (Training Loss: 58160.268, Training Time: 206 seconds)
Epoch:  47/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 57858.787, Training Time: 54 seconds), Stats for epoch: (Training Loss: 58099.972, Training Time: 260 seconds)
Epoch:  47/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 55045.142, Training Time: 55 seconds), Stats for epoch: (Training Loss: 57590.833, Training Time: 316 seconds)
Epoch:  47/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 51020.031, Training Time: 57 seconds), Stats for epoch: (Training Loss: 56652.147, Training Time: 373 seconds)
Epoch:  47/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 47787.564, Training Time: 58 seconds), Stats for epoch: (Training Loss: 55544.074, Training Time: 432 seconds)
Epoch:  47/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 47675.977, Training Time: 60 seconds), Stats for epoch: (Training Loss: 54669.841, Training Time: 493 seconds)
Epoch:  47/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 45217.871, Training Time: 63 seconds), Stats for epoch: (Training Loss: 53724.644, Training Time: 556 seconds)
Epoch:  47/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 44539.956, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52889.673, Training Time: 622 seconds)
Epoch:  47/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 46375.679, Training Time: 65 seconds), Stats for epoch: (Training Loss: 52346.840, Training Time: 688 seconds)
Epoch:  47/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 48960.385, Training Time: 9 seconds), Stats for epoch: (Training Loss: 52307.787, Training Time: 697 seconds)
Epoch:  47/100, Validation loss: 59898.832, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.782 to  1.778
Epoch:  48/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 39036.775, Training Time: 49 seconds), Stats for epoch: (Training Loss: 39036.775, Training Time: 49 seconds)
Epoch:  48/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64431.005, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51733.890, Training Time: 100 seconds)
Epoch:  48/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 65476.870, Training Time: 52 seconds), Stats for epoch: (Training Loss: 56314.883, Training Time: 152 seconds)
Epoch:  48/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 61423.167, Training Time: 53 seconds), Stats for epoch: (Training Loss: 57591.954, Training Time: 206 seconds)
Epoch:  48/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 56956.588, Training Time: 54 seconds), Stats for epoch: (Training Loss: 57464.881, Training Time: 260 seconds)
Epoch:  48/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 54692.061, Training Time: 55 seconds), Stats for epoch: (Training Loss: 57002.744, Training Time: 316 seconds)
Epoch:  48/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 50289.007, Training Time: 57 seconds), Stats for epoch: (Training Loss: 56043.639, Training Time: 373 seconds)
Epoch:  48/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 46289.383, Training Time: 58 seconds), Stats for epoch: (Training Loss: 54824.357, Training Time: 432 seconds)
Epoch:  48/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 45255.299, Training Time: 60 seconds), Stats for epoch: (Training Loss: 53761.128, Training Time: 493 seconds)
Epoch:  48/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 40415.500, Training Time: 63 seconds), Stats for epoch: (Training Loss: 52426.565, Training Time: 557 seconds)
Epoch:  48/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 39362.130, Training Time: 65 seconds), Stats for epoch: (Training Loss: 51238.889, Training Time: 622 seconds)
Epoch:  48/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 40134.486, Training Time: 65 seconds), Stats for epoch: (Training Loss: 50313.522, Training Time: 688 seconds)
Epoch:  48/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 42885.803, Training Time: 9 seconds), Stats for epoch: (Training Loss: 50227.865, Training Time: 697 seconds)
Epoch:  48/100, Validation loss: 55653.103, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.778 to  1.774
Epoch:  49/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37510.321, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37510.321, Training Time: 49 seconds)
Epoch:  49/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 61830.110, Training Time: 51 seconds), Stats for epoch: (Training Loss: 49670.216, Training Time: 100 seconds)
Epoch:  49/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62073.700, Training Time: 52 seconds), Stats for epoch: (Training Loss: 53804.711, Training Time: 152 seconds)
Epoch:  49/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 58562.050, Training Time: 53 seconds), Stats for epoch: (Training Loss: 54994.045, Training Time: 206 seconds)
Epoch:  49/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 53524.735, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54700.183, Training Time: 260 seconds)
Epoch:  49/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 51058.214, Training Time: 55 seconds), Stats for epoch: (Training Loss: 54093.188, Training Time: 316 seconds)
Epoch:  49/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 47096.133, Training Time: 57 seconds), Stats for epoch: (Training Loss: 53093.609, Training Time: 373 seconds)
Epoch:  49/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 43294.837, Training Time: 58 seconds), Stats for epoch: (Training Loss: 51868.763, Training Time: 432 seconds)
Epoch:  49/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 40870.629, Training Time: 60 seconds), Stats for epoch: (Training Loss: 50646.748, Training Time: 493 seconds)
Epoch:  49/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 36992.896, Training Time: 63 seconds), Stats for epoch: (Training Loss: 49281.363, Training Time: 557 seconds)
Epoch:  49/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 36200.281, Training Time: 65 seconds), Stats for epoch: (Training Loss: 48092.173, Training Time: 622 seconds)
Epoch:  49/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 39914.747, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47410.721, Training Time: 688 seconds)
Epoch:  49/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 41389.445, Training Time: 9 seconds), Stats for epoch: (Training Loss: 47341.283, Training Time: 697 seconds)
Epoch:  49/100, Validation loss: 54553.933, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.774 to  1.769
Epoch:  50/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37313.317, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37313.317, Training Time: 49 seconds)
Epoch:  50/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 62393.262, Training Time: 51 seconds), Stats for epoch: (Training Loss: 49853.289, Training Time: 100 seconds)
Epoch:  50/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62603.284, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54103.287, Training Time: 152 seconds)
Epoch:  50/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 58548.056, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55214.480, Training Time: 206 seconds)
Epoch:  50/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 53038.693, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54779.322, Training Time: 260 seconds)
Epoch:  50/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 49791.075, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53947.948, Training Time: 316 seconds)
Epoch:  50/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 46038.083, Training Time: 57 seconds), Stats for epoch: (Training Loss: 52817.967, Training Time: 374 seconds)
Epoch:  50/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 42212.304, Training Time: 58 seconds), Stats for epoch: (Training Loss: 51492.259, Training Time: 432 seconds)
Epoch:  50/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 39467.352, Training Time: 60 seconds), Stats for epoch: (Training Loss: 50156.158, Training Time: 493 seconds)
Epoch:  50/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 35522.886, Training Time: 63 seconds), Stats for epoch: (Training Loss: 48692.831, Training Time: 557 seconds)
Epoch:  50/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 34873.091, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47436.491, Training Time: 622 seconds)
Epoch:  50/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 36087.505, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46490.742, Training Time: 688 seconds)
Epoch:  50/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 40879.086, Training Time: 9 seconds), Stats for epoch: (Training Loss: 46426.028, Training Time: 697 seconds)
Epoch:  50/100, Validation loss: 53727.391, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.769 to  1.765
Epoch:  51/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 38136.488, Training Time: 49 seconds), Stats for epoch: (Training Loss: 38136.488, Training Time: 49 seconds)
Epoch:  51/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 62941.239, Training Time: 51 seconds), Stats for epoch: (Training Loss: 50538.863, Training Time: 100 seconds)
Epoch:  51/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62477.441, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54518.389, Training Time: 152 seconds)
Epoch:  51/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 58048.015, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55400.796, Training Time: 206 seconds)
Epoch:  51/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 52394.355, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54799.508, Training Time: 260 seconds)
Epoch:  51/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 49282.142, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53879.947, Training Time: 316 seconds)
Epoch:  51/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 44868.835, Training Time: 57 seconds), Stats for epoch: (Training Loss: 52592.645, Training Time: 374 seconds)
Epoch:  51/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 40682.741, Training Time: 58 seconds), Stats for epoch: (Training Loss: 51103.907, Training Time: 432 seconds)
Epoch:  51/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 39043.434, Training Time: 60 seconds), Stats for epoch: (Training Loss: 49763.855, Training Time: 493 seconds)
Epoch:  51/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 36749.182, Training Time: 63 seconds), Stats for epoch: (Training Loss: 48462.387, Training Time: 557 seconds)
Epoch:  51/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 37833.248, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47496.102, Training Time: 622 seconds)
Epoch:  51/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 40693.334, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46929.205, Training Time: 688 seconds)
Epoch:  51/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 44079.753, Training Time: 9 seconds), Stats for epoch: (Training Loss: 46896.344, Training Time: 697 seconds)
Epoch:  51/100, Validation loss: 56595.594, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.765 to  1.760
Epoch:  52/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37517.277, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37517.277, Training Time: 49 seconds)
Epoch:  52/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63175.751, Training Time: 51 seconds), Stats for epoch: (Training Loss: 50346.514, Training Time: 100 seconds)
Epoch:  52/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 63220.685, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54637.905, Training Time: 152 seconds)
Epoch:  52/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 59177.167, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55772.720, Training Time: 206 seconds)
Epoch:  52/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 53852.805, Training Time: 54 seconds), Stats for epoch: (Training Loss: 55388.737, Training Time: 260 seconds)
Epoch:  52/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 50673.169, Training Time: 55 seconds), Stats for epoch: (Training Loss: 54602.809, Training Time: 316 seconds)
Epoch:  52/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 46339.572, Training Time: 57 seconds), Stats for epoch: (Training Loss: 53422.347, Training Time: 373 seconds)
Epoch:  52/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 42113.676, Training Time: 58 seconds), Stats for epoch: (Training Loss: 52008.763, Training Time: 432 seconds)
Epoch:  52/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 39777.705, Training Time: 60 seconds), Stats for epoch: (Training Loss: 50649.756, Training Time: 493 seconds)
Epoch:  52/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 38468.985, Training Time: 63 seconds), Stats for epoch: (Training Loss: 49431.679, Training Time: 557 seconds)
Epoch:  52/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 38282.089, Training Time: 65 seconds), Stats for epoch: (Training Loss: 48418.080, Training Time: 622 seconds)
Epoch:  52/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 38804.955, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47616.986, Training Time: 688 seconds)
Epoch:  52/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 39269.122, Training Time: 9 seconds), Stats for epoch: (Training Loss: 47520.718, Training Time: 697 seconds)
Epoch:  52/100, Validation loss: 52428.566, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.760 to  1.756
Epoch:  53/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37352.626, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37352.626, Training Time: 49 seconds)
Epoch:  53/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63647.447, Training Time: 51 seconds), Stats for epoch: (Training Loss: 50500.037, Training Time: 100 seconds)
Epoch:  53/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62851.614, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54617.229, Training Time: 152 seconds)
Epoch:  53/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 57468.889, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55330.144, Training Time: 206 seconds)
Epoch:  53/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 51066.170, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54477.349, Training Time: 260 seconds)
Epoch:  53/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 47659.570, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53341.053, Training Time: 316 seconds)
Epoch:  53/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 43422.684, Training Time: 57 seconds), Stats for epoch: (Training Loss: 51924.143, Training Time: 373 seconds)
Epoch:  53/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 39831.403, Training Time: 58 seconds), Stats for epoch: (Training Loss: 50412.550, Training Time: 432 seconds)
Epoch:  53/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 37965.216, Training Time: 60 seconds), Stats for epoch: (Training Loss: 49029.513, Training Time: 493 seconds)
Epoch:  53/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 34571.538, Training Time: 63 seconds), Stats for epoch: (Training Loss: 47583.716, Training Time: 557 seconds)
Epoch:  53/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 34332.504, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46379.060, Training Time: 622 seconds)
Epoch:  53/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 35843.074, Training Time: 65 seconds), Stats for epoch: (Training Loss: 45501.061, Training Time: 688 seconds)
Epoch:  53/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 38381.601, Training Time: 9 seconds), Stats for epoch: (Training Loss: 45418.959, Training Time: 697 seconds)
Epoch:  53/100, Validation loss: 53874.143, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.756 to  1.752
Epoch:  54/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37406.615, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37406.615, Training Time: 49 seconds)
Epoch:  54/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63464.493, Training Time: 51 seconds), Stats for epoch: (Training Loss: 50435.554, Training Time: 100 seconds)
Epoch:  54/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62207.771, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54359.627, Training Time: 152 seconds)
Epoch:  54/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 56907.424, Training Time: 53 seconds), Stats for epoch: (Training Loss: 54996.576, Training Time: 206 seconds)
Epoch:  54/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 50727.932, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54142.847, Training Time: 260 seconds)
Epoch:  54/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 47646.028, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53060.044, Training Time: 316 seconds)
Epoch:  54/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 43658.110, Training Time: 57 seconds), Stats for epoch: (Training Loss: 51716.911, Training Time: 374 seconds)
Epoch:  54/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 41955.848, Training Time: 58 seconds), Stats for epoch: (Training Loss: 50496.778, Training Time: 432 seconds)
Epoch:  54/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 38296.297, Training Time: 60 seconds), Stats for epoch: (Training Loss: 49141.169, Training Time: 493 seconds)
Epoch:  54/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 37272.614, Training Time: 63 seconds), Stats for epoch: (Training Loss: 47954.313, Training Time: 557 seconds)
Epoch:  54/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 37009.260, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46959.308, Training Time: 622 seconds)
Epoch:  54/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 39996.798, Training Time: 65 seconds), Stats for epoch: (Training Loss: 46379.099, Training Time: 688 seconds)
Epoch:  54/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 44297.740, Training Time: 9 seconds), Stats for epoch: (Training Loss: 46355.097, Training Time: 697 seconds)
Epoch:  54/100, Validation loss: 56749.985, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.752 to  1.747
Epoch:  55/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37757.806, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37757.806, Training Time: 49 seconds)
Epoch:  55/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64751.467, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51254.636, Training Time: 100 seconds)
Epoch:  55/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 63870.023, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55459.765, Training Time: 152 seconds)
Epoch:  55/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 58880.245, Training Time: 53 seconds), Stats for epoch: (Training Loss: 56314.885, Training Time: 206 seconds)
Epoch:  55/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 53186.899, Training Time: 54 seconds), Stats for epoch: (Training Loss: 55689.288, Training Time: 260 seconds)
Epoch:  55/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 50287.741, Training Time: 55 seconds), Stats for epoch: (Training Loss: 54789.030, Training Time: 316 seconds)
Epoch:  55/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 45646.299, Training Time: 57 seconds), Stats for epoch: (Training Loss: 53482.926, Training Time: 373 seconds)
Epoch:  55/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 41186.557, Training Time: 58 seconds), Stats for epoch: (Training Loss: 51945.880, Training Time: 432 seconds)
Epoch:  55/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 39378.175, Training Time: 60 seconds), Stats for epoch: (Training Loss: 50549.468, Training Time: 493 seconds)
Epoch:  55/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 37146.867, Training Time: 63 seconds), Stats for epoch: (Training Loss: 49209.208, Training Time: 556 seconds)
Epoch:  55/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 36331.916, Training Time: 65 seconds), Stats for epoch: (Training Loss: 48038.545, Training Time: 622 seconds)
Epoch:  55/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 40158.013, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47381.834, Training Time: 687 seconds)
Epoch:  55/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 43356.955, Training Time: 9 seconds), Stats for epoch: (Training Loss: 47335.419, Training Time: 697 seconds)
Epoch:  55/100, Validation loss: 56340.691, Batch Validation Time: 57 seconds
Learning rate decay: adjusting from  1.747 to  1.743
Epoch:  56/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37864.283, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37864.283, Training Time: 49 seconds)
Epoch:  56/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 65224.859, Training Time: 51 seconds), Stats for epoch: (Training Loss: 51544.571, Training Time: 100 seconds)
Epoch:  56/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 64313.256, Training Time: 52 seconds), Stats for epoch: (Training Loss: 55800.799, Training Time: 152 seconds)
Epoch:  56/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 59522.214, Training Time: 53 seconds), Stats for epoch: (Training Loss: 56731.153, Training Time: 206 seconds)
Epoch:  56/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 53633.171, Training Time: 54 seconds), Stats for epoch: (Training Loss: 56111.557, Training Time: 260 seconds)
Epoch:  56/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 49996.054, Training Time: 55 seconds), Stats for epoch: (Training Loss: 55092.306, Training Time: 316 seconds)
Epoch:  56/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 45908.711, Training Time: 57 seconds), Stats for epoch: (Training Loss: 53780.364, Training Time: 373 seconds)
Epoch:  56/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 42639.395, Training Time: 58 seconds), Stats for epoch: (Training Loss: 52387.743, Training Time: 432 seconds)
Epoch:  56/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 40071.170, Training Time: 60 seconds), Stats for epoch: (Training Loss: 51019.235, Training Time: 493 seconds)
Epoch:  56/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 36969.179, Training Time: 63 seconds), Stats for epoch: (Training Loss: 49614.229, Training Time: 556 seconds)
Epoch:  56/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 37360.893, Training Time: 65 seconds), Stats for epoch: (Training Loss: 48500.290, Training Time: 622 seconds)
Epoch:  56/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 39426.465, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47744.138, Training Time: 687 seconds)
Epoch:  56/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 43589.240, Training Time: 9 seconds), Stats for epoch: (Training Loss: 47696.223, Training Time: 696 seconds)
Epoch:  56/100, Validation loss: 56254.618, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.743 to  1.738
Epoch:  57/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37308.550, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37308.550, Training Time: 49 seconds)
Epoch:  57/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 64162.092, Training Time: 51 seconds), Stats for epoch: (Training Loss: 50735.321, Training Time: 100 seconds)
Epoch:  57/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62863.733, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54778.125, Training Time: 152 seconds)
Epoch:  57/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 57907.258, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55560.408, Training Time: 206 seconds)
Epoch:  57/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 51949.880, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54838.303, Training Time: 260 seconds)
Epoch:  57/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 48759.778, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53825.215, Training Time: 316 seconds)
Epoch:  57/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 44653.788, Training Time: 57 seconds), Stats for epoch: (Training Loss: 52515.011, Training Time: 373 seconds)
Epoch:  57/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 41269.599, Training Time: 58 seconds), Stats for epoch: (Training Loss: 51109.335, Training Time: 432 seconds)
Epoch:  57/100, Batch:  900/1214, Stats for last 100 batches: (Training Loss: 40134.667, Training Time: 60 seconds), Stats for epoch: (Training Loss: 49889.927, Training Time: 493 seconds)
Epoch:  57/100, Batch: 1000/1214, Stats for last 100 batches: (Training Loss: 38618.522, Training Time: 63 seconds), Stats for epoch: (Training Loss: 48762.787, Training Time: 557 seconds)
Epoch:  57/100, Batch: 1100/1214, Stats for last 100 batches: (Training Loss: 37401.372, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47729.931, Training Time: 622 seconds)
Epoch:  57/100, Batch: 1200/1214, Stats for last 100 batches: (Training Loss: 39354.766, Training Time: 65 seconds), Stats for epoch: (Training Loss: 47032.000, Training Time: 688 seconds)
Epoch:  57/100, Batch: 1214/1214, Stats for last 14 batches: (Training Loss: 44315.890, Training Time: 9 seconds), Stats for epoch: (Training Loss: 47000.678, Training Time: 697 seconds)
Epoch:  57/100, Validation loss: 56236.891, Batch Validation Time: 58 seconds
Learning rate decay: adjusting from  1.738 to  1.734
Epoch:  58/100, Batch:  100/1214, Stats for last 100 batches: (Training Loss: 37065.696, Training Time: 49 seconds), Stats for epoch: (Training Loss: 37065.696, Training Time: 49 seconds)
Epoch:  58/100, Batch:  200/1214, Stats for last 100 batches: (Training Loss: 63743.379, Training Time: 51 seconds), Stats for epoch: (Training Loss: 50404.538, Training Time: 100 seconds)
Epoch:  58/100, Batch:  300/1214, Stats for last 100 batches: (Training Loss: 62459.365, Training Time: 52 seconds), Stats for epoch: (Training Loss: 54422.814, Training Time: 152 seconds)
Epoch:  58/100, Batch:  400/1214, Stats for last 100 batches: (Training Loss: 57859.076, Training Time: 53 seconds), Stats for epoch: (Training Loss: 55281.879, Training Time: 206 seconds)
Epoch:  58/100, Batch:  500/1214, Stats for last 100 batches: (Training Loss: 51723.505, Training Time: 54 seconds), Stats for epoch: (Training Loss: 54570.204, Training Time: 260 seconds)
Epoch:  58/100, Batch:  600/1214, Stats for last 100 batches: (Training Loss: 48858.575, Training Time: 55 seconds), Stats for epoch: (Training Loss: 53618.266, Training Time: 316 seconds)
Epoch:  58/100, Batch:  700/1214, Stats for last 100 batches: (Training Loss: 44565.485, Training Time: 57 seconds), Stats for epoch: (Training Loss: 52325.012, Training Time: 373 seconds)
Epoch:  58/100, Batch:  800/1214, Stats for last 100 batches: (Training Loss: 42096.576, Training Time: 58 seconds), Stats for epoch: (Training Loss: 51046.457, Training Time: 432 seconds)