
Reading dataset 'csv'...

Final shared vocab size: 80513

Splitting 122008 samples into training & validation sets (20.0% used for validation)...
Training set: 97607 samples. Validation set: 24401 samples.
Sorting training & validation sets to increase training efficiency...
Initializing model...


Creating checkpoint batch files...
Initializing training...
Epochs: 100
Batch Size: 128
Optimizer: sgd
Epoch:   1/100, Batch:  100/763, Stats for last 100 batches: (Training Loss: 11.096, Training Time: 49 seconds), Stats for epoch: (Training Loss: 11.096, Training Time: 49 seconds)
Epoch:   1/100, Batch:  200/763, Stats for last 100 batches: (Training Loss: 10.019, Training Time: 49 seconds), Stats for epoch: (Training Loss: 10.558, Training Time: 98 seconds)
Epoch:   1/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  9.246, Training Time: 51 seconds), Stats for epoch: (Training Loss: 10.120, Training Time: 150 seconds)
Epoch:   1/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  8.884, Training Time: 53 seconds), Stats for epoch: (Training Loss:  9.811, Training Time: 203 seconds)
Epoch:   1/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  8.723, Training Time: 56 seconds), Stats for epoch: (Training Loss:  9.594, Training Time: 260 seconds)
Epoch:   1/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  8.608, Training Time: 59 seconds), Stats for epoch: (Training Loss:  9.429, Training Time: 320 seconds)
Epoch:   1/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  8.567, Training Time: 62 seconds), Stats for epoch: (Training Loss:  9.306, Training Time: 382 seconds)
Epoch:   1/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  8.464, Training Time: 39 seconds), Stats for epoch: (Training Loss:  9.237, Training Time: 421 seconds)
Epoch:   1/100, Validation loss:  8.567, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   2/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  8.829, Training Time: 47 seconds), Stats for epoch: (Training Loss:  8.829, Training Time: 47 seconds)
Epoch:   2/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  8.472, Training Time: 49 seconds), Stats for epoch: (Training Loss:  8.650, Training Time: 96 seconds)
Epoch:   2/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  8.412, Training Time: 51 seconds), Stats for epoch: (Training Loss:  8.571, Training Time: 147 seconds)
Epoch:   2/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  8.356, Training Time: 53 seconds), Stats for epoch: (Training Loss:  8.517, Training Time: 201 seconds)
Epoch:   2/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  8.328, Training Time: 56 seconds), Stats for epoch: (Training Loss:  8.479, Training Time: 258 seconds)
Epoch:   2/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  8.292, Training Time: 59 seconds), Stats for epoch: (Training Loss:  8.448, Training Time: 318 seconds)
Epoch:   2/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  8.304, Training Time: 62 seconds), Stats for epoch: (Training Loss:  8.428, Training Time: 380 seconds)
Epoch:   2/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  8.196, Training Time: 39 seconds), Stats for epoch: (Training Loss:  8.408, Training Time: 419 seconds)
Epoch:   2/100, Validation loss:  8.298, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   3/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  8.516, Training Time: 46 seconds), Stats for epoch: (Training Loss:  8.516, Training Time: 46 seconds)
Epoch:   3/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  8.236, Training Time: 49 seconds), Stats for epoch: (Training Loss:  8.376, Training Time: 96 seconds)
Epoch:   3/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  8.209, Training Time: 51 seconds), Stats for epoch: (Training Loss:  8.320, Training Time: 147 seconds)
Epoch:   3/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  8.170, Training Time: 53 seconds), Stats for epoch: (Training Loss:  8.283, Training Time: 201 seconds)
Epoch:   3/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  8.157, Training Time: 56 seconds), Stats for epoch: (Training Loss:  8.257, Training Time: 257 seconds)
Epoch:   3/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  8.134, Training Time: 60 seconds), Stats for epoch: (Training Loss:  8.237, Training Time: 317 seconds)
Epoch:   3/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  8.155, Training Time: 62 seconds), Stats for epoch: (Training Loss:  8.225, Training Time: 379 seconds)
Epoch:   3/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  8.046, Training Time: 39 seconds), Stats for epoch: (Training Loss:  8.210, Training Time: 419 seconds)
Epoch:   3/100, Validation loss:  8.143, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   4/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  8.327, Training Time: 46 seconds), Stats for epoch: (Training Loss:  8.327, Training Time: 46 seconds)
Epoch:   4/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  8.093, Training Time: 49 seconds), Stats for epoch: (Training Loss:  8.210, Training Time: 96 seconds)
Epoch:   4/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  8.081, Training Time: 51 seconds), Stats for epoch: (Training Loss:  8.167, Training Time: 147 seconds)
Epoch:   4/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  8.048, Training Time: 53 seconds), Stats for epoch: (Training Loss:  8.137, Training Time: 200 seconds)
Epoch:   4/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  8.043, Training Time: 56 seconds), Stats for epoch: (Training Loss:  8.118, Training Time: 257 seconds)
Epoch:   4/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  8.026, Training Time: 59 seconds), Stats for epoch: (Training Loss:  8.103, Training Time: 316 seconds)
Epoch:   4/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  8.050, Training Time: 62 seconds), Stats for epoch: (Training Loss:  8.095, Training Time: 379 seconds)
Epoch:   4/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.942, Training Time: 38 seconds), Stats for epoch: (Training Loss:  8.083, Training Time: 418 seconds)
Epoch:   4/100, Validation loss:  8.036, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   5/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  8.194, Training Time: 46 seconds), Stats for epoch: (Training Loss:  8.194, Training Time: 46 seconds)
Epoch:   5/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.991, Training Time: 49 seconds), Stats for epoch: (Training Loss:  8.093, Training Time: 96 seconds)
Epoch:   5/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.988, Training Time: 51 seconds), Stats for epoch: (Training Loss:  8.058, Training Time: 147 seconds)
Epoch:   5/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.959, Training Time: 53 seconds), Stats for epoch: (Training Loss:  8.033, Training Time: 201 seconds)
Epoch:   5/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.959, Training Time: 56 seconds), Stats for epoch: (Training Loss:  8.018, Training Time: 257 seconds)
Epoch:   5/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.946, Training Time: 59 seconds), Stats for epoch: (Training Loss:  8.006, Training Time: 317 seconds)
Epoch:   5/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.970, Training Time: 62 seconds), Stats for epoch: (Training Loss:  8.001, Training Time: 379 seconds)
Epoch:   5/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.865, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.990, Training Time: 418 seconds)
Epoch:   5/100, Validation loss:  7.956, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   6/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  8.095, Training Time: 46 seconds), Stats for epoch: (Training Loss:  8.095, Training Time: 46 seconds)
Epoch:   6/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.915, Training Time: 49 seconds), Stats for epoch: (Training Loss:  8.005, Training Time: 96 seconds)
Epoch:   6/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.917, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.975, Training Time: 147 seconds)
Epoch:   6/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.891, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.954, Training Time: 201 seconds)
Epoch:   6/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.894, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.942, Training Time: 257 seconds)
Epoch:   6/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.884, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.932, Training Time: 317 seconds)
Epoch:   6/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.907, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.929, Training Time: 379 seconds)
Epoch:   6/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.805, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.919, Training Time: 418 seconds)
Epoch:   6/100, Validation loss:  7.892, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   7/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  8.017, Training Time: 46 seconds), Stats for epoch: (Training Loss:  8.017, Training Time: 46 seconds)
Epoch:   7/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.854, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.935, Training Time: 96 seconds)
Epoch:   7/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.860, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.910, Training Time: 147 seconds)
Epoch:   7/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.836, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.892, Training Time: 201 seconds)
Epoch:   7/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.841, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.881, Training Time: 257 seconds)
Epoch:   7/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.833, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.873, Training Time: 317 seconds)
Epoch:   7/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.855, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.871, Training Time: 379 seconds)
Epoch:   7/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.756, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.861, Training Time: 418 seconds)
Epoch:   7/100, Validation loss:  7.840, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   8/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.953, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.953, Training Time: 46 seconds)
Epoch:   8/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.805, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.879, Training Time: 96 seconds)
Epoch:   8/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.812, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.857, Training Time: 147 seconds)
Epoch:   8/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.790, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.840, Training Time: 201 seconds)
Epoch:   8/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.797, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.831, Training Time: 257 seconds)
Epoch:   8/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.790, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.824, Training Time: 317 seconds)
Epoch:   8/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.812, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.823, Training Time: 379 seconds)
Epoch:   8/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.715, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.814, Training Time: 418 seconds)
Epoch:   8/100, Validation loss:  7.797, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:   9/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.900, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.900, Training Time: 46 seconds)
Epoch:   9/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.762, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.831, Training Time: 96 seconds)
Epoch:   9/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.771, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.811, Training Time: 147 seconds)
Epoch:   9/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.751, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.796, Training Time: 200 seconds)
Epoch:   9/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.759, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.789, Training Time: 257 seconds)
Epoch:   9/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.753, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.783, Training Time: 317 seconds)
Epoch:   9/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.775, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.782, Training Time: 379 seconds)
Epoch:   9/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.680, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.773, Training Time: 418 seconds)
Epoch:   9/100, Validation loss:  7.759, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  10/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.854, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.854, Training Time: 46 seconds)
Epoch:  10/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.726, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.790, Training Time: 96 seconds)
Epoch:  10/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.736, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.772, Training Time: 147 seconds)
Epoch:  10/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.717, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.758, Training Time: 200 seconds)
Epoch:  10/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.726, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.752, Training Time: 257 seconds)
Epoch:  10/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.721, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.747, Training Time: 317 seconds)
Epoch:  10/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.743, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.746, Training Time: 379 seconds)
Epoch:  10/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.649, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.738, Training Time: 418 seconds)
Epoch:  10/100, Validation loss:  7.727, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  11/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.814, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.814, Training Time: 46 seconds)
Epoch:  11/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.693, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.753, Training Time: 95 seconds)
Epoch:  11/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.704, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.737, Training Time: 147 seconds)
Epoch:  11/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.686, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.724, Training Time: 200 seconds)
Epoch:  11/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.696, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.718, Training Time: 257 seconds)
Epoch:  11/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.693, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.714, Training Time: 316 seconds)
Epoch:  11/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.714, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.714, Training Time: 378 seconds)
Epoch:  11/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.622, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.707, Training Time: 417 seconds)
Epoch:  11/100, Validation loss:  7.699, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  12/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.778, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.778, Training Time: 46 seconds)
Epoch:  12/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.664, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.721, Training Time: 96 seconds)
Epoch:  12/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.676, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.706, Training Time: 147 seconds)
Epoch:  12/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.659, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.694, Training Time: 201 seconds)
Epoch:  12/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.669, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.689, Training Time: 257 seconds)
Epoch:  12/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.667, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.686, Training Time: 317 seconds)
Epoch:  12/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.688, Training Time: 61 seconds), Stats for epoch: (Training Loss:  7.686, Training Time: 379 seconds)
Epoch:  12/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.596, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.679, Training Time: 418 seconds)
Epoch:  12/100, Validation loss:  7.672, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  13/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.747, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.747, Training Time: 46 seconds)
Epoch:  13/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.638, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.693, Training Time: 96 seconds)
Epoch:  13/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.650, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.679, Training Time: 147 seconds)
Epoch:  13/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.634, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.667, Training Time: 201 seconds)
Epoch:  13/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.645, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.663, Training Time: 257 seconds)
Epoch:  13/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.644, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.660, Training Time: 317 seconds)
Epoch:  13/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.665, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.660, Training Time: 379 seconds)
Epoch:  13/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.574, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.653, Training Time: 418 seconds)
Epoch:  13/100, Validation loss:  7.648, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  14/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.718, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.718, Training Time: 46 seconds)
Epoch:  14/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.615, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.666, Training Time: 96 seconds)
Epoch:  14/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.627, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.653, Training Time: 147 seconds)
Epoch:  14/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.612, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.643, Training Time: 201 seconds)
Epoch:  14/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.623, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.639, Training Time: 257 seconds)
Epoch:  14/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.623, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.636, Training Time: 317 seconds)
Epoch:  14/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.643, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.637, Training Time: 379 seconds)
Epoch:  14/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.554, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.630, Training Time: 418 seconds)
Epoch:  14/100, Validation loss:  7.627, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  15/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.692, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.692, Training Time: 46 seconds)
Epoch:  15/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.593, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.642, Training Time: 96 seconds)
Epoch:  15/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.606, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.630, Training Time: 147 seconds)
Epoch:  15/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.591, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.621, Training Time: 201 seconds)
Epoch:  15/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.603, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.617, Training Time: 257 seconds)
Epoch:  15/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.603, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.615, Training Time: 317 seconds)
Epoch:  15/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.624, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.616, Training Time: 379 seconds)
Epoch:  15/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.535, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.609, Training Time: 418 seconds)
Epoch:  15/100, Validation loss:  7.609, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  16/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.669, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.669, Training Time: 46 seconds)
Epoch:  16/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.573, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.621, Training Time: 96 seconds)
Epoch:  16/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.587, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.610, Training Time: 147 seconds)
Epoch:  16/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.573, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.601, Training Time: 201 seconds)
Epoch:  16/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.585, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.597, Training Time: 257 seconds)
Epoch:  16/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.585, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.595, Training Time: 317 seconds)
Epoch:  16/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.606, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.597, Training Time: 379 seconds)
Epoch:  16/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.518, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.590, Training Time: 418 seconds)
Epoch:  16/100, Validation loss:  7.589, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  17/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.647, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.647, Training Time: 46 seconds)
Epoch:  17/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.555, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.601, Training Time: 96 seconds)
Epoch:  17/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.569, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.590, Training Time: 147 seconds)
Epoch:  17/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.555, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.582, Training Time: 201 seconds)
Epoch:  17/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.568, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.579, Training Time: 257 seconds)
Epoch:  17/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.569, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.577, Training Time: 317 seconds)
Epoch:  17/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.589, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.579, Training Time: 379 seconds)
Epoch:  17/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.503, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.573, Training Time: 418 seconds)
Epoch:  17/100, Validation loss:  7.573, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  18/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.626, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.626, Training Time: 46 seconds)
Epoch:  18/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.538, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.582, Training Time: 96 seconds)
Epoch:  18/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.553, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.572, Training Time: 147 seconds)
Epoch:  18/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.539, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.564, Training Time: 201 seconds)
Epoch:  18/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.552, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.562, Training Time: 257 seconds)
Epoch:  18/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.553, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.560, Training Time: 317 seconds)
Epoch:  18/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.573, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.562, Training Time: 379 seconds)
Epoch:  18/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.487, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.556, Training Time: 418 seconds)
Epoch:  18/100, Validation loss:  7.557, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  19/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.608, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.608, Training Time: 46 seconds)
Epoch:  19/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.523, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.565, Training Time: 96 seconds)
Epoch:  19/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.537, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.556, Training Time: 147 seconds)
Epoch:  19/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.524, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.548, Training Time: 201 seconds)
Epoch:  19/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.538, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.546, Training Time: 257 seconds)
Epoch:  19/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.539, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.545, Training Time: 317 seconds)
Epoch:  19/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.558, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.547, Training Time: 379 seconds)
Epoch:  19/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.474, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.541, Training Time: 418 seconds)
Epoch:  19/100, Validation loss:  7.543, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  20/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.591, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.591, Training Time: 46 seconds)
Epoch:  20/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.508, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.550, Training Time: 96 seconds)
Epoch:  20/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.523, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.541, Training Time: 147 seconds)
Epoch:  20/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.510, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.533, Training Time: 201 seconds)
Epoch:  20/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.524, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.531, Training Time: 257 seconds)
Epoch:  20/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.526, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.531, Training Time: 317 seconds)
Epoch:  20/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.546, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.533, Training Time: 379 seconds)
Epoch:  20/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.462, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.527, Training Time: 418 seconds)
Epoch:  20/100, Validation loss:  7.532, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  21/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.575, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.575, Training Time: 46 seconds)
Epoch:  21/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.495, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.535, Training Time: 96 seconds)
Epoch:  21/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.510, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.527, Training Time: 147 seconds)
Epoch:  21/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.497, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.519, Training Time: 201 seconds)
Epoch:  21/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.512, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.518, Training Time: 257 seconds)
Epoch:  21/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.514, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.517, Training Time: 317 seconds)
Epoch:  21/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.533, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.519, Training Time: 379 seconds)
Epoch:  21/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.450, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.514, Training Time: 418 seconds)
Epoch:  21/100, Validation loss:  7.518, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  22/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.561, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.561, Training Time: 46 seconds)
Epoch:  22/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.482, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.521, Training Time: 96 seconds)
Epoch:  22/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.498, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.513, Training Time: 147 seconds)
Epoch:  22/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.485, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.506, Training Time: 201 seconds)
Epoch:  22/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.500, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.505, Training Time: 257 seconds)
Epoch:  22/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.502, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.504, Training Time: 317 seconds)
Epoch:  22/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.520, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.507, Training Time: 379 seconds)
Epoch:  22/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.438, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.501, Training Time: 418 seconds)
Epoch:  22/100, Validation loss:  7.506, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  23/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.547, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.547, Training Time: 46 seconds)
Epoch:  23/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.470, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.508, Training Time: 96 seconds)
Epoch:  23/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.486, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.501, Training Time: 147 seconds)
Epoch:  23/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.474, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.494, Training Time: 201 seconds)
Epoch:  23/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.488, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.493, Training Time: 257 seconds)
Epoch:  23/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.490, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.492, Training Time: 317 seconds)
Epoch:  23/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.509, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.495, Training Time: 379 seconds)
Epoch:  23/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.428, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.489, Training Time: 418 seconds)
Epoch:  23/100, Validation loss:  7.495, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  24/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.533, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.533, Training Time: 46 seconds)
Epoch:  24/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.458, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.496, Training Time: 96 seconds)
Epoch:  24/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.475, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.489, Training Time: 147 seconds)
Epoch:  24/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.463, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.482, Training Time: 201 seconds)
Epoch:  24/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.478, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.481, Training Time: 257 seconds)
Epoch:  24/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.480, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.481, Training Time: 317 seconds)
Epoch:  24/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.498, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.484, Training Time: 379 seconds)
Epoch:  24/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.419, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.478, Training Time: 418 seconds)
Epoch:  24/100, Validation loss:  7.483, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  25/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.521, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.521, Training Time: 46 seconds)
Epoch:  25/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.448, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.484, Training Time: 96 seconds)
Epoch:  25/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.465, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.478, Training Time: 147 seconds)
Epoch:  25/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.453, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.471, Training Time: 201 seconds)
Epoch:  25/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.468, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.471, Training Time: 257 seconds)
Epoch:  25/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.470, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.471, Training Time: 317 seconds)
Epoch:  25/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.488, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.473, Training Time: 379 seconds)
Epoch:  25/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.408, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.468, Training Time: 418 seconds)
Epoch:  25/100, Validation loss:  7.475, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  26/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.510, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.510, Training Time: 46 seconds)
Epoch:  26/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.438, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.474, Training Time: 96 seconds)
Epoch:  26/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.455, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.467, Training Time: 147 seconds)
Epoch:  26/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.443, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.461, Training Time: 201 seconds)
Epoch:  26/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.458, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.461, Training Time: 257 seconds)
Epoch:  26/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.461, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.461, Training Time: 317 seconds)
Epoch:  26/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.478, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.463, Training Time: 379 seconds)
Epoch:  26/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.400, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.458, Training Time: 418 seconds)
Epoch:  26/100, Validation loss:  7.466, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  27/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.498, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.498, Training Time: 46 seconds)
Epoch:  27/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.428, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.463, Training Time: 96 seconds)
Epoch:  27/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.446, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.457, Training Time: 147 seconds)
Epoch:  27/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.434, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.451, Training Time: 201 seconds)
Epoch:  27/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.449, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.451, Training Time: 257 seconds)
Epoch:  27/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.452, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.451, Training Time: 317 seconds)
Epoch:  27/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.469, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.454, Training Time: 379 seconds)
Epoch:  27/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.391, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.448, Training Time: 418 seconds)
Epoch:  27/100, Validation loss:  7.457, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  28/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.488, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.488, Training Time: 46 seconds)
Epoch:  28/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.419, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.454, Training Time: 96 seconds)
Epoch:  28/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.437, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.448, Training Time: 147 seconds)
Epoch:  28/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.425, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.442, Training Time: 201 seconds)
Epoch:  28/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.441, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.442, Training Time: 257 seconds)
Epoch:  28/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.444, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.442, Training Time: 317 seconds)
Epoch:  28/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.460, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.445, Training Time: 379 seconds)
Epoch:  28/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.384, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.440, Training Time: 418 seconds)
Epoch:  28/100, Validation loss:  7.447, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  29/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.478, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.478, Training Time: 46 seconds)
Epoch:  29/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.411, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.445, Training Time: 96 seconds)
Epoch:  29/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.428, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.439, Training Time: 147 seconds)
Epoch:  29/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.417, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.434, Training Time: 201 seconds)
Epoch:  29/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.432, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.433, Training Time: 257 seconds)
Epoch:  29/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.435, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.434, Training Time: 317 seconds)
Epoch:  29/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.452, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.436, Training Time: 379 seconds)
Epoch:  29/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.376, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.431, Training Time: 418 seconds)
Epoch:  29/100, Validation loss:  7.439, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  30/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.469, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.469, Training Time: 46 seconds)
Epoch:  30/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.403, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.436, Training Time: 96 seconds)
Epoch:  30/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.421, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.431, Training Time: 147 seconds)
Epoch:  30/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.409, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.425, Training Time: 201 seconds)
Epoch:  30/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.425, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.425, Training Time: 257 seconds)
Epoch:  30/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.428, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.426, Training Time: 317 seconds)
Epoch:  30/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.444, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.428, Training Time: 379 seconds)
Epoch:  30/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.367, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.423, Training Time: 418 seconds)
Epoch:  30/100, Validation loss:  7.433, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  31/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.461, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.461, Training Time: 46 seconds)
Epoch:  31/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.395, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.428, Training Time: 96 seconds)
Epoch:  31/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.413, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.423, Training Time: 147 seconds)
Epoch:  31/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.401, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.417, Training Time: 201 seconds)
Epoch:  31/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.418, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.417, Training Time: 257 seconds)
Epoch:  31/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.420, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.418, Training Time: 317 seconds)
Epoch:  31/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.436, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.421, Training Time: 379 seconds)
Epoch:  31/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.362, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.416, Training Time: 418 seconds)
Epoch:  31/100, Validation loss:  7.424, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  32/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.452, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.452, Training Time: 46 seconds)
Epoch:  32/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.388, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.420, Training Time: 96 seconds)
Epoch:  32/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.406, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.415, Training Time: 147 seconds)
Epoch:  32/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.395, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.410, Training Time: 201 seconds)
Epoch:  32/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.410, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.410, Training Time: 257 seconds)
Epoch:  32/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.414, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.411, Training Time: 317 seconds)
Epoch:  32/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.430, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.413, Training Time: 379 seconds)
Epoch:  32/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.355, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.409, Training Time: 418 seconds)
Epoch:  32/100, Validation loss:  7.419, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  33/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.443, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.443, Training Time: 46 seconds)
Epoch:  33/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.380, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.412, Training Time: 96 seconds)
Epoch:  33/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.399, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.408, Training Time: 147 seconds)
Epoch:  33/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.388, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.403, Training Time: 201 seconds)
Epoch:  33/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.404, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.403, Training Time: 257 seconds)
Epoch:  33/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.407, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.403, Training Time: 317 seconds)
Epoch:  33/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.423, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.406, Training Time: 379 seconds)
Epoch:  33/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.349, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.401, Training Time: 418 seconds)
Epoch:  33/100, Validation loss:  7.411, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  34/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.435, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.435, Training Time: 46 seconds)
Epoch:  34/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.374, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.404, Training Time: 96 seconds)
Epoch:  34/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.392, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.400, Training Time: 147 seconds)
Epoch:  34/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.381, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.396, Training Time: 200 seconds)
Epoch:  34/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.397, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.396, Training Time: 257 seconds)
Epoch:  34/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.400, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.397, Training Time: 317 seconds)
Epoch:  34/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.416, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.399, Training Time: 379 seconds)
Epoch:  34/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.343, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.395, Training Time: 418 seconds)
Epoch:  34/100, Validation loss:  7.405, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  35/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.428, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.428, Training Time: 46 seconds)
Epoch:  35/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.367, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.398, Training Time: 96 seconds)
Epoch:  35/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.386, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.394, Training Time: 147 seconds)
Epoch:  35/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.375, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.389, Training Time: 201 seconds)
Epoch:  35/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.391, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.390, Training Time: 257 seconds)
Epoch:  35/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.394, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.390, Training Time: 317 seconds)
Epoch:  35/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.408, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.393, Training Time: 379 seconds)
Epoch:  35/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.337, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.388, Training Time: 418 seconds)
Epoch:  35/100, Validation loss:  7.399, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  36/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.421, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.421, Training Time: 46 seconds)
Epoch:  36/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.361, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.391, Training Time: 96 seconds)
Epoch:  36/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.380, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.387, Training Time: 147 seconds)
Epoch:  36/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.369, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.383, Training Time: 201 seconds)
Epoch:  36/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.385, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.383, Training Time: 257 seconds)
Epoch:  36/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.388, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.384, Training Time: 317 seconds)
Epoch:  36/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.404, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.387, Training Time: 379 seconds)
Epoch:  36/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.331, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.382, Training Time: 418 seconds)
Epoch:  36/100, Validation loss:  7.393, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  37/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.414, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.414, Training Time: 46 seconds)
Epoch:  37/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.355, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.384, Training Time: 96 seconds)
Epoch:  37/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.375, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.381, Training Time: 147 seconds)
Epoch:  37/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.363, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.377, Training Time: 201 seconds)
Epoch:  37/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.380, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.377, Training Time: 257 seconds)
Epoch:  37/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.383, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.378, Training Time: 316 seconds)
Epoch:  37/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.399, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.381, Training Time: 379 seconds)
Epoch:  37/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.326, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.377, Training Time: 418 seconds)
Epoch:  37/100, Validation loss:  7.387, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  38/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.407, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.407, Training Time: 46 seconds)
Epoch:  38/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.350, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.378, Training Time: 96 seconds)
Epoch:  38/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.369, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.375, Training Time: 147 seconds)
Epoch:  38/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.358, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.371, Training Time: 201 seconds)
Epoch:  38/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.374, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.372, Training Time: 257 seconds)
Epoch:  38/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.377, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.373, Training Time: 317 seconds)
Epoch:  38/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.392, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.375, Training Time: 379 seconds)
Epoch:  38/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.321, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.371, Training Time: 418 seconds)
Epoch:  38/100, Validation loss:  7.381, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  39/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.401, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.401, Training Time: 46 seconds)
Epoch:  39/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.344, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.373, Training Time: 96 seconds)
Epoch:  39/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.364, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.370, Training Time: 147 seconds)
Epoch:  39/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.352, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.365, Training Time: 200 seconds)
Epoch:  39/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.369, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.366, Training Time: 257 seconds)
Epoch:  39/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.372, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.367, Training Time: 316 seconds)
Epoch:  39/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.387, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.370, Training Time: 379 seconds)
Epoch:  39/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.316, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.365, Training Time: 418 seconds)
Epoch:  39/100, Validation loss:  7.377, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  40/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.396, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.396, Training Time: 46 seconds)
Epoch:  40/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.339, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.368, Training Time: 96 seconds)
Epoch:  40/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.358, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.365, Training Time: 147 seconds)
Epoch:  40/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.347, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.360, Training Time: 200 seconds)
Epoch:  40/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.364, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.361, Training Time: 257 seconds)
Epoch:  40/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.367, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.362, Training Time: 317 seconds)
Epoch:  40/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.381, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.365, Training Time: 379 seconds)
Epoch:  40/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.311, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.360, Training Time: 418 seconds)
Epoch:  40/100, Validation loss:  7.373, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  41/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.390, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.390, Training Time: 46 seconds)
Epoch:  41/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.334, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.362, Training Time: 96 seconds)
Epoch:  41/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.354, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.359, Training Time: 147 seconds)
Epoch:  41/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.342, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.355, Training Time: 201 seconds)
Epoch:  41/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.359, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.356, Training Time: 257 seconds)
Epoch:  41/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.362, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.357, Training Time: 317 seconds)
Epoch:  41/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.376, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.360, Training Time: 379 seconds)
Epoch:  41/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.306, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.355, Training Time: 418 seconds)
Epoch:  41/100, Validation loss:  7.367, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  42/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.383, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.383, Training Time: 46 seconds)
Epoch:  42/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.329, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.356, Training Time: 96 seconds)
Epoch:  42/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.349, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.354, Training Time: 147 seconds)
Epoch:  42/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.337, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.350, Training Time: 201 seconds)
Epoch:  42/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.355, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.351, Training Time: 257 seconds)
Epoch:  42/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.358, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.352, Training Time: 317 seconds)
Epoch:  42/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.373, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.355, Training Time: 379 seconds)
Epoch:  42/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.303, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.351, Training Time: 418 seconds)
Epoch:  42/100, Validation loss:  7.362, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  43/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.378, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.378, Training Time: 46 seconds)
Epoch:  43/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.324, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.351, Training Time: 96 seconds)
Epoch:  43/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.344, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.349, Training Time: 147 seconds)
Epoch:  43/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.333, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.345, Training Time: 201 seconds)
Epoch:  43/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.350, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.346, Training Time: 257 seconds)
Epoch:  43/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.353, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.347, Training Time: 317 seconds)
Epoch:  43/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.366, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.350, Training Time: 379 seconds)
Epoch:  43/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.296, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.345, Training Time: 418 seconds)
Epoch:  43/100, Validation loss:  7.358, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  44/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.373, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.373, Training Time: 46 seconds)
Epoch:  44/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.320, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.346, Training Time: 96 seconds)
Epoch:  44/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.340, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.344, Training Time: 147 seconds)
Epoch:  44/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.329, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.340, Training Time: 201 seconds)
Epoch:  44/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.346, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.341, Training Time: 257 seconds)
Epoch:  44/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.349, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.343, Training Time: 317 seconds)
Epoch:  44/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.363, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.346, Training Time: 379 seconds)
Epoch:  44/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.292, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.341, Training Time: 418 seconds)
Epoch:  44/100, Validation loss:  7.355, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  45/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.371, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.371, Training Time: 46 seconds)
Epoch:  45/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.315, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.343, Training Time: 96 seconds)
Epoch:  45/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.336, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.341, Training Time: 147 seconds)
Epoch:  45/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.325, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.337, Training Time: 201 seconds)
Epoch:  45/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.341, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.338, Training Time: 257 seconds)
Epoch:  45/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.344, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.339, Training Time: 317 seconds)
Epoch:  45/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.358, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.341, Training Time: 379 seconds)
Epoch:  45/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.290, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.337, Training Time: 418 seconds)
Epoch:  45/100, Validation loss:  7.349, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  46/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.363, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.363, Training Time: 46 seconds)
Epoch:  46/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.311, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.337, Training Time: 96 seconds)
Epoch:  46/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.332, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.335, Training Time: 147 seconds)
Epoch:  46/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.320, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.332, Training Time: 201 seconds)
Epoch:  46/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.337, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.333, Training Time: 257 seconds)
Epoch:  46/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.341, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.334, Training Time: 317 seconds)
Epoch:  46/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.352, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.337, Training Time: 379 seconds)
Epoch:  46/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.285, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.332, Training Time: 418 seconds)
Epoch:  46/100, Validation loss:  7.346, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  47/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.358, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.358, Training Time: 46 seconds)
Epoch:  47/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.307, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.333, Training Time: 96 seconds)
Epoch:  47/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.327, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.331, Training Time: 147 seconds)
Epoch:  47/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.317, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.327, Training Time: 201 seconds)
Epoch:  47/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.333, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.328, Training Time: 257 seconds)
Epoch:  47/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.337, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.330, Training Time: 317 seconds)
Epoch:  47/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.349, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.333, Training Time: 379 seconds)
Epoch:  47/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.281, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.328, Training Time: 418 seconds)
Epoch:  47/100, Validation loss:  7.341, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  48/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.354, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.354, Training Time: 46 seconds)
Epoch:  48/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.303, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.329, Training Time: 96 seconds)
Epoch:  48/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.324, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.327, Training Time: 147 seconds)
Epoch:  48/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.313, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.323, Training Time: 201 seconds)
Epoch:  48/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.329, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.325, Training Time: 257 seconds)
Epoch:  48/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.333, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.326, Training Time: 317 seconds)
Epoch:  48/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.345, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.329, Training Time: 379 seconds)
Epoch:  48/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.280, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.325, Training Time: 418 seconds)
Epoch:  48/100, Validation loss:  7.338, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  49/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.350, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.350, Training Time: 46 seconds)
Epoch:  49/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.299, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.325, Training Time: 96 seconds)
Epoch:  49/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.319, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.323, Training Time: 147 seconds)
Epoch:  49/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.309, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.319, Training Time: 201 seconds)
Epoch:  49/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.326, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.321, Training Time: 257 seconds)
Epoch:  49/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.329, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.322, Training Time: 317 seconds)
Epoch:  49/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.341, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.325, Training Time: 379 seconds)
Epoch:  49/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.274, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.321, Training Time: 418 seconds)
Epoch:  49/100, Validation loss:  7.335, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  50/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.347, Training Time: 47 seconds), Stats for epoch: (Training Loss:  7.347, Training Time: 47 seconds)
Epoch:  50/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.296, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.321, Training Time: 96 seconds)
Epoch:  50/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.316, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.320, Training Time: 147 seconds)
Epoch:  50/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.305, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.316, Training Time: 201 seconds)
Epoch:  50/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.322, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.317, Training Time: 257 seconds)
Epoch:  50/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.326, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.319, Training Time: 317 seconds)
Epoch:  50/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.339, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.322, Training Time: 379 seconds)
Epoch:  50/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.272, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.317, Training Time: 418 seconds)
Epoch:  50/100, Validation loss:  7.330, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  51/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.342, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.342, Training Time: 46 seconds)
Epoch:  51/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.292, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.317, Training Time: 96 seconds)
Epoch:  51/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.313, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.316, Training Time: 147 seconds)
Epoch:  51/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.302, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.312, Training Time: 201 seconds)
Epoch:  51/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.319, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.314, Training Time: 257 seconds)
Epoch:  51/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.322, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.315, Training Time: 317 seconds)
Epoch:  51/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.334, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.318, Training Time: 379 seconds)
Epoch:  51/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.268, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.313, Training Time: 418 seconds)
Epoch:  51/100, Validation loss:  7.327, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  52/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.340, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.340, Training Time: 46 seconds)
Epoch:  52/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.289, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.314, Training Time: 96 seconds)
Epoch:  52/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.309, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.312, Training Time: 147 seconds)
Epoch:  52/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.299, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.309, Training Time: 201 seconds)
Epoch:  52/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.315, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.310, Training Time: 257 seconds)
Epoch:  52/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.319, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.312, Training Time: 317 seconds)
Epoch:  52/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.330, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.314, Training Time: 379 seconds)
Epoch:  52/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.264, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.310, Training Time: 418 seconds)
Epoch:  52/100, Validation loss:  7.324, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  53/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.334, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.334, Training Time: 46 seconds)
Epoch:  53/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.285, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.310, Training Time: 96 seconds)
Epoch:  53/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.306, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.308, Training Time: 147 seconds)
Epoch:  53/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.295, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.305, Training Time: 201 seconds)
Epoch:  53/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.312, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.307, Training Time: 257 seconds)
Epoch:  53/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.316, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.308, Training Time: 317 seconds)
Epoch:  53/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.327, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.311, Training Time: 379 seconds)
Epoch:  53/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.265, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.307, Training Time: 419 seconds)
Epoch:  53/100, Validation loss:  7.319, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  54/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.332, Training Time: 47 seconds), Stats for epoch: (Training Loss:  7.332, Training Time: 47 seconds)
Epoch:  54/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.282, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.307, Training Time: 96 seconds)
Epoch:  54/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.303, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.306, Training Time: 147 seconds)
Epoch:  54/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.292, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.302, Training Time: 201 seconds)
Epoch:  54/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.309, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.304, Training Time: 257 seconds)
Epoch:  54/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.312, Training Time: 60 seconds), Stats for epoch: (Training Loss:  7.305, Training Time: 317 seconds)
Epoch:  54/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.324, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.308, Training Time: 379 seconds)
Epoch:  54/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.258, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.304, Training Time: 419 seconds)
Epoch:  54/100, Validation loss:  7.317, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  55/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.328, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.328, Training Time: 46 seconds)
Epoch:  55/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.279, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.303, Training Time: 96 seconds)
Epoch:  55/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.300, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.302, Training Time: 147 seconds)
Epoch:  55/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.289, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.299, Training Time: 201 seconds)
Epoch:  55/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.306, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.300, Training Time: 257 seconds)
Epoch:  55/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.309, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.302, Training Time: 317 seconds)
Epoch:  55/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.320, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.304, Training Time: 379 seconds)
Epoch:  55/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.255, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.300, Training Time: 418 seconds)
Epoch:  55/100, Validation loss:  7.315, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  56/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.325, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.325, Training Time: 46 seconds)
Epoch:  56/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.276, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.300, Training Time: 96 seconds)
Epoch:  56/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.297, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.299, Training Time: 147 seconds)
Epoch:  56/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.286, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.296, Training Time: 201 seconds)
Epoch:  56/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.303, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.297, Training Time: 257 seconds)
Epoch:  56/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.306, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.299, Training Time: 317 seconds)
Epoch:  56/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.318, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.302, Training Time: 379 seconds)
Epoch:  56/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.253, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.297, Training Time: 418 seconds)
Epoch:  56/100, Validation loss:  7.311, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  57/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.319, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.319, Training Time: 46 seconds)
Epoch:  57/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.273, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.296, Training Time: 96 seconds)
Epoch:  57/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.294, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.295, Training Time: 147 seconds)
Epoch:  57/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.283, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.292, Training Time: 201 seconds)
Epoch:  57/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.300, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.294, Training Time: 257 seconds)
Epoch:  57/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.303, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.295, Training Time: 317 seconds)
Epoch:  57/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.313, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.298, Training Time: 379 seconds)
Epoch:  57/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.251, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.294, Training Time: 418 seconds)
Epoch:  57/100, Validation loss:  7.308, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  58/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.315, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.315, Training Time: 46 seconds)
Epoch:  58/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.270, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.293, Training Time: 96 seconds)
Epoch:  58/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.291, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.292, Training Time: 147 seconds)
Epoch:  58/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.280, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.289, Training Time: 201 seconds)
Epoch:  58/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.298, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.291, Training Time: 257 seconds)
Epoch:  58/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.301, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.292, Training Time: 317 seconds)
Epoch:  58/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.310, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.295, Training Time: 379 seconds)
Epoch:  58/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.249, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.291, Training Time: 418 seconds)
Epoch:  58/100, Validation loss:  7.306, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  59/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.316, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.316, Training Time: 46 seconds)
Epoch:  59/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.267, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.292, Training Time: 96 seconds)
Epoch:  59/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.288, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.290, Training Time: 147 seconds)
Epoch:  59/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.277, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.287, Training Time: 200 seconds)
Epoch:  59/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.294, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.289, Training Time: 257 seconds)
Epoch:  59/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.298, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.290, Training Time: 317 seconds)
Epoch:  59/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.309, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.293, Training Time: 379 seconds)
Epoch:  59/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.245, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.289, Training Time: 418 seconds)
Epoch:  59/100, Validation loss:  7.303, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  60/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.312, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.312, Training Time: 46 seconds)
Epoch:  60/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.264, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.288, Training Time: 96 seconds)
Epoch:  60/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.285, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.287, Training Time: 147 seconds)
Epoch:  60/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.275, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.284, Training Time: 201 seconds)
Epoch:  60/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.292, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.286, Training Time: 257 seconds)
Epoch:  60/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.295, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.287, Training Time: 317 seconds)
Epoch:  60/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.307, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.290, Training Time: 379 seconds)
Epoch:  60/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.242, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.286, Training Time: 418 seconds)
Epoch:  60/100, Validation loss:  7.300, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  61/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.308, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.308, Training Time: 46 seconds)
Epoch:  61/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.262, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.285, Training Time: 96 seconds)
Epoch:  61/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.282, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.284, Training Time: 147 seconds)
Epoch:  61/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.272, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.281, Training Time: 201 seconds)
Epoch:  61/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.289, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.283, Training Time: 257 seconds)
Epoch:  61/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.293, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.284, Training Time: 317 seconds)
Epoch:  61/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.304, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.287, Training Time: 379 seconds)
Epoch:  61/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.241, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.283, Training Time: 418 seconds)
Epoch:  61/100, Validation loss:  7.297, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  62/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.306, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.306, Training Time: 46 seconds)
Epoch:  62/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.259, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.282, Training Time: 96 seconds)
Epoch:  62/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.280, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.282, Training Time: 147 seconds)
Epoch:  62/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.269, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.279, Training Time: 201 seconds)
Epoch:  62/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.287, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.280, Training Time: 257 seconds)
Epoch:  62/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.290, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.282, Training Time: 317 seconds)
Epoch:  62/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.301, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.285, Training Time: 379 seconds)
Epoch:  62/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.238, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.281, Training Time: 418 seconds)
Epoch:  62/100, Validation loss:  7.295, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  63/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.303, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.303, Training Time: 46 seconds)
Epoch:  63/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.257, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.280, Training Time: 96 seconds)
Epoch:  63/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.277, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.279, Training Time: 147 seconds)
Epoch:  63/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.267, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.276, Training Time: 201 seconds)
Epoch:  63/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.284, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.277, Training Time: 257 seconds)
Epoch:  63/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.288, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.279, Training Time: 317 seconds)
Epoch:  63/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.297, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.282, Training Time: 379 seconds)
Epoch:  63/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.235, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.278, Training Time: 418 seconds)
Epoch:  63/100, Validation loss:  7.293, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  64/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.300, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.300, Training Time: 46 seconds)
Epoch:  64/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.254, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.277, Training Time: 96 seconds)
Epoch:  64/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.275, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.276, Training Time: 147 seconds)
Epoch:  64/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.265, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.273, Training Time: 201 seconds)
Epoch:  64/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.282, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.275, Training Time: 257 seconds)
Epoch:  64/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.285, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.277, Training Time: 317 seconds)
Epoch:  64/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.300, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.280, Training Time: 379 seconds)
Epoch:  64/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.233, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.276, Training Time: 418 seconds)
Epoch:  64/100, Validation loss:  7.290, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  65/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.297, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.297, Training Time: 46 seconds)
Epoch:  65/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.252, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.274, Training Time: 96 seconds)
Epoch:  65/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.273, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.274, Training Time: 147 seconds)
Epoch:  65/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.262, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.271, Training Time: 201 seconds)
Epoch:  65/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.280, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.273, Training Time: 257 seconds)
Epoch:  65/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.283, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.274, Training Time: 317 seconds)
Epoch:  65/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.292, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.277, Training Time: 379 seconds)
Epoch:  65/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.231, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.273, Training Time: 418 seconds)
Epoch:  65/100, Validation loss:  7.288, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  66/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.294, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.294, Training Time: 46 seconds)
Epoch:  66/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.249, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.272, Training Time: 96 seconds)
Epoch:  66/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.270, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.271, Training Time: 147 seconds)
Epoch:  66/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.260, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.268, Training Time: 201 seconds)
Epoch:  66/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.277, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.270, Training Time: 257 seconds)
Epoch:  66/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.281, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.272, Training Time: 317 seconds)
Epoch:  66/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.290, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.274, Training Time: 379 seconds)
Epoch:  66/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.229, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.271, Training Time: 418 seconds)
Epoch:  66/100, Validation loss:  7.286, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  67/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.292, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.292, Training Time: 46 seconds)
Epoch:  67/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.247, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.269, Training Time: 96 seconds)
Epoch:  67/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.268, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.269, Training Time: 147 seconds)
Epoch:  67/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.258, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.266, Training Time: 201 seconds)
Epoch:  67/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.275, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.268, Training Time: 257 seconds)
Epoch:  67/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.279, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.270, Training Time: 317 seconds)
Epoch:  67/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.288, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.272, Training Time: 379 seconds)
Epoch:  67/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.226, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.268, Training Time: 418 seconds)
Epoch:  67/100, Validation loss:  7.283, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  68/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.289, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.289, Training Time: 46 seconds)
Epoch:  68/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.245, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.267, Training Time: 96 seconds)
Epoch:  68/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.266, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.266, Training Time: 147 seconds)
Epoch:  68/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.255, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.264, Training Time: 201 seconds)
Epoch:  68/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.273, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.265, Training Time: 257 seconds)
Epoch:  68/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.276, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.267, Training Time: 317 seconds)
Epoch:  68/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.286, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.270, Training Time: 379 seconds)
Epoch:  68/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.224, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.266, Training Time: 418 seconds)
Epoch:  68/100, Validation loss:  7.282, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  69/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.286, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.286, Training Time: 46 seconds)
Epoch:  69/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.242, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.264, Training Time: 96 seconds)
Epoch:  69/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.264, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.264, Training Time: 147 seconds)
Epoch:  69/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.253, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.261, Training Time: 201 seconds)
Epoch:  69/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.271, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.263, Training Time: 257 seconds)
Epoch:  69/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.274, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.265, Training Time: 317 seconds)
Epoch:  69/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.283, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.268, Training Time: 379 seconds)
Epoch:  69/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.222, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.264, Training Time: 418 seconds)
Epoch:  69/100, Validation loss:  7.279, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  70/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.284, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.284, Training Time: 46 seconds)
Epoch:  70/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.240, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.262, Training Time: 96 seconds)
Epoch:  70/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.262, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.262, Training Time: 147 seconds)
Epoch:  70/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.251, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.259, Training Time: 201 seconds)
Epoch:  70/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.269, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.261, Training Time: 257 seconds)
Epoch:  70/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.272, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.263, Training Time: 317 seconds)
Epoch:  70/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.281, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.266, Training Time: 379 seconds)
Epoch:  70/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.220, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.262, Training Time: 418 seconds)
Epoch:  70/100, Validation loss:  7.277, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  71/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.282, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.282, Training Time: 46 seconds)
Epoch:  71/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.238, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.260, Training Time: 96 seconds)
Epoch:  71/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.259, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.260, Training Time: 147 seconds)
Epoch:  71/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.249, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.257, Training Time: 201 seconds)
Epoch:  71/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.267, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.259, Training Time: 257 seconds)
Epoch:  71/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.270, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.261, Training Time: 317 seconds)
Epoch:  71/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.283, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.264, Training Time: 379 seconds)
Epoch:  71/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.219, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.260, Training Time: 418 seconds)
Epoch:  71/100, Validation loss:  7.275, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  72/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.279, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.279, Training Time: 46 seconds)
Epoch:  72/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.236, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.258, Training Time: 96 seconds)
Epoch:  72/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.258, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.258, Training Time: 147 seconds)
Epoch:  72/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.247, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.255, Training Time: 201 seconds)
Epoch:  72/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.265, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.257, Training Time: 257 seconds)
Epoch:  72/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.268, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.259, Training Time: 317 seconds)
Epoch:  72/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.277, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.261, Training Time: 379 seconds)
Epoch:  72/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.217, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.258, Training Time: 418 seconds)
Epoch:  72/100, Validation loss:  7.274, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  73/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.277, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.277, Training Time: 46 seconds)
Epoch:  73/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.234, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.255, Training Time: 96 seconds)
Epoch:  73/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.256, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.255, Training Time: 147 seconds)
Epoch:  73/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.245, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.253, Training Time: 201 seconds)
Epoch:  73/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.263, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.255, Training Time: 257 seconds)
Epoch:  73/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.266, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.257, Training Time: 317 seconds)
Epoch:  73/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.275, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.259, Training Time: 379 seconds)
Epoch:  73/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.215, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.256, Training Time: 418 seconds)
Epoch:  73/100, Validation loss:  7.271, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  74/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.273, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.273, Training Time: 46 seconds)
Epoch:  74/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.233, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.253, Training Time: 96 seconds)
Epoch:  74/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.253, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.253, Training Time: 147 seconds)
Epoch:  74/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.243, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.250, Training Time: 201 seconds)
Epoch:  74/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.261, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.253, Training Time: 257 seconds)
Epoch:  74/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.265, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.255, Training Time: 317 seconds)
Epoch:  74/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.273, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.257, Training Time: 379 seconds)
Epoch:  74/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.215, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.254, Training Time: 418 seconds)
Epoch:  74/100, Validation loss:  7.270, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  75/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.272, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.272, Training Time: 46 seconds)
Epoch:  75/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.231, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.251, Training Time: 96 seconds)
Epoch:  75/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.252, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.251, Training Time: 147 seconds)
Epoch:  75/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.241, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.249, Training Time: 201 seconds)
Epoch:  75/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.259, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.251, Training Time: 257 seconds)
Epoch:  75/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.262, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.253, Training Time: 317 seconds)
Epoch:  75/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.271, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.255, Training Time: 379 seconds)
Epoch:  75/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.211, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.252, Training Time: 418 seconds)
Epoch:  75/100, Validation loss:  7.268, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  76/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.270, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.270, Training Time: 46 seconds)
Epoch:  76/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.228, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.249, Training Time: 96 seconds)
Epoch:  76/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.250, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.250, Training Time: 147 seconds)
Epoch:  76/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.240, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.247, Training Time: 201 seconds)
Epoch:  76/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.257, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.249, Training Time: 257 seconds)
Epoch:  76/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.261, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.251, Training Time: 317 seconds)
Epoch:  76/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.270, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.254, Training Time: 379 seconds)
Epoch:  76/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.210, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.250, Training Time: 418 seconds)
Epoch:  76/100, Validation loss:  7.266, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  77/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.268, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.268, Training Time: 46 seconds)
Epoch:  77/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.227, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.247, Training Time: 96 seconds)
Epoch:  77/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.248, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.248, Training Time: 147 seconds)
Epoch:  77/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.238, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.245, Training Time: 201 seconds)
Epoch:  77/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.256, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.247, Training Time: 257 seconds)
Epoch:  77/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.259, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.249, Training Time: 317 seconds)
Epoch:  77/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.267, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.252, Training Time: 379 seconds)
Epoch:  77/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.208, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.248, Training Time: 418 seconds)
Epoch:  77/100, Validation loss:  7.265, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  78/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.264, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.264, Training Time: 46 seconds)
Epoch:  78/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.225, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.244, Training Time: 96 seconds)
Epoch:  78/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.246, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.245, Training Time: 147 seconds)
Epoch:  78/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.236, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.243, Training Time: 201 seconds)
Epoch:  78/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.253, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.245, Training Time: 257 seconds)
Epoch:  78/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.257, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.247, Training Time: 317 seconds)
Epoch:  78/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.270, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.250, Training Time: 379 seconds)
Epoch:  78/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.207, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.247, Training Time: 418 seconds)
Epoch:  78/100, Validation loss:  7.263, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  79/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.264, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.264, Training Time: 46 seconds)
Epoch:  79/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.223, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.244, Training Time: 96 seconds)
Epoch:  79/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.244, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.244, Training Time: 147 seconds)
Epoch:  79/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.234, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.242, Training Time: 201 seconds)
Epoch:  79/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.252, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.244, Training Time: 257 seconds)
Epoch:  79/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.255, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.246, Training Time: 317 seconds)
Epoch:  79/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.264, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.248, Training Time: 379 seconds)
Epoch:  79/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.205, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.245, Training Time: 418 seconds)
Epoch:  79/100, Validation loss:  7.261, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  80/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.263, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.263, Training Time: 46 seconds)
Epoch:  80/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.221, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.242, Training Time: 96 seconds)
Epoch:  80/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.243, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.242, Training Time: 147 seconds)
Epoch:  80/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.233, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.240, Training Time: 201 seconds)
Epoch:  80/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.251, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.242, Training Time: 257 seconds)
Epoch:  80/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.254, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.244, Training Time: 317 seconds)
Epoch:  80/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.262, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.247, Training Time: 379 seconds)
Epoch:  80/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.204, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.243, Training Time: 418 seconds)
Epoch:  80/100, Validation loss:  7.260, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  81/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.259, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.259, Training Time: 46 seconds)
Epoch:  81/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.220, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.239, Training Time: 96 seconds)
Epoch:  81/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.241, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.240, Training Time: 147 seconds)
Epoch:  81/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.231, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.238, Training Time: 201 seconds)
Epoch:  81/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.249, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.240, Training Time: 257 seconds)
Epoch:  81/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.252, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.242, Training Time: 317 seconds)
Epoch:  81/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.261, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.245, Training Time: 379 seconds)
Epoch:  81/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.202, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.241, Training Time: 418 seconds)
Epoch:  81/100, Validation loss:  7.258, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  82/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.257, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.257, Training Time: 46 seconds)
Epoch:  82/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.218, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.238, Training Time: 96 seconds)
Epoch:  82/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.240, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.238, Training Time: 147 seconds)
Epoch:  82/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.230, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.236, Training Time: 201 seconds)
Epoch:  82/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.247, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.238, Training Time: 257 seconds)
Epoch:  82/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.250, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.240, Training Time: 317 seconds)
Epoch:  82/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.259, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.243, Training Time: 379 seconds)
Epoch:  82/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.201, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.239, Training Time: 418 seconds)
Epoch:  82/100, Validation loss:  7.256, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  83/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.255, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.255, Training Time: 46 seconds)
Epoch:  83/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.216, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.236, Training Time: 96 seconds)
Epoch:  83/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.238, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.236, Training Time: 147 seconds)
Epoch:  83/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.228, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.234, Training Time: 201 seconds)
Epoch:  83/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.245, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.237, Training Time: 257 seconds)
Epoch:  83/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.249, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.239, Training Time: 317 seconds)
Epoch:  83/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.258, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.241, Training Time: 379 seconds)
Epoch:  83/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.199, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.238, Training Time: 418 seconds)
Epoch:  83/100, Validation loss:  7.255, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  84/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.252, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.252, Training Time: 46 seconds)
Epoch:  84/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.215, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.234, Training Time: 96 seconds)
Epoch:  84/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.236, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.235, Training Time: 147 seconds)
Epoch:  84/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.226, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.233, Training Time: 201 seconds)
Epoch:  84/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.244, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.235, Training Time: 257 seconds)
Epoch:  84/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.248, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.237, Training Time: 317 seconds)
Epoch:  84/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.256, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.240, Training Time: 379 seconds)
Epoch:  84/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.198, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.236, Training Time: 418 seconds)
Epoch:  84/100, Validation loss:  7.254, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  85/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.252, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.252, Training Time: 46 seconds)
Epoch:  85/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.213, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.233, Training Time: 96 seconds)
Epoch:  85/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.235, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.233, Training Time: 147 seconds)
Epoch:  85/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.225, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.231, Training Time: 201 seconds)
Epoch:  85/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.242, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.233, Training Time: 257 seconds)
Epoch:  85/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.246, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.236, Training Time: 317 seconds)
Epoch:  85/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.254, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.238, Training Time: 379 seconds)
Epoch:  85/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.196, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.235, Training Time: 418 seconds)
Epoch:  85/100, Validation loss:  7.252, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  86/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.249, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.249, Training Time: 46 seconds)
Epoch:  86/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.212, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.230, Training Time: 96 seconds)
Epoch:  86/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.233, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.231, Training Time: 147 seconds)
Epoch:  86/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.223, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.229, Training Time: 201 seconds)
Epoch:  86/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.241, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.232, Training Time: 257 seconds)
Epoch:  86/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.244, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.234, Training Time: 317 seconds)
Epoch:  86/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.253, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.236, Training Time: 379 seconds)
Epoch:  86/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.195, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.233, Training Time: 418 seconds)
Epoch:  86/100, Validation loss:  7.251, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  87/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.248, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.248, Training Time: 46 seconds)
Epoch:  87/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.210, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.229, Training Time: 96 seconds)
Epoch:  87/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.232, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.230, Training Time: 147 seconds)
Epoch:  87/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.222, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.228, Training Time: 201 seconds)
Epoch:  87/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.240, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.230, Training Time: 257 seconds)
Epoch:  87/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.243, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.233, Training Time: 317 seconds)
Epoch:  87/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.251, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.235, Training Time: 379 seconds)
Epoch:  87/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.194, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.232, Training Time: 418 seconds)
Epoch:  87/100, Validation loss:  7.249, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  88/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.246, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.246, Training Time: 46 seconds)
Epoch:  88/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.209, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.227, Training Time: 96 seconds)
Epoch:  88/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.231, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.229, Training Time: 147 seconds)
Epoch:  88/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.221, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.227, Training Time: 201 seconds)
Epoch:  88/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.238, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.229, Training Time: 257 seconds)
Epoch:  88/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.242, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.231, Training Time: 317 seconds)
Epoch:  88/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.250, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.234, Training Time: 379 seconds)
Epoch:  88/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.192, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.230, Training Time: 418 seconds)
Epoch:  88/100, Validation loss:  7.248, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  89/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.242, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.242, Training Time: 46 seconds)
Epoch:  89/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.207, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.225, Training Time: 96 seconds)
Epoch:  89/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.229, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.226, Training Time: 147 seconds)
Epoch:  89/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.219, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.225, Training Time: 201 seconds)
Epoch:  89/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.237, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.227, Training Time: 257 seconds)
Epoch:  89/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.240, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.229, Training Time: 317 seconds)
Epoch:  89/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.249, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.232, Training Time: 379 seconds)
Epoch:  89/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.191, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.229, Training Time: 418 seconds)
Epoch:  89/100, Validation loss:  7.247, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  90/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.244, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.244, Training Time: 46 seconds)
Epoch:  90/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.206, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.225, Training Time: 96 seconds)
Epoch:  90/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.228, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.226, Training Time: 147 seconds)
Epoch:  90/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.218, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.224, Training Time: 201 seconds)
Epoch:  90/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.235, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.226, Training Time: 257 seconds)
Epoch:  90/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.239, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.228, Training Time: 317 seconds)
Epoch:  90/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.247, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.231, Training Time: 379 seconds)
Epoch:  90/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.189, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.228, Training Time: 418 seconds)
Epoch:  90/100, Validation loss:  7.245, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  91/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.239, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.239, Training Time: 46 seconds)
Epoch:  91/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.205, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.222, Training Time: 96 seconds)
Epoch:  91/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.226, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.223, Training Time: 147 seconds)
Epoch:  91/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.216, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.222, Training Time: 201 seconds)
Epoch:  91/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.234, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.224, Training Time: 257 seconds)
Epoch:  91/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.238, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.226, Training Time: 317 seconds)
Epoch:  91/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.246, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.229, Training Time: 379 seconds)
Epoch:  91/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.189, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.226, Training Time: 418 seconds)
Epoch:  91/100, Validation loss:  7.244, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  92/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.241, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.241, Training Time: 46 seconds)
Epoch:  92/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.203, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.222, Training Time: 96 seconds)
Epoch:  92/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.225, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.223, Training Time: 147 seconds)
Epoch:  92/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.215, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.221, Training Time: 201 seconds)
Epoch:  92/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.233, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.223, Training Time: 257 seconds)
Epoch:  92/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.236, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.226, Training Time: 317 seconds)
Epoch:  92/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.244, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.228, Training Time: 379 seconds)
Epoch:  92/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.187, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.225, Training Time: 418 seconds)
Epoch:  92/100, Validation loss:  7.243, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  93/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.238, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.238, Training Time: 46 seconds)
Epoch:  93/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.202, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.220, Training Time: 96 seconds)
Epoch:  93/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.224, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.221, Training Time: 147 seconds)
Epoch:  93/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.214, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.219, Training Time: 201 seconds)
Epoch:  93/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.231, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.222, Training Time: 257 seconds)
Epoch:  93/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.235, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.224, Training Time: 317 seconds)
Epoch:  93/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.243, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.227, Training Time: 379 seconds)
Epoch:  93/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.186, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.223, Training Time: 418 seconds)
Epoch:  93/100, Validation loss:  7.241, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  94/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.235, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.235, Training Time: 46 seconds)
Epoch:  94/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.201, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.218, Training Time: 96 seconds)
Epoch:  94/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.223, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.219, Training Time: 147 seconds)
Epoch:  94/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.213, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.218, Training Time: 201 seconds)
Epoch:  94/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.230, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.220, Training Time: 257 seconds)
Epoch:  94/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.234, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.223, Training Time: 317 seconds)
Epoch:  94/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.242, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.225, Training Time: 379 seconds)
Epoch:  94/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.185, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.222, Training Time: 418 seconds)
Epoch:  94/100, Validation loss:  7.240, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  95/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.235, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.235, Training Time: 46 seconds)
Epoch:  95/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.199, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.217, Training Time: 96 seconds)
Epoch:  95/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.221, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.219, Training Time: 147 seconds)
Epoch:  95/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.211, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.217, Training Time: 201 seconds)
Epoch:  95/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.229, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.219, Training Time: 257 seconds)
Epoch:  95/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.233, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.221, Training Time: 317 seconds)
Epoch:  95/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.241, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.224, Training Time: 379 seconds)
Epoch:  95/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.184, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.221, Training Time: 418 seconds)
Epoch:  95/100, Validation loss:  7.239, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  96/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.234, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.234, Training Time: 46 seconds)
Epoch:  96/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.198, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.216, Training Time: 96 seconds)
Epoch:  96/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.220, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.217, Training Time: 147 seconds)
Epoch:  96/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.210, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.215, Training Time: 201 seconds)
Epoch:  96/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.228, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.218, Training Time: 257 seconds)
Epoch:  96/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.231, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.220, Training Time: 317 seconds)
Epoch:  96/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.240, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.223, Training Time: 379 seconds)
Epoch:  96/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.183, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.220, Training Time: 418 seconds)
Epoch:  96/100, Validation loss:  7.237, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  97/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.230, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.230, Training Time: 46 seconds)
Epoch:  97/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.197, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.213, Training Time: 96 seconds)
Epoch:  97/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.219, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.215, Training Time: 147 seconds)
Epoch:  97/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.209, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.213, Training Time: 201 seconds)
Epoch:  97/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.227, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.216, Training Time: 257 seconds)
Epoch:  97/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.230, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.218, Training Time: 317 seconds)
Epoch:  97/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.238, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.221, Training Time: 379 seconds)
Epoch:  97/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.181, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.218, Training Time: 418 seconds)
Epoch:  97/100, Validation loss:  7.237, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  98/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.231, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.231, Training Time: 46 seconds)
Epoch:  98/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.196, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.213, Training Time: 96 seconds)
Epoch:  98/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.218, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.215, Training Time: 147 seconds)
Epoch:  98/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.208, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.213, Training Time: 201 seconds)
Epoch:  98/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.226, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.216, Training Time: 257 seconds)
Epoch:  98/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.229, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.218, Training Time: 317 seconds)
Epoch:  98/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.237, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.221, Training Time: 379 seconds)
Epoch:  98/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.180, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.217, Training Time: 418 seconds)
Epoch:  98/100, Validation loss:  7.235, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch:  99/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.228, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.228, Training Time: 46 seconds)
Epoch:  99/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.194, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.211, Training Time: 96 seconds)
Epoch:  99/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.216, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.213, Training Time: 147 seconds)
Epoch:  99/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.206, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.211, Training Time: 201 seconds)
Epoch:  99/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.224, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.214, Training Time: 257 seconds)
Epoch:  99/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.228, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.216, Training Time: 317 seconds)
Epoch:  99/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.236, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.219, Training Time: 379 seconds)
Epoch:  99/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.179, Training Time: 38 seconds), Stats for epoch: (Training Loss:  7.216, Training Time: 418 seconds)
Epoch:  99/100, Validation loss:  7.234, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Epoch: 100/100, Batch:  100/763, Stats for last 100 batches: (Training Loss:  7.227, Training Time: 46 seconds), Stats for epoch: (Training Loss:  7.227, Training Time: 46 seconds)
Epoch: 100/100, Batch:  200/763, Stats for last 100 batches: (Training Loss:  7.193, Training Time: 49 seconds), Stats for epoch: (Training Loss:  7.210, Training Time: 96 seconds)
Epoch: 100/100, Batch:  300/763, Stats for last 100 batches: (Training Loss:  7.215, Training Time: 51 seconds), Stats for epoch: (Training Loss:  7.212, Training Time: 147 seconds)
Epoch: 100/100, Batch:  400/763, Stats for last 100 batches: (Training Loss:  7.206, Training Time: 53 seconds), Stats for epoch: (Training Loss:  7.210, Training Time: 201 seconds)
Epoch: 100/100, Batch:  500/763, Stats for last 100 batches: (Training Loss:  7.223, Training Time: 56 seconds), Stats for epoch: (Training Loss:  7.213, Training Time: 257 seconds)
Epoch: 100/100, Batch:  600/763, Stats for last 100 batches: (Training Loss:  7.227, Training Time: 59 seconds), Stats for epoch: (Training Loss:  7.215, Training Time: 317 seconds)
Epoch: 100/100, Batch:  700/763, Stats for last 100 batches: (Training Loss:  7.235, Training Time: 62 seconds), Stats for epoch: (Training Loss:  7.218, Training Time: 379 seconds)
Epoch: 100/100, Batch:  763/763, Stats for last 63 batches: (Training Loss:  7.178, Training Time: 39 seconds), Stats for epoch: (Training Loss:  7.215, Training Time: 418 seconds)
Epoch: 100/100, Validation loss:  7.233, Batch Validation Time: 35 seconds
Training loss improved!
Validation loss improved!
Training Complete!
