{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prueba_de_chatbots.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swALc1OXSa7Q"
      },
      "source": [
        "# Chatterbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTyHGX9-RkyL",
        "outputId": "1ab541ba-efd0-4927-f197-d493a93c1764",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install chatterbot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chatterbot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/21/85c2b114bd9dfabdd46ba58fc4519acdaed45d8c70898d40079e37a45e67/ChatterBot-1.0.8-py2.py3-none-any.whl (63kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 20kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 40kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n",
            "\u001b[?25hCollecting mathparse<0.2,>=0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/e5/4910fb85950cb960fcf3f5aabe1c8e55f5c9201788a1c1302b570a7e1f84/mathparse-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2.8.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied: sqlalchemy<1.4,>=1.3 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (1.3.19)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
            "Installing collected packages: mathparse, chatterbot\n",
            "Successfully installed chatterbot-1.0.8 mathparse-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3u7vl4JSgw1"
      },
      "source": [
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BX0zaDNXcwW",
        "outputId": "2cbc4711-984f-4a06-eaab-ed226f93e3e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chatbot = ChatBot('Testing bot')\n",
        "trainer = ListTrainer(chatbot, show_training_progress=True)\n",
        "\n",
        "trainer.train([\n",
        "    \"Hi, can I help you?\",\n",
        "    \"Sure, I'd like to book a flight to Iceland.\",\n",
        "    \"Your flight has been booked.\"\n",
        "])\n",
        "\n",
        "# Get a response to the input text 'I would like to book a flight.'\n",
        "response = chatbot.get_response('I would like to book a flight.')\n",
        "\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n",
            "Hi, can I help you?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNlX0jqxw2s5"
      },
      "source": [
        "# suriyadeepan practical_seq2seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNmxclvKw6II",
        "outputId": "95cc95d0-d54a-4edf-ee16-a7e7356c706e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/suriyadeepan/practical_seq2seq.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'practical_seq2seq'...\n",
            "remote: Enumerating objects: 167, done.\u001b[K\n",
            "remote: Total 167 (delta 0), reused 0 (delta 0), pack-reused 167\n",
            "Receiving objects: 100% (167/167), 7.13 MiB | 5.71 MiB/s, done.\n",
            "Resolving deltas: 100% (73/73), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m76elolKxeOJ",
        "outputId": "c63a8263-26ad-4cf9-cb32-22a78bedf687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd practical_seq2seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/practical_seq2seq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdEsHgoXxxuo",
        "outputId": "c0308c9e-11b5-4c2f-ea67-1b17b17fda81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install tensorflow==1.0.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/58/b71480f9ec9d08d581d672a81b15ab5fec36a5fcda2093558a23614d8468/tensorflow-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (44.5MB)\n",
            "\u001b[K     |████████████████████████████████| 44.5MB 65kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->tensorflow==1.0.0) (50.3.0)\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed tensorflow-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtCfjOJMxsNl",
        "outputId": "4f4cb31b-cd8a-4818-e0d6-7081987dbd49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# preprocessed data\n",
        "from datasets.twitter import data\n",
        "import data_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:474: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:475: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMpjixJiyLVo",
        "outputId": "fab2d089-e56c-4a9e-d620-e95876159216",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/practical_seq2seq/datasets/twitter/data.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">> Read lines from file\n",
            "\n",
            ":: Sample from read(p) lines\n",
            "[]\n",
            "\n",
            ">> Filter lines\n",
            "[]\n",
            "\n",
            ">> 2nd layer of filtering\n",
            "10% filtered from original data\n",
            "\n",
            "q : hola como estas ; a : yo bien y t\n",
            "\n",
            "q : tambin estoy bien es un hermoso da ; a : lo es este da soleado me encanta\n",
            "\n",
            ">> Segment lines into words\n",
            "\n",
            ":: Sample from segmented list of words\n",
            "\n",
            "q : ['hola', 'como', 'estas'] ; a : ['yo', 'bien', 'y', 't']\n",
            "\n",
            "q : ['tambin', 'estoy', 'bien', 'es', 'un', 'hermoso', 'da'] ; a : ['lo', 'es', 'este', 'da', 'soleado', 'me', 'encanta']\n",
            "\n",
            " >> Index words\n",
            "\n",
            " >> Zero Padding\n",
            "\n",
            " >> Save numpy arrays to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXodIYjmxjA5",
        "outputId": "2898fc6f-6472-4484-9110-4ff0b292fc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        }
      },
      "source": [
        "# load data from pickle and npy files\n",
        "metadata, idx_q, idx_a = data.load_data(PATH='/content/practical_seq2seq/datasets/twitter/')\n",
        "(trainX, trainY), (testX, testY), (validX, validY) = data_utils.split_dataset(idx_q, idx_a)\n",
        "print(trainX)\n",
        "# parameters \n",
        "xseq_len = trainX.shape[-1]\n",
        "yseq_len = trainY.shape[-1]\n",
        "batch_size = 1\n",
        "xvocab_size = len(metadata['idx2w'])  \n",
        "yvocab_size = xvocab_size\n",
        "emb_dim = 1024\n",
        "\n",
        "import seq2seq_wrapper\n",
        "\n",
        "# In[7]:\n",
        "\n",
        "model = seq2seq_wrapper.Seq2Seq(xseq_len=xseq_len,\n",
        "                               yseq_len=yseq_len,\n",
        "                               xvocab_size=xvocab_size,\n",
        "                               yvocab_size=yvocab_size,\n",
        "                               ckpt_path='ckpt/twitter/',\n",
        "                               emb_dim=emb_dim,\n",
        "                               num_layers=3,\n",
        "                               epochs=10\n",
        "                               )\n",
        "\n",
        "\n",
        "# In[8]:\n",
        "\n",
        "val_batch_gen = data_utils.rand_batch_gen(validX, validY, 32)\n",
        "train_batch_gen = data_utils.rand_batch_gen(trainX, trainY, batch_size)\n",
        "\n",
        "# In[9]:\n",
        "sess = model.restore_last_session()\n",
        "sess = model.train(train_batch_gen, val_batch_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[19 20 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [22 23 10  7  8 24  4  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 5 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [26 27 28 29  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [30 31  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [32  2 33 34 11 35  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "<log> Building Graph </log>\n",
            "<log> Training started </log>\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1f01c23fdff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# In[9]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_last_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/practical_seq2seq/seq2seq_wrapper.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_set, valid_set, sess)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;31m# evaluate to get validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# TODO : and this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                 \u001b[0;31m# print stats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nModel saved to disk at iteration #{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/practical_seq2seq/seq2seq_wrapper.py\u001b[0m in \u001b[0;36meval_batches\u001b[0;34m(self, sess, eval_batch_gen, num_batches)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mloss_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_op_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_batch_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/practical_seq2seq/seq2seq_wrapper.py\u001b[0m in \u001b[0;36meval_step\u001b[0;34m(self, sess, eval_batch_gen)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_batch_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# get batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mbatchX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_batch_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;31m# build feed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/practical_seq2seq/data_utils.py\u001b[0m in \u001b[0;36mrand_batch_gen\u001b[0;34m(x, y, batch_size)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrand_batch_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0msample_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMfEKzRjX5Vq"
      },
      "source": [
        "# Marsan-Ma-zz / tf_chatbot_seq2seq_antilm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsJjYV2UX9gl",
        "outputId": "dafce07b-e293-4488-dfff-28071160f066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Marsan-Ma-zz/tf_chatbot_seq2seq_antilm.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tf_chatbot_seq2seq_antilm'...\n",
            "remote: Enumerating objects: 214, done.\u001b[K\n",
            "remote: Total 214 (delta 0), reused 0 (delta 0), pack-reused 214\u001b[K\n",
            "Receiving objects: 100% (214/214), 11.17 MiB | 7.54 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyHd8T26YZN3",
        "outputId": "af75bd93-cfc0-45b0-ae08-61d20780a230",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install tensorflow==1.0.0 jieba"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.0.0 in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (0.42.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (0.35.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->tensorflow==1.0.0) (50.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiEaxeCoZZ_q",
        "outputId": "a86fdd19-b339-4b5d-ccf0-ad729d39fd6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd tf_chatbot_seq2seq_antilm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/tf_chatbot_seq2seq_antilm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VOPLT5Kb7dM",
        "outputId": "466bef14-5577-4ed3-8825-9e5418e1ee35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "practical_seq2seq  sample_data\ttf_chatbot_seq2seq_antilm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjLXAPj3ZfT2",
        "outputId": "8e38e5b2-02a1-4b9b-c68e-4eb59fb44eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 /content/tf_chatbot_seq2seq_antilm/main.py --mode train --model_name lyrics_ptt --steps_per_checkpoint 1 --batch_size=2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:474: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:475: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "[args]:  Namespace(antilm=0, batch_size=2, beam_size=1, buckets=[(5, 10), (10, 15), (20, 25), (40, 50)], data_dir='works/lyrics_ptt/data', en_tfboard=0, gpu_usage=1.0, learning_rate=0.5, learning_rate_decay_factor=0.99, max_gradient_norm=5.0, max_train_data_size=0, mert_dataset_path='works/lyrics_ptt/data/test/mert_set.txt', mode='train', model_dir='works/lyrics_ptt/nn_models', model_name='lyrics_ptt', n_bonus=0, num_layers=4, reinforce_learn=0, results_dir='works/lyrics_ptt/results', rev_model=0, scope_name='lyrics_ptt', size=256, steps_per_checkpoint=1, test_dataset_path='works/lyrics_ptt/data/test/test_set.txt', tf_board_dir='works/lyrics_ptt/tf_board', vocab_size=100000, work_root='works', workspace='works/lyrics_ptt')\n",
            "[lyrics_ptt] Preparing dialog data in works/lyrics_ptt/data\n",
            "works/lyrics_ptt\n",
            "works/lyrics_ptt\n",
            "works/lyrics_ptt\n",
            "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
            "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
            "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
            "Creating 4 layers of 256 units.\n",
            "Reading model parameters from works/lyrics_ptt/nn_models/model.ckpt-2 @ 2020-10-07 19:20:12.625273\n",
            "Model reloaded @ 2020-10-07 19:20:17.385318\n",
            "Reading development and training data (limit: 0).\n",
            "global step 3 learning rate 0.5000 step-time 1.27 perplexity 83039.06 @ 2020-10-07 19:20:19.397810\n",
            "  eval: bucket 0 perplexity 81175.67\n",
            "  eval: bucket 1 perplexity 72664.99\n",
            "  eval: bucket 2 perplexity 80998.28\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/tf_chatbot_seq2seq_antilm/main.py\", line 28, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\n",
            "    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n",
            "  File \"/content/tf_chatbot_seq2seq_antilm/main.py\", line 18, in main\n",
            "    train(args)\n",
            "  File \"/content/tf_chatbot_seq2seq_antilm/lib/train.py\", line 114, in train\n",
            "    encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)\n",
            "  File \"/content/tf_chatbot_seq2seq_antilm/lib/seq2seq_model.py\", line 454, in get_batch\n",
            "    encoder_input, decoder_input = random.choice(data[bucket_id])\n",
            "  File \"/usr/lib/python3.6/random.py\", line 260, in choice\n",
            "    raise IndexError('Cannot choose from an empty sequence') from None\n",
            "IndexError: Cannot choose from an empty sequence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TkgJo6HOhxI"
      },
      "source": [
        "# AbrahamSanders seq2seq-chatbot.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EAl8UvbOk_x",
        "outputId": "3dc56fb9-dd6d-4416-f34b-e50ca977d65c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/AbrahamSanders/seq2seq-chatbot.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'seq2seq-chatbot'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 319 (delta 0), reused 0 (delta 0), pack-reused 316\u001b[K\n",
            "Receiving objects: 100% (319/319), 19.19 MiB | 28.69 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I41p07kVQlG4",
        "outputId": "668e1219-982e-4b54-de6f-73768e8f7b2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install jsonpickle\n",
        "!pip install --upgrade tensorflow-gpu==1.*"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle) (3.2.0)\n",
            "Collecting tensorflow-gpu==1.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/b1/9c0d6640eab34fae38f4dae6b312894f8bc1025b0876b3eae1fe11745a7b/tensorflow_gpu-1.15.4-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.15.1)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.*) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.*) (50.3.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.*) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.*) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.*) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.*) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.*) (3.2.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-1.15.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17wqY1GyQO_X",
        "outputId": "b4f4157e-a3de-48bb-fd5b-513adbd0ff57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cd seq2seq-chatbot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/seq2seq-chatbot/seq2seq-chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuhS9jDrQRCA",
        "outputId": "e0f55750-5bba-44b3-b693-52592d6c5a88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdoc_files\u001b[0m/  LICENSE  README.md  \u001b[01;34mseq2seq-chatbot\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KBr456MQFkG",
        "outputId": "82e475d5-35ec-4ad0-fae3-4d8a03b34d8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/seq2seq-chatbot/seq2seq-chatbot/train.py --datasetdir=./datasets/csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Reading dataset 'csv'...\n",
            "\n",
            "Final shared vocab size: 67\n",
            "\n",
            "Splitting 16 samples into training & validation sets (0.0% used for validation)...\n",
            "Training set: 16 samples. Validation set: 0 samples.\n",
            "Sorting training & validation sets to increase training efficiency...\n",
            "Initializing model...\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:409: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:428: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:759: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:773: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:516: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:464: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py:244: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:650: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:654: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:664: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:668: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:118: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:791: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:793: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-10-07 23:27:39.201384: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2020-10-07 23:27:39.216898: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-10-07 23:27:39.217309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14f1100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-07 23:27:39.217346: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-10-07 23:27:39.232353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-10-07 23:27:39.396119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-07 23:27:39.396803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14f12c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-10-07 23:27:39.396833: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-10-07 23:27:39.399874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-07 23:27:39.400422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-10-07 23:27:39.406765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-10-07 23:27:39.415265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2020-10-07 23:27:39.418827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2020-10-07 23:27:39.424868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2020-10-07 23:27:39.433624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2020-10-07 23:27:39.439826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2020-10-07 23:27:39.452649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-10-07 23:27:39.452791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-07 23:27:39.453464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-07 23:27:39.454012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-10-07 23:27:39.457621: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2020-10-07 23:27:39.458914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-10-07 23:27:39.458945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-10-07 23:27:39.458957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-10-07 23:27:39.459446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-07 23:27:39.460077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-10-07 23:27:39.460704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:123: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:125: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/seq2seq-chatbot/seq2seq-chatbot/chatbot_model.py:127: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "\n",
            "Creating checkpoint batch files...\n",
            "Initializing training...\n",
            "Epochs: 50\n",
            "Batch Size: 128\n",
            "Optimizer: sgd\n",
            "2020-10-07 23:27:43.502592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "Epoch:   1/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  4.211, Training Time: 3 seconds), Stats for epoch: (Training Loss:  4.211, Training Time: 3 seconds)\n",
            "Learning rate decay: adjusting from  2.000 to  1.995\n",
            "Training loss improved!\n",
            "Epoch:   2/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  4.039, Training Time: 0 seconds), Stats for epoch: (Training Loss:  4.039, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.995 to  1.990\n",
            "Training loss improved!\n",
            "Epoch:   3/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  4.241, Training Time: 0 seconds), Stats for epoch: (Training Loss:  4.241, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.990 to  1.985\n",
            "Epoch:   4/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  4.814, Training Time: 0 seconds), Stats for epoch: (Training Loss:  4.814, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.985 to  1.980\n",
            "Epoch:   5/50, Batch:    1/1, Stats for last 1 batches: (Training Loss: 10.543, Training Time: 0 seconds), Stats for epoch: (Training Loss: 10.543, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.980 to  1.975\n",
            "Epoch:   6/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  6.482, Training Time: 0 seconds), Stats for epoch: (Training Loss:  6.482, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.975 to  1.970\n",
            "Epoch:   7/50, Batch:    1/1, Stats for last 1 batches: (Training Loss: 11.464, Training Time: 0 seconds), Stats for epoch: (Training Loss: 11.464, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.970 to  1.965\n",
            "Epoch:   8/50, Batch:    1/1, Stats for last 1 batches: (Training Loss: 15.845, Training Time: 0 seconds), Stats for epoch: (Training Loss: 15.845, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.965 to  1.960\n",
            "Epoch:   9/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  8.642, Training Time: 0 seconds), Stats for epoch: (Training Loss:  8.642, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.960 to  1.955\n",
            "Epoch:  10/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  9.403, Training Time: 0 seconds), Stats for epoch: (Training Loss:  9.403, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.955 to  1.951\n",
            "Epoch:  11/50, Batch:    1/1, Stats for last 1 batches: (Training Loss: 14.606, Training Time: 0 seconds), Stats for epoch: (Training Loss: 14.606, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.951 to  1.946\n",
            "Epoch:  12/50, Batch:    1/1, Stats for last 1 batches: (Training Loss: 12.495, Training Time: 0 seconds), Stats for epoch: (Training Loss: 12.495, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.946 to  1.941\n",
            "Epoch:  13/50, Batch:    1/1, Stats for last 1 batches: (Training Loss: 11.268, Training Time: 0 seconds), Stats for epoch: (Training Loss: 11.268, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.941 to  1.936\n",
            "Epoch:  14/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  7.840, Training Time: 0 seconds), Stats for epoch: (Training Loss:  7.840, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.936 to  1.931\n",
            "Epoch:  15/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  5.120, Training Time: 0 seconds), Stats for epoch: (Training Loss:  5.120, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.931 to  1.926\n",
            "Epoch:  16/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  7.408, Training Time: 0 seconds), Stats for epoch: (Training Loss:  7.408, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.926 to  1.921\n",
            "Epoch:  17/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  7.799, Training Time: 0 seconds), Stats for epoch: (Training Loss:  7.799, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.921 to  1.917\n",
            "Epoch:  18/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  4.817, Training Time: 0 seconds), Stats for epoch: (Training Loss:  4.817, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.917 to  1.912\n",
            "Epoch:  19/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.951, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.951, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.912 to  1.907\n",
            "Training loss improved!\n",
            "Epoch:  20/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.536, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.536, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.907 to  1.902\n",
            "Training loss improved!\n",
            "Epoch:  21/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.763, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.763, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.902 to  1.898\n",
            "Epoch:  22/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.432, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.432, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.898 to  1.893\n",
            "Training loss improved!\n",
            "Epoch:  23/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.267, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.267, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.893 to  1.888\n",
            "Training loss improved!\n",
            "Epoch:  24/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.237, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.237, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.888 to  1.883\n",
            "Training loss improved!\n",
            "Epoch:  25/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.308, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.308, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.883 to  1.879\n",
            "Epoch:  26/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.214, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.214, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.879 to  1.874\n",
            "Training loss improved!\n",
            "Epoch:  27/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.150, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.150, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.874 to  1.869\n",
            "Training loss improved!\n",
            "Epoch:  28/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.095, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.095, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.869 to  1.865\n",
            "Training loss improved!\n",
            "Epoch:  29/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.103, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.103, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.865 to  1.860\n",
            "Epoch:  30/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.118, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.118, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.860 to  1.855\n",
            "Epoch:  31/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.110, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.110, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.855 to  1.851\n",
            "Epoch:  32/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.109, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.109, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.851 to  1.846\n",
            "Epoch:  33/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.027, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.027, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.846 to  1.841\n",
            "Training loss improved!\n",
            "Epoch:  34/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.963, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.963, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.841 to  1.837\n",
            "Training loss improved!\n",
            "Backup to models/csv/20201007_232736_backup_2_963 complete!\n",
            "Epoch:  35/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.007, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.007, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.837 to  1.832\n",
            "Epoch:  36/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.997, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.997, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.832 to  1.828\n",
            "Epoch:  37/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.958, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.958, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.828 to  1.823\n",
            "Training loss improved!\n",
            "Epoch:  38/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.928, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.928, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.823 to  1.819\n",
            "Training loss improved!\n",
            "Epoch:  39/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.904, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.904, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.819 to  1.814\n",
            "Training loss improved!\n",
            "Epoch:  40/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.927, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.927, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.814 to  1.809\n",
            "Epoch:  41/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.069, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.069, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.809 to  1.805\n",
            "Epoch:  42/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.348, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.348, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.805 to  1.800\n",
            "Epoch:  43/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.208, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.208, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.800 to  1.796\n",
            "Epoch:  44/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  3.187, Training Time: 0 seconds), Stats for epoch: (Training Loss:  3.187, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.796 to  1.791\n",
            "Epoch:  45/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.901, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.901, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.791 to  1.787\n",
            "Training loss improved!\n",
            "Epoch:  46/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.884, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.884, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.787 to  1.782\n",
            "Training loss improved!\n",
            "Epoch:  47/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.845, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.845, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.782 to  1.778\n",
            "Training loss improved!\n",
            "Epoch:  48/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.761, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.761, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.778 to  1.774\n",
            "Training loss improved!\n",
            "Epoch:  49/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.821, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.821, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.774 to  1.769\n",
            "Epoch:  50/50, Batch:    1/1, Stats for last 1 batches: (Training Loss:  2.836, Training Time: 0 seconds), Stats for epoch: (Training Loss:  2.836, Training Time: 0 seconds)\n",
            "Learning rate decay: adjusting from  1.769 to  1.765\n",
            "Training Complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STUXgKiJ6hU9"
      },
      "source": [
        "# jackfrost1411 naive_bayes_chatbot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-tM7U1l6hak",
        "outputId": "e6d5fb96-36f8-4942-d24d-880aef6ebb31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "! git clone https://github.com/jackfrost1411/naive_bayes_chatbot.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'naive_bayes_chatbot'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 19 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-pahUFY6har",
        "outputId": "ce4b0f2c-1c48-48a0-f93b-da96ac907092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd naive_bayes_chatbot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/naive_bayes_chatbot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwP7HCCd6hax"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-25TP2g26ha3"
      },
      "source": [
        "labels = []\n",
        "questions = []\n",
        "for line in open('que.txt', encoding=\"utf8\"):\n",
        "    labels.append(line.strip().split(\" \")[-1])\n",
        "    questions.append(\" \".join(line.strip().split(\" \")[:-1]))\n",
        "answers = []\n",
        "for line in open('ans.txt', encoding=\"utf8\"):\n",
        "    answers.append(line.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRsVJJqQ6ha8",
        "outputId": "3e5b037c-1484-4ac1-fe29-d63336f84f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bow_vectorizer = CountVectorizer()\n",
        "training_vectors = bow_vectorizer.fit_transform(questions)\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(training_vectors, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0wkXtVo6hbE"
      },
      "source": [
        "class ChatBot:\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "  def start_chat(self):\n",
        "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs!!\\n\")\n",
        "    self.chat(user_response)\n",
        "  \n",
        "  def chat(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "    return\n",
        "  \n",
        "  def generate_response(self, sentence):\n",
        "    input_vector = bow_vectorizer.transform([sentence])\n",
        "    predict = classifier.predict(input_vector)\n",
        "    index = int(predict[0])\n",
        "    print(\"Accurate:\",str(classifier.predict_proba(input_vector)[0][index-1] * 100)[:5] + \"%\")\n",
        "    return answers[index-1]\n",
        "  \n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INj0U3B16hbI",
        "outputId": "7e9d1ddb-ea06-41d4-f6ed-bfbcd509b77e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 943
        }
      },
      "source": [
        "etcetera = ChatBot()\n",
        "etcetera.start_chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi, I'm a chatbot trained on random dialogs!!\n",
            "hello\n",
            "Accurate: 10.64%\n",
            "Hi there, how are you !?\n",
            "good. You?\n",
            "Accurate: 4.914%\n",
            "My name is etcetera, but you can call me etc.\n",
            "Hello etc\n",
            "Accurate: 10.64%\n",
            "Hi there, how are you !?\n",
            "good\n",
            "Accurate: 6.338%\n",
            "Good night! Sweet dreams :)\n",
            "thanks\n",
            "Accurate: 6.512%\n",
            "Good, tell me..\n",
            "tell you what?\n",
            "Accurate: 3.431%\n",
            "I'm 22 years old\n",
            "i'm 23\n",
            "Accurate: 8.108%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2eabe0cf0628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0metcetera\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0metcetera\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-198432d10094>\u001b[0m in \u001b[0;36mstart_chat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstart_chat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0muser_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hi, I'm a chatbot trained on random dialogs!!\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-198432d10094>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, reply)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSJ8Oo4HPX4w"
      },
      "source": [
        "# AbdelrahmanRadwan Open-Domain-ChatBot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oJb66jIPTFz",
        "outputId": "7c702e3b-1273-41f3-d398-4aa1d1c582c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!git clone https://github.com/AbdelrahmanRadwan/Open-Domain-ChatBot.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Open-Domain-ChatBot'...\n",
            "remote: Enumerating objects: 262, done.\u001b[K\n",
            "remote: Total 262 (delta 0), reused 0 (delta 0), pack-reused 262\u001b[K\n",
            "Receiving objects: 100% (262/262), 58.22 MiB | 10.10 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91_BYbWSPq3R",
        "outputId": "9580447e-5f12-45c1-c2b7-08b0aaf25e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Open-Domain-ChatBot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Open-Domain-ChatBot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BQw4XIlPzI7",
        "outputId": "bb204ec4-51ea-4b45-8b37-38cb1aefc5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/99/ac32fd13d56e40d4c3e6150030132519997c0bb1f06f448d970e81b177e5/tensorflow_gpu-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4MB 49kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.18.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.41.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (50.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu>=1.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH33-UVeQj7V",
        "outputId": "ffdd8228-2d4e-4f33-dd95-f2ab03ed4029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!python3 -m nltk.downloader punkt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpsRgfztQqXi",
        "outputId": "c3c690b0-7ce9-4f31-9662-f6f03d171745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "!python3 main.py --verbose --corpus lightweight --datasetTag ./data/lightweight/text.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-15 21:57:23.580790: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 24, in <module>\n",
            "    from chatbot import chatbot\n",
            "  File \"/content/Open-Domain-ChatBot/chatbot/chatbot.py\", line 33, in <module>\n",
            "    from chatbot.textdata import TextData\n",
            "  File \"/content/Open-Domain-ChatBot/chatbot/textdata.py\", line 30, in <module>\n",
            "    from chatbot.corpus.cornelldata import CornellData\n",
            "ModuleNotFoundError: No module named 'chatbot.corpus'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}