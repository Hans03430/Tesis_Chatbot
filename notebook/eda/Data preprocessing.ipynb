{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/Documentos/Tesis_Chatbot/.env/lib/python3.8/site-packages/sqlalchemy/orm/util.py:104: SAWarning: The 'delete-orphan' cascade option requires 'delete'.\n",
      "  util.warn(\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Dict\n",
    "import sys\n",
    "\n",
    "\n",
    "from src.processing.constants import BASE_DIRECTORY\n",
    "from src.processing.data_handler.models.obtained_text import ObtainedText\n",
    "from src.processing.data_handler.models.descriptive_index import DescriptiveIndex\n",
    "from src.processing.data_handler.models.connective_index import ConnectiveIndex\n",
    "from src.processing.data_handler.models.lexical_diversity_index import LexicalDiversityIndex\n",
    "from src.processing.data_handler.models.readability_index import ReadabilityIndex\n",
    "from src.processing.data_handler.models.referential_cohesion_index import ReferentialCohesionIndex\n",
    "from src.processing.data_handler.models.syntactic_complexity_index import SyntacticComplexityIndex\n",
    "from src.processing.data_handler.models.syntactic_pattern_density_index import SyntacticPatternDensityIndex\n",
    "from src.processing.data_handler.models.word_information_index import WordInformationIndex\n",
    "from src.processing.data_handler.data_access.obtained_text_da import ObtainedTextDA\n",
    "from src.processing.text_complexity_analizer import TextComplexityAnalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate text complexity indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta_castellano_inicial.txt Ya ha sido procesado anteriormente.\n",
      "abecedario.txt Ya ha sido procesado anteriormente.\n",
      "aguita-vida.txt Ya ha sido procesado anteriormente.\n",
      "antes-muy-antes.txt Ya ha sido procesado anteriormente.\n",
      "antologia-de-poesia-para-ninos-y-ninas.txt Ya ha sido procesado anteriormente.\n",
      "aprendemos-jugando-2018-4.txt Ya ha sido procesado anteriormente.\n",
      "aprendemos-jugando-2018-5.txt Ya ha sido procesado anteriormente.\n",
      "cancion-amor.txt Ya ha sido procesado anteriormente.\n",
      "cancionero-bebetecas.txt Ya ha sido procesado anteriormente.\n",
      "capacidades_comunica_ama.txt Ya ha sido procesado anteriormente.\n",
      "capacidades_comunica_ande.txt Ya ha sido procesado anteriormente.\n",
      "cartilla-acogida-comunidad-educativa-reinicio-clases.txt Ya ha sido procesado anteriormente.\n",
      "con-los-ojos-abierto-yo-escucho.txt Ya ha sido procesado anteriormente.\n",
      "con-los-ojos-abiertos-yo-veo.txt Ya ha sido procesado anteriormente.\n",
      "cuentos-trabalenguas-3.txt Ya ha sido procesado anteriormente.\n",
      "cuentos-trabalenguas-4.txt Ya ha sido procesado anteriormente.\n",
      "cuentos-trabalenguas-5.txt Ya ha sido procesado anteriormente.\n",
      "cuidados-con-amor.txt Ya ha sido procesado anteriormente.\n",
      "desarrollo-expresion-diversos-lenguajes.txt Ya ha sido procesado anteriormente.\n",
      "el-muneco-de-brea.txt Ya ha sido procesado anteriormente.\n",
      "el-muqui.txt Ya ha sido procesado anteriormente.\n",
      "el-valor-educativo-de-la-observacion-del-desarrollo-del-nino.txt Ya ha sido procesado anteriormente.\n",
      "el-viaje-al-cielo.txt Ya ha sido procesado anteriormente.\n",
      "el-zorro-que-devoro-la-nube.txt Ya ha sido procesado anteriormente.\n",
      "entorno-educativo-calidad-educacion-inicial-guia-docentes.txt Ya ha sido procesado anteriormente.\n",
      "espacios-educativos-para-ninos-ninas-0-3.txt Ya ha sido procesado anteriormente.\n",
      "f_rutas_ini_bil_02.txt Ya ha sido procesado anteriormente.\n",
      "favoreciendo-la-autonomia-y-el-juego.txt Ya ha sido procesado anteriormente.\n",
      "guia-de-encuentros-con-padres-madres-y-cuidadores.txt Ya ha sido procesado anteriormente.\n",
      "guia-materiales-educativos-ninos-ninas-0-3.txt Ya ha sido procesado anteriormente.\n",
      "guia-metodologica-educacion-inicial-eib.txt Ya ha sido procesado anteriormente.\n",
      "guia-para-docente-kits-estudiantes-dotacion.txt Ya ha sido procesado anteriormente.\n",
      "guia-para-trabajo-padres-madres-familia-educacion-inicial.txt Ya ha sido procesado anteriormente.\n",
      "historias-magicas.txt Ya ha sido procesado anteriormente.\n",
      "huallata-zorro.txt Ya ha sido procesado anteriormente.\n",
      "informe-indicadores-clave-evaluacion-nacional.txt Ya ha sido procesado anteriormente.\n",
      "juegos-y-actividades-ludicas-3.txt Ya ha sido procesado anteriormente.\n",
      "juegos-y-actividades-ludicas-4.txt Ya ha sido procesado anteriormente.\n",
      "juegos-y-actividades-ludicas-5.txt Ya ha sido procesado anteriormente.\n",
      "juegos_para_ensenar_a_pensar_1.txt Ya ha sido procesado anteriormente.\n",
      "juegos_para_ensenar_a_pensar_2.txt Ya ha sido procesado anteriormente.\n",
      "jugando-con-las-palabras.txt Ya ha sido procesado anteriormente.\n",
      "la-fiesta-de-la-candelaria.txt Ya ha sido procesado anteriormente.\n",
      "la-papa-tesoro-de-la-tierra.txt Ya ha sido procesado anteriormente.\n",
      "la-planificacion-en-la-educacion-inicial-guia-orientaciones.txt Ya ha sido procesado anteriormente.\n",
      "laminas-para-padres-de-actividades-cotidianas.txt Ya ha sido procesado anteriormente.\n",
      "mi-mantita-linda.txt Ya ha sido procesado anteriormente.\n",
      "momentos-de-cuidado-0.txt Ya ha sido procesado anteriormente.\n",
      "momentos-de-cuidado-1.txt Ya ha sido procesado anteriormente.\n",
      "momentos-de-cuidado-2.txt Ya ha sido procesado anteriormente.\n",
      "momentos-de-juego-0.txt Ya ha sido procesado anteriormente.\n",
      "momentos-de-juego-1.txt Ya ha sido procesado anteriormente.\n",
      "momentos-de-juego-2.txt Ya ha sido procesado anteriormente.\n",
      "orientaciones-para-padres-de-familia-3.txt Ya ha sido procesado anteriormente.\n",
      "orientaciones-para-padres-de-familia-4.txt Ya ha sido procesado anteriormente.\n",
      "orientaciones-para-padres-de-familia-5.txt Ya ha sido procesado anteriormente.\n",
      "programa-curricular-educacion-inicial.txt Ya ha sido procesado anteriormente.\n",
      "proyectos-de-aprendizaje-en-educacion-inicial.txt Ya ha sido procesado anteriormente.\n",
      "que-bonito.txt Ya ha sido procesado anteriormente.\n",
      "que-como-aprenden-nuestros-ninos-ninas-desarrollo-comunicacion-fasciculo-1.txt Ya ha sido procesado anteriormente.\n",
      "rotafolio-sierra-selva.txt Ya ha sido procesado anteriormente.\n",
      "rutas-aprendizaje-que-como-deben-aprender-desarrollo-personal-social-emocional-2015.txt Ya ha sido procesado anteriormente.\n",
      "rutas-aprendizaje-que-como-deben-aprender-desarrollo-personal-social-emocional.txt Ya ha sido procesado anteriormente.\n",
      "rutas-aprendizaje-version-2015-que-como-aprenden-nuestros-ninos-curricular-matem√°tica-3-4-5.txt Ya ha sido procesado anteriormente.\n",
      "selva-selvita-curanderita.txt Ya ha sido procesado anteriormente.\n",
      "somos-herederos-y-guardianes-de-la-tierra.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-02.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-03.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-04.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-05.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-07.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-08.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-09.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-10.txt Ya ha sido procesado anteriormente.\n",
      "taller-de-psicomotricidad-inicio.txt Ya ha sido procesado anteriormente.\n",
      "texto_recurso_desafios_4_anos.txt Ya ha sido procesado anteriormente.\n",
      "texto_recurso_desafios_5_anos.txt Ya ha sido procesado anteriormente.\n",
      "uno-dos-tres-escalones-de-taquile.txt Ya ha sido procesado anteriormente.\n",
      "vicunita-princesita-del-altiplano.txt Ya ha sido procesado anteriormente.\n",
      "y-tu-que-ves.txt Ya ha sido procesado anteriormente.\n",
      "orientaciones-ensenanza-arte-cultura.txt Ya ha sido procesado anteriormente.\n",
      "Ruta_castellano_2a.txt Ya ha sido procesado anteriormente.\n",
      "Ruta_castellano_2b_comprension_y_oralidad.txt Ya ha sido procesado anteriormente.\n",
      "Ruta_castellano_ComMat_IVciclo.txt Ya ha sido procesado anteriormente.\n",
      "Ruta_castellano_ComMat_Vciclo.txt Ya ha sido procesado anteriormente.\n",
      "Ruta_castellano_amazonico_IVciclo.txt Ya ha sido procesado anteriormente.\n",
      "Ruta_castellano_primaria.txt Ya ha sido procesado anteriormente.\n",
      "aprende_conmigo_1.txt Ya ha sido procesado anteriormente.\n",
      "aprende_conmigo_2.txt Ya ha sido procesado anteriormente.\n",
      "aprende_conmigo_3.txt Ya ha sido procesado anteriormente.\n",
      "aprende_conmigo_4.txt Ya ha sido procesado anteriormente.\n",
      "cartilla-informativa-plan-lector.txt Ya ha sido procesado anteriormente.\n",
      "como-organizamos-planificamos-trabajo-castellano-curricular.txt Ya ha sido procesado anteriormente.\n",
      "como-organizamos-planificamos-trabajo-curricular-primaria-bilingue.txt Ya ha sido procesado anteriormente.\n",
      "como-realizamos-caracterizacion-sociolinguistica.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion-situaciones-comunicativas-portafolio-inicial-1.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion1-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion2-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion3-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion4-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion5-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion6-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo-alfabetizacion-inicial-comunicacion1.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo-alfabetizacion-inicial-comunicacion2.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo-alfabetizacion-inicial-comunicacion3.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo_salida2_comunicacion_4to_grado.txt Ya ha sido procesado anteriormente.\n",
      "cuaderno_trabajo_5.txt Ya ha sido procesado anteriormente.\n",
      "cuaderno_trabajo_6.txt Ya ha sido procesado anteriormente.\n",
      "curriculo-nacional-educacion-basica.txt Ya ha sido procesado anteriormente.\n",
      "f_rutas_ini_bil_01.txt Ya ha sido procesado anteriormente.\n",
      "guia-aprendizaje-lengua-senas-peruana-vocabulario-basico.txt Ya ha sido procesado anteriormente.\n",
      "guia-atencion-educativa-ninos-jovenes-tea.txt Ya ha sido procesado anteriormente.\n",
      "guia-atencion-estudiantes-discapacidad-visual.txt Ya ha sido procesado anteriormente.\n",
      "guia-cuadernillos-alfabetizacion.txt Ya ha sido procesado anteriormente.\n",
      "guia-metodologica-primaria.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-1trimestre-entrada1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-1trimestre-entrada2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-2trimestre-proceso1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-2trimestre-proceso2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-3trimestre-salida1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-3trimestre-salida2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-1trimestre-entrada1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-1trimestre-entrada2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-2trimestre-proceso1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-2trimestre-proceso2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-3trimestre-salida.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-manual-uso-docente-4to-primaria-comunicacion.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-manual-uso-docente-4to-primaria-matematica.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-registro-logros-2do-primaria-comunicacion-1trimestre-entrada.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-registro-logros-2do-primaria-comunicacion-2trimestre-proceso.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-registro-logros-2do-primaria-comunicacion-3trimestre-salida.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-registro-logros-4to-primaria-comunicacion-1trimestre-entrada.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-registro-logros-4to-primaria-comunicacion-2trimestre-proceso.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-registro-logros-4to-primaria-comunicacion-3trimestre-salida.txt Ya ha sido procesado anteriormente.\n",
      "libros-biblioteca-aula-primaria-1er-grado-catalogo.txt Ya ha sido procesado anteriormente.\n",
      "libros-biblioteca-aula-primaria-2do-grado-catalogo.txt Ya ha sido procesado anteriormente.\n",
      "libros-biblioteca-aula-primaria-3er-grado-catalogo.txt Ya ha sido procesado anteriormente.\n",
      "libros-biblioteca-aula-primaria-4to-grado-catalogo.txt Ya ha sido procesado anteriormente.\n",
      "libros-biblioteca-aula-primaria-5to-grado-catalogo.txt Ya ha sido procesado anteriormente.\n",
      "libros-biblioteca-aula-primaria-6to-grado-catalogo.txt Ya ha sido procesado anteriormente.\n",
      "maestros-padres-mejores-aliados-aprendizaje-ciclo3.txt Ya ha sido procesado anteriormente.\n",
      "maestros-padres-mejores-aliados-aprendizaje-ciclo4.txt Ya ha sido procesado anteriormente.\n",
      "maestros-padres-mejores-aliados-aprendizaje-ciclo5.txt Ya ha sido procesado anteriormente.\n",
      "mama_ven.txt Ya ha sido procesado anteriormente.\n",
      "manual-familia-1.txt Ya ha sido procesado anteriormente.\n",
      "manual-familia-2.txt Ya ha sido procesado anteriormente.\n",
      "manual-lenguaje-senas-peruanas.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-1.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-2.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-3.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-4.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-5.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-6.txt Ya ha sido procesado anteriormente.\n",
      "neologismo-lenguas-originarias.txt Ya ha sido procesado anteriormente.\n",
      "orientaciones-atencion-educativa-estudiantes-discapacidad-auditiva.txt Ya ha sido procesado anteriormente.\n",
      "orientaciones-para-generar-aprendizajes-inicial.txt Ya ha sido procesado anteriormente.\n",
      "orientaciones-para-generar-aprendizajes-intermedio.txt Ya ha sido procesado anteriormente.\n",
      "programa-curricular-educacion-primaria.txt Ya ha sido procesado anteriormente.\n",
      "proyecto-aprendizaje-portafolio-inicial.txt Ya ha sido procesado anteriormente.\n",
      "proyectos-aprendizaje-rutas-aprendizaje.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-comunicativas-comunicacion-texto-1-inicial.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-comunicativas-texto-2-inicial.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-portafolio-2-intermedio.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-portafolio-intermedio-1.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-texto-2-intermedio.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-texto-3-intermedio.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-texto-intermedio-1.txt Ya ha sido procesado anteriormente.\n",
      "san_martin_porres.txt Ya ha sido procesado anteriormente.\n",
      "santa_rosa.txt Ya ha sido procesado anteriormente.\n",
      "toribio_mogrovejo.txt Ya ha sido procesado anteriormente.\n",
      "augusto_leguia.txt Ya ha sido procesado anteriormente.\n",
      "carta_jamaica.txt Ya ha sido procesado anteriormente.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuenca_rio_santa.txt no pudo ser procesado debido a un error en el procesamiento.\n",
      "division by zero\n",
      "Tiempo demorado para fernando_belaunde.txt: 21.833874464035034 segundos.\n",
      "Tiempo demorado para haya_torre.txt: 14.459125280380249 segundos.\n",
      "Tiempo demorado para historia_geografia.txt: 198.79838013648987 segundos.\n",
      "Tiempo demorado para manuel_valdes.txt: 14.912410974502563 segundos.\n",
      "Tiempo demorado para manuela_saenz.txt: 18.727966785430908 segundos.\n",
      "Tiempo demorado para agua_suelo.txt: 91.08719158172607 segundos.\n",
      "Tiempo demorado para ambiente-salud-unidad-2-portafolio-3-avanzado.txt: 627.8673944473267 segundos.\n",
      "Tiempo demorado para ambiente-salud-unidad-2-portafolio-4-avanzado.txt: 1833.1775631904602 segundos.\n",
      "Tiempo demorado para ambiente-salud-unidad-2-texto-1-avanzado.txt: 1175.930245399475 segundos.\n",
      "Tiempo demorado para ambiente-salud-unidad-2-texto-2.txt: 1209.7159872055054 segundos.\n",
      "Tiempo demorado para ambiente-salud-unidad-2-texto-3-avanzado.txt: 1452.2210519313812 segundos.\n",
      "Tiempo demorado para ambiente-salud-unidad-2-texto-4-avanzado.txt: 2199.9148824214935 segundos.\n",
      "Tiempo demorado para biodiversidad_docente.txt: 88.87464809417725 segundos.\n",
      "Tiempo demorado para biologia.txt: 96.4570734500885 segundos.\n",
      "Tiempo demorado para conciencia-ambiental-globe.txt: 707.9739344120026 segundos.\n",
      "Tiempo demorado para espacios-vida-esvi.txt: 430.8853762149811 segundos.\n",
      "Tiempo demorado para extranos_mundos.txt: 35.3832893371582 segundos.\n",
      "Tiempo demorado para fisica.txt: 143.79486465454102 segundos.\n",
      "Tiempo demorado para fragmentos_nuevo_mundo.txt: 20.015270471572876 segundos.\n",
      "Tiempo demorado para guia-tic-2019.txt: 70.78859972953796 segundos.\n",
      "Tiempo demorado para guiso_fantasmagorico.txt: 15.160338878631592 segundos.\n",
      "Tiempo demorado para inventores_viajeros_docentes.txt: 90.37847805023193 segundos.\n",
      "Tiempo demorado para manejo-residuos-solidos-mares.txt: 323.19424772262573 segundos.\n",
      "Tiempo demorado para promoviendo-estilos-vida-alimentacion-saludable.txt: 141.28698754310608 segundos.\n",
      "rotafolio_estudiantes.txt no pudo ser procesado debido a un error en el procesamiento.\n",
      "division by zero\n",
      "rotafolio_promotores_parteras.txt no pudo ser procesado debido a un error en el procesamiento.\n",
      "division by zero\n",
      "Tiempo demorado para tsunami.txt: 483.658084154129 segundos.\n",
      "Tiempo demorado para vih_sida_aw.txt: 14.312796354293823 segundos.\n",
      "Tiempo demorado para vih_sida_es.txt: 12.510514497756958 segundos.\n",
      "Tiempo demorado para arte.txt: 126.36778235435486 segundos.\n",
      "Tiempo demorado para arte_digital_interactividad.txt: 416.0400846004486 segundos.\n",
      "Tiempo demorado para maria_granda.txt: 15.389428615570068 segundos.\n",
      "Tiempo demorado para 20_leguas_viaje_submarino.txt: 6202.1183478832245 segundos.\n",
      "Tiempo demorado para abel_sanchez.txt: 335.0362195968628 segundos.\n",
      "Tiempo demorado para amistad_funesta.txt: 481.20472621917725 segundos.\n",
      "Tiempo demorado para antologia-literaria-1.txt: 812.8982014656067 segundos.\n",
      "Tiempo demorado para antologia-literaria-2.txt: 788.8642954826355 segundos.\n",
      "Tiempo demorado para antologia-literaria-4.txt: 1013.5568473339081 segundos.\n",
      "Tiempo demorado para antologia-literaria-5.txt: 1188.6739642620087 segundos.\n",
      "Tiempo demorado para antologia_leer_escribir.txt: 465.8080675601959 segundos.\n",
      "Tiempo demorado para arguedas.txt: 17.325379848480225 segundos.\n",
      "Tiempo demorado para aventuras_robinson_crusoe.txt: 1743.9254729747772 segundos.\n",
      "Tiempo demorado para aventuras_tom_sawyer.txt: 1809.105315208435 segundos.\n",
      "Tiempo demorado para bella_bestia.txt: 30.828803300857544 segundos.\n",
      "Tiempo demorado para bibliotecas_escolares.txt: 1847.9804487228394 segundos.\n",
      "Tiempo demorado para cartas_sor_juana.txt: 240.6056182384491 segundos.\n",
      "Tiempo demorado para castellano-como-segunda-lengua.txt: 8886.579404830933 segundos.\n",
      "Tiempo demorado para castillo.txt: 3719.4170446395874 segundos.\n",
      "Tiempo demorado para cesar_vallejo.txt: 19.988574981689453 segundos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hans/Documentos/Tesis_Chatbot/.env/lib/python3.8/site-packages/numpy/core/_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/home/hans/Documentos/Tesis_Chatbot/.env/lib/python3.8/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "/home/hans/Documentos/Tesis_Chatbot/.env/lib/python3.8/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/hans/Documentos/Tesis_Chatbot/.env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/hans/Documentos/Tesis_Chatbot/.env/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charles_dickens.txt no pudo ser procesado debido a un error en el procesamiento.\n",
      "division by zero\n",
      "Tiempo demorado para clorinda_matto.txt: 20.951656341552734 segundos.\n",
      "Tiempo demorado para competencias-comunicativas.txt: 1735.8768134117126 segundos.\n",
      "Tiempo demorado para comunicacion-secundaria-rural-cuaderno-1.txt: 855.0696384906769 segundos.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-707354fb7967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexical_diversity_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLexicalDiversityIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_lexical_diversity_density_indices_for_one_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadability_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadabilityIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_readability_indices_for_one_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_words_per_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_words_per_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_syllables_per_word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_syllables_per_word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreferential_cohesion_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReferentialCohesionIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_referential_cohesion_indices_for_one_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Save the indices for the current record\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Tesis_Chatbot/src/processing/text_complexity_analizer.py\u001b[0m in \u001b[0;36mcalculate_referential_cohesion_indices_for_one_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CRFNOa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_noun_overlap_all_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CRFAO1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_argument_overlap_adjacent_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CRFAOa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_argument_overlap_all_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CRFSO1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stem_overlap_adjacent_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CRFSOa'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rci\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stem_overlap_all_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Tesis_Chatbot/src/processing/coh_metrix_indices/referential_cohesion_indices.py\u001b[0m in \u001b[0;36mget_argument_overlap_all_sentences\u001b[0;34m(self, text, workers)\u001b[0m\n\u001b[1;32m    182\u001b[0m         '''\n\u001b[1;32m    183\u001b[0m         \u001b[0mdisable_pipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'parser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ner'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_overlap_for_all_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_pipeline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_analizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manalize_argument_overlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatistic_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_stem_overlap_adjacent_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Tesis_Chatbot/src/processing/coh_metrix_indices/referential_cohesion_indices.py\u001b[0m in \u001b[0;36m_calculate_overlap_for_all_sentences\u001b[0;34m(self, text, disable_pipeline, sentence_analizer, statistic_type, workers)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msent_one\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msent_two\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_analizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_two\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mstat_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatisticsResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Create empty container\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documentos/Tesis_Chatbot/src/processing/coh_metrix_indices/referential_cohesion_indices.py\u001b[0m in \u001b[0;36manalize_argument_overlap\u001b[0;34m(prev_sentence, cur_sentence)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcur_sentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Iterate every token of the current sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alpha\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NOUN'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemma_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprev_sentence_noun_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# There's cohesion by noun lemma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tca = TextComplexityAnalizer('es')\n",
    "da = ObtainedTextDA()\n",
    "obtained_texts = da.select_all()\n",
    "\n",
    "for ot in obtained_texts:\n",
    "    if ot.descriptive_index is not None and ot.word_information_index is not None and ot.syntactic_pattern_density_index is not None and ot.syntactic_complexity_index is not None and ot.connective_index is not None and ot.lexical_diversity_index is not None and ot.readability_index is not None and ot.referential_cohesion_index:\n",
    "        print(f'{ot.filename} Ya ha sido procesado anteriormente.')\n",
    "    else:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            descriptive_row = tca.calculate_descriptive_indices_for_one_text(ot.text)\n",
    "            word_count = descriptive_row['DESWC']\n",
    "            mean_words_per_sentence = descriptive_row['DESSL']\n",
    "            mean_syllables_per_word = descriptive_row['DESWLsy']\n",
    "            ot.descriptive_index = DescriptiveIndex(**descriptive_row)\n",
    "            ot.word_information_index = WordInformationIndex(**tca.calculate_word_information_indices_for_one_text(ot.text, word_count))\n",
    "            ot.syntactic_pattern_density_index = SyntacticPatternDensityIndex(**tca.calculate_syntactic_pattern_density_indices_for_one_text(ot.text, word_count))\n",
    "            ot.syntactic_complexity_index = SyntacticComplexityIndex(**tca.calculate_syntactic_complexity_indices_for_one_text(ot.text))\n",
    "            ot.connective_index = ConnectiveIndex(**tca.calculate_connective_indices_for_one_text(ot.text, word_count))\n",
    "            ot.lexical_diversity_index = LexicalDiversityIndex(**tca.calculate_lexical_diversity_density_indices_for_one_text(ot.text))\n",
    "            ot.readability_index = ReadabilityIndex(**tca.calculate_readability_indices_for_one_text(ot.text, mean_words_per_sentence=mean_words_per_sentence, mean_syllables_per_word=mean_syllables_per_word))\n",
    "            ot.referential_cohesion_index = ReferentialCohesionIndex(**tca.calculate_referential_cohesion_indices_for_one_text(text=ot.text))\n",
    "            end = time.time()\n",
    "            da.update(ot) # Save the indices for the current record       \n",
    "            print(f'Tiempo demorado para {ot.filename}: {end - start} segundos.')\n",
    "        except Exception as e:\n",
    "            print(f'{ot.filename} no pudo ser procesado debido a un error en el procesamiento.')\n",
    "            print(str(e))\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
