{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            import asyncio\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Dict\n",
    "import sys\n",
    "                                                                                                                                                                                                                                                    \n",
    "\n",
    "from src.processing.constants import BASE_DIRECTORY\n",
    "from src.preparation.models.obtained_text import ObtainedText\n",
    "from src.preparation.models.descriptive_index import DescriptiveIndex\n",
    "from src.preparation.models.connective_index import ConnectiveIndex\n",
    "from src.preparation.models.lexical_diversity_index import LexicalDiversityIndex\n",
    "from src.preparation.models.readability_index import ReadabilityIndex\n",
    "from src.preparation.models.referential_cohesion_index import ReferentialCohesionIndex\n",
    "from src.preparation.models.syntactic_complexity_index import SyntacticComplexityIndex\n",
    "from src.preparation.models.syntactic_pattern_density_index import SyntacticPatternDensityIndex\n",
    "from src.preparation.models.word_information_index import WordInformationIndex\n",
    "from src.preparation.data_access.obtained_text_da import ObtainedTextDA\n",
    "from src.processing.text_complexity_analyzer import TextComplexityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate text complexity indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atahualpa.txt Ya ha sido procesado anteriormente.\n",
      "avelino_caceres.txt Ya ha sido procesado anteriormente.\n",
      "cartilla_fenomeno_nino.txt Ya ha sido procesado anteriormente.\n",
      "cartilla_inundaciones.txt Ya ha sido procesado anteriormente.\n",
      "enrique_meiggs.txt Ya ha sido procesado anteriormente.\n",
      "epopeya_arica.txt Ya ha sido procesado anteriormente.\n",
      "francisco_bolognesi.txt Ya ha sido procesado anteriormente.\n",
      "francisco_orellana.txt Ya ha sido procesado anteriormente.\n",
      "francisco_toledo.txt Ya ha sido procesado anteriormente.\n",
      "guaman_poma.txt Ya ha sido procesado anteriormente.\n",
      "hipolito_unanue.txt Ya ha sido procesado anteriormente.\n",
      "ines_huaylas.txt Ya ha sido procesado anteriormente.\n",
      "jorge_basadre.txt Ya ha sido procesado anteriormente.\n",
      "jorge_chavez.txt Ya ha sido procesado anteriormente.\n",
      "jose_olaya.txt Ya ha sido procesado anteriormente.\n",
      "jsanchez_carrion.txt Ya ha sido procesado anteriormente.\n",
      "juanita.txt Ya ha sido procesado anteriormente.\n",
      "leoncio_prado.txt Ya ha sido procesado anteriormente.\n",
      "manco_inca.txt Ya ha sido procesado anteriormente.\n",
      "mateo_pumacahua.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-ps-1.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-ps-2.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-ps-3.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-ps-5.txt Ya ha sido procesado anteriormente.\n",
      "micaela_bastidas.txt Ya ha sido procesado anteriormente.\n",
      "miguel_grau.txt Ya ha sido procesado anteriormente.\n",
      "nicolas_pierola.txt Ya ha sido procesado anteriormente.\n",
      "pachacutec.txt Ya ha sido procesado anteriormente.\n",
      "pedro_peralta.txt Ya ha sido procesado anteriormente.\n",
      "ramon_castilla.txt Ya ha sido procesado anteriormente.\n",
      "santa_cruz.txt Ya ha sido procesado anteriormente.\n",
      "sipan.txt Ya ha sido procesado anteriormente.\n",
      "tupac_amaru.txt Ya ha sido procesado anteriormente.\n",
      "tupac_amaru2.txt Ya ha sido procesado anteriormente.\n",
      "ahorro-energia-eficiente-tecnologias.txt Ya ha sido procesado anteriormente.\n",
      "amigos-amigas-energia-3-4-cartilla-actividad.txt Ya ha sido procesado anteriormente.\n",
      "amigos-amigas-energia-3-4-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "areas-verdes-escuela.txt Ya ha sido procesado anteriormente.\n",
      "cambio-climatico.txt Ya ha sido procesado anteriormente.\n",
      "energizate-planes-clase.txt Ya ha sido procesado anteriormente.\n",
      "guia_espacio_vida_estudiantes_iii.txt Ya ha sido procesado anteriormente.\n",
      "guia_espacio_vida_estudiantes_iv.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-cya-1.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-cya-2.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-cya-3.txt Ya ha sido procesado anteriormente.\n",
      "proyecto-de-aprendizaje-inicial.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion-situaciones-comunicativas-portafolio-inicial-1.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion1-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion2-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion3-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion4-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion5-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion6-cuaderno-trabajo.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo-alfabetizacion-inicial-comunicacion1.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo-alfabetizacion-inicial-comunicacion2.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo-alfabetizacion-inicial-comunicacion3.txt Ya ha sido procesado anteriormente.\n",
      "cuadernillo_salida2_comunicacion_4to_grado.txt Ya ha sido procesado anteriormente.\n",
      "cuaderno_trabajo_5.txt Ya ha sido procesado anteriormente.\n",
      "cuaderno_trabajo_6.txt Ya ha sido procesado anteriormente.\n",
      "guia-metodologica-primaria.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-1trimestre-entrada1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-1trimestre-entrada2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-2trimestre-proceso1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-2trimestre-proceso2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-3trimestre-salida1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-2do-primaria-comunicacion-3trimestre-salida2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-1trimestre-entrada1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-1trimestre-entrada2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-2trimestre-proceso1.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-2trimestre-proceso2.txt Ya ha sido procesado anteriormente.\n",
      "kit-evaluacion-demostrando-aprendimos-4to-primaria-comunicacion-3trimestre-salida.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-1.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-2.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-3.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-4.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-5.txt Ya ha sido procesado anteriormente.\n",
      "mi-cuaderno-autoaprendizaje-com-6.txt Ya ha sido procesado anteriormente.\n",
      "proyecto-aprendizaje-portafolio-inicial.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-comunicativas-comunicacion-texto-1-inicial.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-comunicativas-texto-2-inicial.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-portafolio-2-intermedio.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-portafolio-intermedio-1.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-texto-2-intermedio.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-texto-3-intermedio.txt Ya ha sido procesado anteriormente.\n",
      "situaciones-para-aprender-construir-texto-intermedio-1.txt Ya ha sido procesado anteriormente.\n",
      "Sin t√≠tulo 1.txt Ya ha sido procesado anteriormente.\n",
      "augusto_leguia.txt Ya ha sido procesado anteriormente.\n",
      "canal_panama.txt Ya ha sido procesado anteriormente.\n",
      "carta_jamaica.txt Ya ha sido procesado anteriormente.\n",
      "cuenca_rio_santa.txt Ya ha sido procesado anteriormente.\n",
      "expansion_roma.txt Ya ha sido procesado anteriormente.\n",
      "fernando_belaunde.txt Ya ha sido procesado anteriormente.\n",
      "haya_torre.txt Ya ha sido procesado anteriormente.\n",
      "historia_geografia.txt Ya ha sido procesado anteriormente.\n",
      "la_cuenca_del_amazonas.txt Ya ha sido procesado anteriormente.\n",
      "la_estructura_demografica_de_la_poblacion.txt Ya ha sido procesado anteriormente.\n",
      "la_organizacion_de_la_economia_en_el_imperio_inca.txt Ya ha sido procesado anteriormente.\n",
      "las_corrientes_marinas.txt Ya ha sido procesado anteriormente.\n",
      "las_proyecciones_cartograficas.txt Ya ha sido procesado anteriormente.\n",
      "manuel_valdes.txt Ya ha sido procesado anteriormente.\n",
      "manuela_saenz.txt Ya ha sido procesado anteriormente.\n",
      "maria_granda.txt Ya ha sido procesado anteriormente.\n",
      "mesoamericanos_mayas_aztecas.txt Ya ha sido procesado anteriormente.\n",
      "polis_griega.txt Ya ha sido procesado anteriormente.\n",
      "pueblos_mediterraneo_griegos.txt Ya ha sido procesado anteriormente.\n",
      "agua_suelo.txt Ya ha sido procesado anteriormente.\n",
      "ambiente-salud-unidad-2-portafolio-3-avanzado.txt Ya ha sido procesado anteriormente.\n",
      "ambiente-salud-unidad-2-portafolio-4-avanzado.txt Ya ha sido procesado anteriormente.\n",
      "ambiente-salud-unidad-2-texto-1-avanzado.txt Ya ha sido procesado anteriormente.\n",
      "ambiente-salud-unidad-2-texto-2.txt Ya ha sido procesado anteriormente.\n",
      "ambiente-salud-unidad-2-texto-3-avanzado.txt Ya ha sido procesado anteriormente.\n",
      "ambiente-salud-unidad-2-texto-4-avanzado.txt Ya ha sido procesado anteriormente.\n",
      "biologia.txt Ya ha sido procesado anteriormente.\n",
      "conciencia-ambiental-globe.txt Ya ha sido procesado anteriormente.\n",
      "espacios-vida-esvi.txt Ya ha sido procesado anteriormente.\n",
      "extranos_mundos.txt Ya ha sido procesado anteriormente.\n",
      "fisica.txt Ya ha sido procesado anteriormente.\n",
      "fragmentos_nuevo_mundo.txt Ya ha sido procesado anteriormente.\n",
      "guiso_fantasmagorico.txt Ya ha sido procesado anteriormente.\n",
      "manejo-residuos-solidos-mares.txt Ya ha sido procesado anteriormente.\n",
      "promoviendo-estilos-vida-alimentacion-saludable.txt Ya ha sido procesado anteriormente.\n",
      "vih_sida_es.txt Ya ha sido procesado anteriormente.\n",
      "20_leguas_viaje_submarino.txt Ya ha sido procesado anteriormente.\n",
      "abel_sanchez.txt Ya ha sido procesado anteriormente.\n",
      "amistad_funesta.txt Ya ha sido procesado anteriormente.\n",
      "antologia-literaria-1.txt Ya ha sido procesado anteriormente.\n",
      "antologia-literaria-2.txt Ya ha sido procesado anteriormente.\n",
      "antologia-literaria-4.txt Ya ha sido procesado anteriormente.\n",
      "antologia-literaria-5.txt Ya ha sido procesado anteriormente.\n",
      "antologia_leer_escribir.txt Ya ha sido procesado anteriormente.\n",
      "arguedas.txt Ya ha sido procesado anteriormente.\n",
      "aventuras_robinson_crusoe.txt Ya ha sido procesado anteriormente.\n",
      "aventuras_tom_sawyer.txt Ya ha sido procesado anteriormente.\n",
      "bella_bestia.txt Ya ha sido procesado anteriormente.\n",
      "bibliotecas_escolares.txt Ya ha sido procesado anteriormente.\n",
      "cartas_sor_juana.txt Ya ha sido procesado anteriormente.\n",
      "castillo.txt Ya ha sido procesado anteriormente.\n",
      "cesar_vallejo.txt Ya ha sido procesado anteriormente.\n",
      "charles_dickens.txt Ya ha sido procesado anteriormente.\n",
      "clorinda_matto.txt Ya ha sido procesado anteriormente.\n",
      "comunicacion-secundaria-rural-cuaderno-1.txt Ya ha sido procesado anteriormente.\n",
      "corsario_negro.txt Ya ha sido procesado anteriormente.\n",
      "cuaderno-nivelacion-competencias-com-vi.txt Ya ha sido procesado anteriormente.\n",
      "cumbres_borrascosas.txt Ya ha sido procesado anteriormente.\n",
      "estacion-de-las-letras.txt Ya ha sido procesado anteriormente.\n",
      "extrano_caso_doctor_hyde.txt Ya ha sido procesado anteriormente.\n",
      "frankenstein.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-1-m1.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-1-m2.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-1-m3.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-1-m4.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-2-m1.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-2-m2.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-2-m3.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-2-m4.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-3-m1.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-3-m2.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-3-m3.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-3-m4.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-4-m1.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-4-m2.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-4-m3.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-4-m4.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-5-m1.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-5-m2.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-5-m3.txt Ya ha sido procesado anteriormente.\n",
      "hora-literaria-5-m4.txt Ya ha sido procesado anteriormente.\n",
      "imagenes_frases_atrapan.txt Ya ha sido procesado anteriormente.\n",
      "isla_tesoro.txt Ya ha sido procesado anteriormente.\n",
      "madame_bovary.txt Ya ha sido procesado anteriormente.\n",
      "mariategui.txt Ya ha sido procesado anteriormente.\n",
      "memorias_subsuelo.txt Ya ha sido procesado anteriormente.\n",
      "mirada_lince.txt Ya ha sido procesado anteriormente.\n",
      "moby_dick.txt Ya ha sido procesado anteriormente.\n",
      "poe_crimenes.txt Ya ha sido procesado anteriormente.\n",
      "principe_mendigo.txt Ya ha sido procesado anteriormente.\n",
      "ricardo_palma.txt Ya ha sido procesado anteriormente.\n",
      "romeo_julieta.txt Ya ha sido procesado anteriormente.\n",
      "santos_chocano.txt Ya ha sido procesado anteriormente.\n",
      "seis_personajes_busca.txt Ya ha sido procesado anteriormente.\n",
      "viaje_centro_tierra.txt Ya ha sido procesado anteriormente.\n",
      "viajes_gulliver.txt Ya ha sido procesado anteriormente.\n",
      "vida_lazarillo_tormes.txt Ya ha sido procesado anteriormente.\n",
      "vuelta_mundo_80.txt Ya ha sido procesado anteriormente.\n"
     ]
    }
   ],
   "source": [
    "tca = TextComplexityAnalyzer('es')\n",
    "da = ObtainedTextDA()\n",
    "obtained_texts = da.select_all()\n",
    "\n",
    "for ot in obtained_texts:\n",
    "    if ot.descriptive_index is not None and ot.word_information_index is not None and ot.syntactic_pattern_density_index is not None and ot.syntactic_complexity_index is not None and ot.connective_index is not None and ot.lexical_diversity_index is not None and ot.readability_index is not None and ot.referential_cohesion_index:\n",
    "        print(f'{ot.filename} Ya ha sido procesado anteriormente.')\n",
    "    else:\n",
    "        try:\n",
    "            start = time.time()\n",
    "            descriptive_row = tca.calculate_descriptive_indices_for_one_text(ot.text)\n",
    "            word_count = descriptive_row['DESWC']\n",
    "            mean_words_per_sentence = descriptive_row['DESSL']\n",
    "            mean_syllables_per_word = descriptive_row['DESWLsy']\n",
    "            ot.descriptive_index = DescriptiveIndex(**descriptive_row)\n",
    "            ot.word_information_index = WordInformationIndex(**tca.calculate_word_information_indices_for_one_text(ot.text, word_count=word_count))\n",
    "            ot.syntactic_pattern_density_index = SyntacticPatternDensityIndex(**tca.calculate_syntactic_pattern_density_indices_for_one_text(ot.text, word_count=word_count))\n",
    "            ot.syntactic_complexity_index = SyntacticComplexityIndex(**tca.calculate_syntactic_complexity_indices_for_one_text(ot.text))\n",
    "            ot.connective_index = ConnectiveIndex(**tca.calculate_connective_indices_for_one_text(ot.text, word_count=word_count))\n",
    "            ot.lexical_diversity_index = LexicalDiversityIndex(**tca.calculate_lexical_diversity_density_indices_for_one_text(ot.text))\n",
    "            ot.readability_index = ReadabilityIndex(**tca.calculate_readability_indices_for_one_text(ot.text, mean_words_per_sentence=mean_words_per_sentence, mean_syllables_per_word=mean_syllables_per_word))\n",
    "            ot.referential_cohesion_index = ReferentialCohesionIndex(**tca.calculate_referential_cohesion_indices_for_one_text(text=ot.text))\n",
    "            end = time.time()\n",
    "            da.update(ot) # Save the indices for the current record       \n",
    "            print(f'Tiempo demorado para {ot.filename}: {end - start} segundos.')\n",
    "        except Exception as e:\n",
    "            print(f'{ot.filename} no pudo ser procesado debido a un error en el procesamiento.')\n",
    "            print(str(e))\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing  the data obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNCADC</th>\n",
       "      <th>CNCAdd</th>\n",
       "      <th>CNCAll</th>\n",
       "      <th>CNCCaus</th>\n",
       "      <th>CNCLogic</th>\n",
       "      <th>CNCTemp</th>\n",
       "      <th>CRFANP1</th>\n",
       "      <th>CRFANPa</th>\n",
       "      <th>CRFAO1</th>\n",
       "      <th>CRFAOa</th>\n",
       "      <th>...</th>\n",
       "      <th>WRDPRP2p</th>\n",
       "      <th>WRDPRP2s</th>\n",
       "      <th>WRDPRP3p</th>\n",
       "      <th>WRDPRP3s</th>\n",
       "      <th>WRDVERB</th>\n",
       "      <th>category</th>\n",
       "      <th>cluster_grade</th>\n",
       "      <th>filename</th>\n",
       "      <th>grade</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.595524</td>\n",
       "      <td>0.532907</td>\n",
       "      <td>56.754596</td>\n",
       "      <td>17.319478</td>\n",
       "      <td>30.109246</td>\n",
       "      <td>3.197442</td>\n",
       "      <td>0.099526</td>\n",
       "      <td>0.079630</td>\n",
       "      <td>0.236967</td>\n",
       "      <td>0.148887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.398082</td>\n",
       "      <td>10.125233</td>\n",
       "      <td>110.578204</td>\n",
       "      <td>Historia, Geograf√≠a y Econom√≠a</td>\n",
       "      <td>None</td>\n",
       "      <td>atahualpa.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.526167</td>\n",
       "      <td>0.848656</td>\n",
       "      <td>56.294201</td>\n",
       "      <td>13.861386</td>\n",
       "      <td>33.663366</td>\n",
       "      <td>3.394625</td>\n",
       "      <td>0.159722</td>\n",
       "      <td>0.119540</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.197797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.848656</td>\n",
       "      <td>2.545969</td>\n",
       "      <td>8.769448</td>\n",
       "      <td>94.766620</td>\n",
       "      <td>Historia, Geograf√≠a y Econom√≠a</td>\n",
       "      <td>None</td>\n",
       "      <td>avelino_caceres.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.737619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.079062</td>\n",
       "      <td>11.294526</td>\n",
       "      <td>40.834057</td>\n",
       "      <td>5.212858</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.019822</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.150034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.212858</td>\n",
       "      <td>1.737619</td>\n",
       "      <td>9.556907</td>\n",
       "      <td>149.435274</td>\n",
       "      <td>Historia, Geograf√≠a y Econom√≠a</td>\n",
       "      <td>None</td>\n",
       "      <td>cartilla_fenomeno_nino.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.765225</td>\n",
       "      <td>1.765225</td>\n",
       "      <td>64.430715</td>\n",
       "      <td>12.356575</td>\n",
       "      <td>44.130627</td>\n",
       "      <td>4.413063</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.142577</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.708738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.708738</td>\n",
       "      <td>151.809356</td>\n",
       "      <td>Historia, Geograf√≠a y Econom√≠a</td>\n",
       "      <td>None</td>\n",
       "      <td>cartilla_inundaciones.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.965697</td>\n",
       "      <td>0.248571</td>\n",
       "      <td>52.945563</td>\n",
       "      <td>13.422819</td>\n",
       "      <td>30.325628</td>\n",
       "      <td>2.982849</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.171011</td>\n",
       "      <td>0.430303</td>\n",
       "      <td>0.273384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.739995</td>\n",
       "      <td>10.688541</td>\n",
       "      <td>93.711161</td>\n",
       "      <td>Historia, Geograf√≠a y Econom√≠a</td>\n",
       "      <td>None</td>\n",
       "      <td>enrique_meiggs.txt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>10.168675</td>\n",
       "      <td>1.012048</td>\n",
       "      <td>60.096386</td>\n",
       "      <td>15.084337</td>\n",
       "      <td>24.626506</td>\n",
       "      <td>9.204819</td>\n",
       "      <td>0.153777</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.229317</td>\n",
       "      <td>0.130330</td>\n",
       "      <td>...</td>\n",
       "      <td>2.650602</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>2.409639</td>\n",
       "      <td>20.192771</td>\n",
       "      <td>118.265060</td>\n",
       "      <td>Comunicaci√≥n</td>\n",
       "      <td>None</td>\n",
       "      <td>seis_personajes_busca.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>8.489796</td>\n",
       "      <td>0.593692</td>\n",
       "      <td>56.653061</td>\n",
       "      <td>15.762523</td>\n",
       "      <td>25.751391</td>\n",
       "      <td>6.055659</td>\n",
       "      <td>0.072211</td>\n",
       "      <td>0.051115</td>\n",
       "      <td>0.170490</td>\n",
       "      <td>0.105130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044527</td>\n",
       "      <td>2.077922</td>\n",
       "      <td>1.128015</td>\n",
       "      <td>9.261596</td>\n",
       "      <td>108.897959</td>\n",
       "      <td>Comunicaci√≥n</td>\n",
       "      <td>None</td>\n",
       "      <td>viaje_centro_tierra.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>8.669041</td>\n",
       "      <td>0.941620</td>\n",
       "      <td>74.623352</td>\n",
       "      <td>19.456726</td>\n",
       "      <td>40.274707</td>\n",
       "      <td>5.281258</td>\n",
       "      <td>0.328918</td>\n",
       "      <td>0.254774</td>\n",
       "      <td>0.546726</td>\n",
       "      <td>0.382347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194465</td>\n",
       "      <td>0.020470</td>\n",
       "      <td>3.531073</td>\n",
       "      <td>13.745599</td>\n",
       "      <td>114.120200</td>\n",
       "      <td>Comunicaci√≥n</td>\n",
       "      <td>None</td>\n",
       "      <td>viajes_gulliver.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>4.147928</td>\n",
       "      <td>0.218312</td>\n",
       "      <td>82.958564</td>\n",
       "      <td>22.355150</td>\n",
       "      <td>52.045584</td>\n",
       "      <td>4.191591</td>\n",
       "      <td>0.287313</td>\n",
       "      <td>0.192939</td>\n",
       "      <td>0.375622</td>\n",
       "      <td>0.225790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480286</td>\n",
       "      <td>2.357770</td>\n",
       "      <td>2.969043</td>\n",
       "      <td>22.922761</td>\n",
       "      <td>102.606645</td>\n",
       "      <td>Comunicaci√≥n</td>\n",
       "      <td>None</td>\n",
       "      <td>vida_lazarillo_tormes.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>8.836926</td>\n",
       "      <td>0.561329</td>\n",
       "      <td>64.119836</td>\n",
       "      <td>15.604953</td>\n",
       "      <td>30.776880</td>\n",
       "      <td>8.339749</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>0.075108</td>\n",
       "      <td>0.196321</td>\n",
       "      <td>0.116191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785861</td>\n",
       "      <td>0.176418</td>\n",
       "      <td>1.443418</td>\n",
       "      <td>11.499230</td>\n",
       "      <td>111.351681</td>\n",
       "      <td>Comunicaci√≥n</td>\n",
       "      <td>None</td>\n",
       "      <td>vuelta_mundo_80.txt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows √ó 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CNCADC    CNCAdd     CNCAll    CNCCaus   CNCLogic   CNCTemp   CRFANP1  \\\n",
       "0     5.595524  0.532907  56.754596  17.319478  30.109246  3.197442  0.099526   \n",
       "1     4.526167  0.848656  56.294201  13.861386  33.663366  3.394625  0.159722   \n",
       "2     1.737619  0.000000  59.079062  11.294526  40.834057  5.212858  0.026316   \n",
       "3     1.765225  1.765225  64.430715  12.356575  44.130627  4.413063  0.035714   \n",
       "4     5.965697  0.248571  52.945563  13.422819  30.325628  2.982849  0.151515   \n",
       "..         ...       ...        ...        ...        ...       ...       ...   \n",
       "179  10.168675  1.012048  60.096386  15.084337  24.626506  9.204819  0.153777   \n",
       "180   8.489796  0.593692  56.653061  15.762523  25.751391  6.055659  0.072211   \n",
       "181   8.669041  0.941620  74.623352  19.456726  40.274707  5.281258  0.328918   \n",
       "182   4.147928  0.218312  82.958564  22.355150  52.045584  4.191591  0.287313   \n",
       "183   8.836926  0.561329  64.119836  15.604953  30.776880  8.339749  0.094280   \n",
       "\n",
       "      CRFANPa    CRFAO1    CRFAOa  ...  WRDPRP2p   WRDPRP2s  WRDPRP3p  \\\n",
       "0    0.079630  0.236967  0.148887  ...  0.000000   0.000000  2.398082   \n",
       "1    0.119540  0.291667  0.197797  ...  0.000000   0.848656  2.545969   \n",
       "2    0.019822  0.197368  0.150034  ...  0.000000   5.212858  1.737619   \n",
       "3    0.039216  0.166667  0.142577  ...  0.000000   9.708738  0.000000   \n",
       "4    0.171011  0.430303  0.273384  ...  0.000000   0.000000  1.739995   \n",
       "..        ...       ...       ...  ...       ...        ...       ...   \n",
       "179  0.113482  0.229317  0.130330  ...  2.650602  15.180723  2.409639   \n",
       "180  0.051115  0.170490  0.105130  ...  0.044527   2.077922  1.128015   \n",
       "181  0.254774  0.546726  0.382347  ...  0.194465   0.020470  3.531073   \n",
       "182  0.192939  0.375622  0.225790  ...  0.480286   2.357770  2.969043   \n",
       "183  0.075108  0.196321  0.116191  ...  0.785861   0.176418  1.443418   \n",
       "\n",
       "      WRDPRP3s     WRDVERB                        category  cluster_grade  \\\n",
       "0    10.125233  110.578204  Historia, Geograf√≠a y Econom√≠a           None   \n",
       "1     8.769448   94.766620  Historia, Geograf√≠a y Econom√≠a           None   \n",
       "2     9.556907  149.435274  Historia, Geograf√≠a y Econom√≠a           None   \n",
       "3     9.708738  151.809356  Historia, Geograf√≠a y Econom√≠a           None   \n",
       "4    10.688541   93.711161  Historia, Geograf√≠a y Econom√≠a           None   \n",
       "..         ...         ...                             ...            ...   \n",
       "179  20.192771  118.265060                    Comunicaci√≥n           None   \n",
       "180   9.261596  108.897959                    Comunicaci√≥n           None   \n",
       "181  13.745599  114.120200                    Comunicaci√≥n           None   \n",
       "182  22.922761  102.606645                    Comunicaci√≥n           None   \n",
       "183  11.499230  111.351681                    Comunicaci√≥n           None   \n",
       "\n",
       "                       filename  grade     id  \n",
       "0                 atahualpa.txt    1.0    1.0  \n",
       "1           avelino_caceres.txt    1.0    2.0  \n",
       "2    cartilla_fenomeno_nino.txt    1.0    3.0  \n",
       "3     cartilla_inundaciones.txt    1.0    4.0  \n",
       "4            enrique_meiggs.txt    1.0    5.0  \n",
       "..                          ...    ...    ...  \n",
       "179   seis_personajes_busca.txt    2.0  181.0  \n",
       "180     viaje_centro_tierra.txt    2.0  182.0  \n",
       "181         viajes_gulliver.txt    2.0  183.0  \n",
       "182   vida_lazarillo_tormes.txt    2.0  184.0  \n",
       "183         vuelta_mundo_80.txt    2.0  185.0  \n",
       "\n",
       "[184 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da = ObtainedTextDA()\n",
    "obtained_texts = da.select_all_as_dataframe()\n",
    "obtained_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
